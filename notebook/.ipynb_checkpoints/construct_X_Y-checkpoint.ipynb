{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id  country iso3   gwno  year  geo_id  geolocation  level     adm1  \\\n",
      "0  109  Albania  ALB  339.0  2009     346  Ana E Malit      3  Shkoder   \n",
      "1  109  Albania  ALB  339.0  2009     351       Bushat      3  Shkoder   \n",
      "\n",
      "       adm2         adm3     location  historical hist_country disastertype  \\\n",
      "0  Shkodres  Ana E Malit  Ana E Malit           0          NaN        flood   \n",
      "1  Shkodres       Bushat       Bushat           0          NaN        flood   \n",
      "\n",
      "  disasterno   latitude  longitude  \n",
      "0  2009-0631  42.020948  19.418317  \n",
      "1  2009-0631  41.959294  19.514309  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3155: DtypeWarning: Columns (8,16,17,18,19,24,25,26,27,46,48) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dis No</th>\n",
       "      <th>Year</th>\n",
       "      <th>Seq</th>\n",
       "      <th>Glide</th>\n",
       "      <th>Disaster Group</th>\n",
       "      <th>Disaster Subgroup</th>\n",
       "      <th>Disaster Type</th>\n",
       "      <th>Disaster Subtype</th>\n",
       "      <th>Disaster Subsubtype</th>\n",
       "      <th>Event Name</th>\n",
       "      <th>...</th>\n",
       "      <th>Reconstruction Costs, Adjusted ('000 US$)</th>\n",
       "      <th>Insured Damages ('000 US$)</th>\n",
       "      <th>Insured Damages, Adjusted ('000 US$)</th>\n",
       "      <th>Total Damages ('000 US$)</th>\n",
       "      <th>Total Damages, Adjusted ('000 US$)</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Adm Level</th>\n",
       "      <th>Admin1 Code</th>\n",
       "      <th>Admin2 Code</th>\n",
       "      <th>Geo Locations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900-9002-CPV</td>\n",
       "      <td>1900</td>\n",
       "      <td>9002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Climatological</td>\n",
       "      <td>Drought</td>\n",
       "      <td>Drought</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.077091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1900-9001-IND</td>\n",
       "      <td>1900</td>\n",
       "      <td>9001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Climatological</td>\n",
       "      <td>Drought</td>\n",
       "      <td>Drought</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.077091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1902-0012-GTM</td>\n",
       "      <td>1902</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>Ground movement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>781207.0</td>\n",
       "      <td>3.200175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1902-0003-GTM</td>\n",
       "      <td>1902</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>Volcanic activity</td>\n",
       "      <td>Ash fall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Santa Maria</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.200175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902-0010-GTM</td>\n",
       "      <td>1902</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Geophysical</td>\n",
       "      <td>Volcanic activity</td>\n",
       "      <td>Ash fall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Santa Maria</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.200175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Dis No  Year   Seq Glide Disaster Group Disaster Subgroup  \\\n",
       "0  1900-9002-CPV  1900  9002   NaN        Natural    Climatological   \n",
       "1  1900-9001-IND  1900  9001   NaN        Natural    Climatological   \n",
       "2  1902-0012-GTM  1902    12   NaN        Natural       Geophysical   \n",
       "3  1902-0003-GTM  1902     3   NaN        Natural       Geophysical   \n",
       "4  1902-0010-GTM  1902    10   NaN        Natural       Geophysical   \n",
       "\n",
       "       Disaster Type Disaster Subtype Disaster Subsubtype   Event Name  ...  \\\n",
       "0            Drought          Drought                 NaN          NaN  ...   \n",
       "1            Drought          Drought                 NaN          NaN  ...   \n",
       "2         Earthquake  Ground movement                 NaN          NaN  ...   \n",
       "3  Volcanic activity         Ash fall                 NaN  Santa Maria  ...   \n",
       "4  Volcanic activity         Ash fall                 NaN  Santa Maria  ...   \n",
       "\n",
       "  Reconstruction Costs, Adjusted ('000 US$) Insured Damages ('000 US$)  \\\n",
       "0                                       NaN                        NaN   \n",
       "1                                       NaN                        NaN   \n",
       "2                                       NaN                        NaN   \n",
       "3                                       NaN                        NaN   \n",
       "4                                       NaN                        NaN   \n",
       "\n",
       "  Insured Damages, Adjusted ('000 US$) Total Damages ('000 US$)  \\\n",
       "0                                  NaN                      NaN   \n",
       "1                                  NaN                      NaN   \n",
       "2                                  NaN                  25000.0   \n",
       "3                                  NaN                      NaN   \n",
       "4                                  NaN                      NaN   \n",
       "\n",
       "  Total Damages, Adjusted ('000 US$)       CPI Adm Level Admin1 Code  \\\n",
       "0                                NaN  3.077091       NaN         NaN   \n",
       "1                                NaN  3.077091       NaN         NaN   \n",
       "2                           781207.0  3.200175       NaN         NaN   \n",
       "3                                NaN  3.200175       NaN         NaN   \n",
       "4                                NaN  3.200175       NaN         NaN   \n",
       "\n",
       "  Admin2 Code Geo Locations  \n",
       "0         NaN           NaN  \n",
       "1         NaN           NaN  \n",
       "2         NaN           NaN  \n",
       "3         NaN           NaN  \n",
       "4         NaN           NaN  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gdis disaster info \n",
    "gdis = pd.read_csv('../data/pend-gdis-1960-2018-disasterlocations.csv')\n",
    "\n",
    "print(gdis.head(2))\n",
    "#get emdat dataset\n",
    "emdat = pd.read_csv('../data/emdat_public_2022_09_21_query_uid-47Yzpr.csv', skiprows=[0,1,2,3,4,5])\n",
    "emdat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select certain columns from emdat and join with gdis \n",
    "emdat['disasterno'] = emdat['Dis No'].str[:-4] #format disasterno to merge  \n",
    "cols = ['disasterno', 'Year', 'Event Name', \n",
    "#         'Disaster Type', 'Disaster Subtype', \n",
    "#         'Region', 'Continent', #'Location',\n",
    "        'Start Year', 'Start Month', 'Start Day', \n",
    "        'End Year', 'End Month','End Day',  \n",
    "        \"Total Damages, Adjusted ('000 US$)\"] \n",
    "\n",
    "emdat = emdat[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join emdat and gdis \n",
    "gdis = pd.merge(emdat, gdis, on = 'disasterno', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #format date time - it's not done because of missing values \n",
    "# df['year'] = df['Start Year']\n",
    "# df['month'] = df['Start Month']\n",
    "# df['day'] = df['Start Day']\n",
    "\n",
    "\n",
    "# # \n",
    "# dff = df[['year','month','day']].fillna(0).astype(int)\n",
    "\n",
    "# pd.to_datetime(dff[['year','month','day']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9924, 27)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print \n",
    "gdis = gdis.drop_duplicates(subset=['id'])\n",
    "gdis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of grid pairs 2852\n"
     ]
    }
   ],
   "source": [
    "#latitude range from -90 to 90, longitude range from -180 to 180 \n",
    "\n",
    "#convert lat and long into 1 degree grid: correspond to 100*100km \n",
    "gdis['lat_grid'] = np.digitize(np.array(gdis['latitude']),np.arange(-90,90,1))\n",
    "gdis['lon_grid'] = np.digitize(np.array(gdis['longitude']),np.arange(-180,180,1)) \n",
    "#compute the grid pair id \n",
    "gdis['grid_id'] = list(zip(gdis['lat_grid'],gdis['lon_grid']))\n",
    "print('total number of grid pairs', len(gdis.grid_id.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disasterno</th>\n",
       "      <th>Year</th>\n",
       "      <th>Event Name</th>\n",
       "      <th>Start Year</th>\n",
       "      <th>Start Month</th>\n",
       "      <th>Start Day</th>\n",
       "      <th>End Year</th>\n",
       "      <th>End Month</th>\n",
       "      <th>End Day</th>\n",
       "      <th>Total Damages, Adjusted ('000 US$)</th>\n",
       "      <th>...</th>\n",
       "      <th>adm3</th>\n",
       "      <th>location</th>\n",
       "      <th>historical</th>\n",
       "      <th>hist_country</th>\n",
       "      <th>disastertype</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>lat_grid</th>\n",
       "      <th>lon_grid</th>\n",
       "      <th>grid_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-0631</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Ana E Malit</td>\n",
       "      <td>Ana E Malit</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flood</td>\n",
       "      <td>42.020948</td>\n",
       "      <td>19.418317</td>\n",
       "      <td>133</td>\n",
       "      <td>200</td>\n",
       "      <td>(133, 200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-0146</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Onjiva</td>\n",
       "      <td>Onjiva</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flood</td>\n",
       "      <td>-17.093484</td>\n",
       "      <td>15.665758</td>\n",
       "      <td>73</td>\n",
       "      <td>196</td>\n",
       "      <td>(73, 196)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-0092</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Evale</td>\n",
       "      <td>Evale</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flood</td>\n",
       "      <td>-16.531533</td>\n",
       "      <td>15.773987</td>\n",
       "      <td>74</td>\n",
       "      <td>196</td>\n",
       "      <td>(74, 196)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2010-0105</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Evale</td>\n",
       "      <td>Evale</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flood</td>\n",
       "      <td>-16.531533</td>\n",
       "      <td>15.773987</td>\n",
       "      <td>74</td>\n",
       "      <td>196</td>\n",
       "      <td>(74, 196)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1995-0082</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1422569.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Hatiya</td>\n",
       "      <td>Hatiya</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>storm</td>\n",
       "      <td>22.291591</td>\n",
       "      <td>91.065456</td>\n",
       "      <td>113</td>\n",
       "      <td>272</td>\n",
       "      <td>(113, 272)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82858</th>\n",
       "      <td>1960-0011</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>Manam</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Manam</td>\n",
       "      <td>1</td>\n",
       "      <td>Australia</td>\n",
       "      <td>volcanic activity</td>\n",
       "      <td>-4.383452</td>\n",
       "      <td>144.922859</td>\n",
       "      <td>86</td>\n",
       "      <td>325</td>\n",
       "      <td>(86, 325)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82859</th>\n",
       "      <td>2009-9633</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unity</td>\n",
       "      <td>1</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>drought</td>\n",
       "      <td>8.926421</td>\n",
       "      <td>29.885783</td>\n",
       "      <td>99</td>\n",
       "      <td>210</td>\n",
       "      <td>(99, 210)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82865</th>\n",
       "      <td>1990-9289</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bar El Ghazal Province</td>\n",
       "      <td>1</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>drought</td>\n",
       "      <td>8.248650</td>\n",
       "      <td>26.099769</td>\n",
       "      <td>99</td>\n",
       "      <td>207</td>\n",
       "      <td>(99, 207)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82866</th>\n",
       "      <td>1969-9069</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73867.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Taiz-Torba</td>\n",
       "      <td>1</td>\n",
       "      <td>Yemen North</td>\n",
       "      <td>drought</td>\n",
       "      <td>13.418716</td>\n",
       "      <td>43.777557</td>\n",
       "      <td>104</td>\n",
       "      <td>224</td>\n",
       "      <td>(104, 224)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82867</th>\n",
       "      <td>2015-0375</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Hurricane Erika</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>551973.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St. Joseph province</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>storm</td>\n",
       "      <td>15.446035</td>\n",
       "      <td>-61.383800</td>\n",
       "      <td>106</td>\n",
       "      <td>119</td>\n",
       "      <td>(106, 119)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9924 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      disasterno    Year       Event Name  Start Year  Start Month  Start Day  \\\n",
       "0      2009-0631  2009.0              NaN      2009.0         12.0       27.0   \n",
       "2      2001-0146  2001.0              NaN      2001.0          4.0        2.0   \n",
       "3      2009-0092  2009.0              NaN      2009.0          3.0        1.0   \n",
       "18     2010-0105  2010.0              NaN      2010.0          3.0        1.0   \n",
       "20     1995-0082  1995.0              NaN      1995.0          5.0       15.0   \n",
       "...          ...     ...              ...         ...          ...        ...   \n",
       "82858  1960-0011  1960.0            Manam      1960.0          3.0       17.0   \n",
       "82859  2009-9633  2009.0              NaN      2009.0          NaN        NaN   \n",
       "82865  1990-9289  1990.0              NaN      1990.0          NaN        NaN   \n",
       "82866  1969-9069  1969.0              NaN      1969.0          NaN        NaN   \n",
       "82867  2015-0375  2015.0  Hurricane Erika      2015.0          8.0       27.0   \n",
       "\n",
       "       End Year  End Month  End Day  Total Damages, Adjusted ('000 US$)  ...  \\\n",
       "0        2010.0        1.0      8.0                                 NaN  ...   \n",
       "2        2001.0        4.0      9.0                                 NaN  ...   \n",
       "3        2009.0        4.0     16.0                                 NaN  ...   \n",
       "18       2010.0        3.0     17.0                                 NaN  ...   \n",
       "20       1995.0        5.0     15.0                           1422569.0  ...   \n",
       "...         ...        ...      ...                                 ...  ...   \n",
       "82858    1960.0        3.0     17.0                                 NaN  ...   \n",
       "82859    2010.0        NaN      NaN                                 NaN  ...   \n",
       "82865    1990.0        NaN      NaN                                 NaN  ...   \n",
       "82866    1971.0        NaN      NaN                             73867.0  ...   \n",
       "82867    2015.0        8.0     27.0                            551973.0  ...   \n",
       "\n",
       "              adm3                location historical  hist_country  \\\n",
       "0      Ana E Malit             Ana E Malit          0           NaN   \n",
       "2           Onjiva                  Onjiva          0           NaN   \n",
       "3            Evale                   Evale          0           NaN   \n",
       "18           Evale                   Evale          0           NaN   \n",
       "20          Hatiya                  Hatiya          0           NaN   \n",
       "...            ...                     ...        ...           ...   \n",
       "82858          NaN                   Manam          1     Australia   \n",
       "82859          NaN                   Unity          1         Sudan   \n",
       "82865          NaN  Bar El Ghazal Province          1         Sudan   \n",
       "82866          NaN              Taiz-Torba          1   Yemen North   \n",
       "82867          NaN     St. Joseph province          1           NaN   \n",
       "\n",
       "            disastertype   latitude   longitude  lat_grid lon_grid     grid_id  \n",
       "0                  flood  42.020948   19.418317       133      200  (133, 200)  \n",
       "2                  flood -17.093484   15.665758        73      196   (73, 196)  \n",
       "3                  flood -16.531533   15.773987        74      196   (74, 196)  \n",
       "18                 flood -16.531533   15.773987        74      196   (74, 196)  \n",
       "20                 storm  22.291591   91.065456       113      272  (113, 272)  \n",
       "...                  ...        ...         ...       ...      ...         ...  \n",
       "82858  volcanic activity  -4.383452  144.922859        86      325   (86, 325)  \n",
       "82859            drought   8.926421   29.885783        99      210   (99, 210)  \n",
       "82865            drought   8.248650   26.099769        99      207   (99, 207)  \n",
       "82866            drought  13.418716   43.777557       104      224  (104, 224)  \n",
       "82867              storm  15.446035  -61.383800       106      119  (106, 119)  \n",
       "\n",
       "[9924 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #count number of locations in each grid_id: ideally just 1 location per grid_id, if not, I can make grid finer. \n",
    "# gdis.groupby('grid_id').agg({'location':'nunique'}).sort_values(by='location').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the grid with most regions \n",
    "# gdis.loc[gdis['grid_id']==(113, 295)].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot function\n",
    "def pivot(df_in, id_col='disastertype', id_list=['Flood']):\n",
    "    df = df_in.reset_index(drop = True)\n",
    "\n",
    "\n",
    "    for id in id_list:\n",
    "        #initialize columns\n",
    "        df[id+'_bin'] = 0\n",
    "        df[id+'_amt'] = 0\n",
    "        df[id+'_ct'] = 0\n",
    "        \n",
    "\n",
    "        df.loc[(df[id_col]==id), id+'_bin'] = 1\n",
    "        df.loc[(df[id_col]==id), id+'_amt'] = df[\"Total Damages, Adjusted ('000 US$)\"].astype(float)\n",
    "        df.loc[(df[id_col]==id), id+'_ct'] = 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flood', 'storm', 'earthquake', 'extreme temperature ', 'landslide', 'volcanic activity', 'drought', 'mass movement (dry)']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disasterno</th>\n",
       "      <th>Year</th>\n",
       "      <th>Event Name</th>\n",
       "      <th>Start Year</th>\n",
       "      <th>Start Month</th>\n",
       "      <th>Start Day</th>\n",
       "      <th>End Year</th>\n",
       "      <th>End Month</th>\n",
       "      <th>End Day</th>\n",
       "      <th>Total Damages, Adjusted ('000 US$)</th>\n",
       "      <th>...</th>\n",
       "      <th>landslide_ct</th>\n",
       "      <th>volcanic activity_bin</th>\n",
       "      <th>volcanic activity_amt</th>\n",
       "      <th>volcanic activity_ct</th>\n",
       "      <th>drought_bin</th>\n",
       "      <th>drought_amt</th>\n",
       "      <th>drought_ct</th>\n",
       "      <th>mass movement (dry)_bin</th>\n",
       "      <th>mass movement (dry)_amt</th>\n",
       "      <th>mass movement (dry)_ct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-0631</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-0146</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-0092</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-0105</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995-0082</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1422569.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9919</th>\n",
       "      <td>1960-0011</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>Manam</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9920</th>\n",
       "      <td>2009-9633</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9921</th>\n",
       "      <td>1990-9289</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9922</th>\n",
       "      <td>1969-9069</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73867.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>73867.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9923</th>\n",
       "      <td>2015-0375</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Hurricane Erika</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>551973.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9924 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     disasterno    Year       Event Name  Start Year  Start Month  Start Day  \\\n",
       "0     2009-0631  2009.0              NaN      2009.0         12.0       27.0   \n",
       "1     2001-0146  2001.0              NaN      2001.0          4.0        2.0   \n",
       "2     2009-0092  2009.0              NaN      2009.0          3.0        1.0   \n",
       "3     2010-0105  2010.0              NaN      2010.0          3.0        1.0   \n",
       "4     1995-0082  1995.0              NaN      1995.0          5.0       15.0   \n",
       "...         ...     ...              ...         ...          ...        ...   \n",
       "9919  1960-0011  1960.0            Manam      1960.0          3.0       17.0   \n",
       "9920  2009-9633  2009.0              NaN      2009.0          NaN        NaN   \n",
       "9921  1990-9289  1990.0              NaN      1990.0          NaN        NaN   \n",
       "9922  1969-9069  1969.0              NaN      1969.0          NaN        NaN   \n",
       "9923  2015-0375  2015.0  Hurricane Erika      2015.0          8.0       27.0   \n",
       "\n",
       "      End Year  End Month  End Day  Total Damages, Adjusted ('000 US$)  ...  \\\n",
       "0       2010.0        1.0      8.0                                 NaN  ...   \n",
       "1       2001.0        4.0      9.0                                 NaN  ...   \n",
       "2       2009.0        4.0     16.0                                 NaN  ...   \n",
       "3       2010.0        3.0     17.0                                 NaN  ...   \n",
       "4       1995.0        5.0     15.0                           1422569.0  ...   \n",
       "...        ...        ...      ...                                 ...  ...   \n",
       "9919    1960.0        3.0     17.0                                 NaN  ...   \n",
       "9920    2010.0        NaN      NaN                                 NaN  ...   \n",
       "9921    1990.0        NaN      NaN                                 NaN  ...   \n",
       "9922    1971.0        NaN      NaN                             73867.0  ...   \n",
       "9923    2015.0        8.0     27.0                            551973.0  ...   \n",
       "\n",
       "     landslide_ct volcanic activity_bin volcanic activity_amt  \\\n",
       "0               0                     0                   0.0   \n",
       "1               0                     0                   0.0   \n",
       "2               0                     0                   0.0   \n",
       "3               0                     0                   0.0   \n",
       "4               0                     0                   0.0   \n",
       "...           ...                   ...                   ...   \n",
       "9919            0                     1                   NaN   \n",
       "9920            0                     0                   0.0   \n",
       "9921            0                     0                   0.0   \n",
       "9922            0                     0                   0.0   \n",
       "9923            0                     0                   0.0   \n",
       "\n",
       "      volcanic activity_ct  drought_bin  drought_amt drought_ct  \\\n",
       "0                        0            0          0.0          0   \n",
       "1                        0            0          0.0          0   \n",
       "2                        0            0          0.0          0   \n",
       "3                        0            0          0.0          0   \n",
       "4                        0            0          0.0          0   \n",
       "...                    ...          ...          ...        ...   \n",
       "9919                     1            0          0.0          0   \n",
       "9920                     0            1          NaN          1   \n",
       "9921                     0            1          NaN          1   \n",
       "9922                     0            1      73867.0          1   \n",
       "9923                     0            0          0.0          0   \n",
       "\n",
       "      mass movement (dry)_bin mass movement (dry)_amt mass movement (dry)_ct  \n",
       "0                           0                     0.0                      0  \n",
       "1                           0                     0.0                      0  \n",
       "2                           0                     0.0                      0  \n",
       "3                           0                     0.0                      0  \n",
       "4                           0                     0.0                      0  \n",
       "...                       ...                     ...                    ...  \n",
       "9919                        0                     0.0                      0  \n",
       "9920                        0                     0.0                      0  \n",
       "9921                        0                     0.0                      0  \n",
       "9922                        0                     0.0                      0  \n",
       "9923                        0                     0.0                      0  \n",
       "\n",
       "[9924 rows x 54 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# id_list= df_sub['Disaster Type'].unique()\n",
    "id_list= gdis['disastertype'].unique().tolist()\n",
    "print(id_list)\n",
    "df_pivot= pivot(gdis, id_col = 'disastertype', id_list = id_list)\n",
    "df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate columns by year\n",
    "def aggregate_yrly(df):\n",
    "    #aggregate count\n",
    "    col_ct = [col for col in df.columns if '_ct' in col]\n",
    "    df_ct = df.groupby(['grid_id','year'])[col_ct].agg('sum')\n",
    "    \n",
    "    #aggregate amount \n",
    "    col_amt = [col for col in df.columns if '_amt' in col]\n",
    "    df_amt = df.groupby(['grid_id','year'])[col_amt].agg('sum')\n",
    "    \n",
    "    #aggregate binary\n",
    "    col_bin = [col for col in df.columns if '_bin' in col]\n",
    "    df_bin= df.groupby(['grid_id','year'])[col_bin].agg('max')\n",
    "\n",
    "    #join\n",
    "    df1= pd.concat([df_amt, df_ct], axis=1)\n",
    "    df_out = pd.concat([df1, df_bin], axis=1)\n",
    "    return df_out.reset_index()\n",
    "df_yrly = aggregate_yrly(df_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_id</th>\n",
       "      <th>year</th>\n",
       "      <th>flood_amt</th>\n",
       "      <th>storm_amt</th>\n",
       "      <th>earthquake_amt</th>\n",
       "      <th>extreme temperature _amt</th>\n",
       "      <th>landslide_amt</th>\n",
       "      <th>volcanic activity_amt</th>\n",
       "      <th>drought_amt</th>\n",
       "      <th>mass movement (dry)_amt</th>\n",
       "      <th>...</th>\n",
       "      <th>drought_ct</th>\n",
       "      <th>mass movement (dry)_ct</th>\n",
       "      <th>flood_bin</th>\n",
       "      <th>storm_bin</th>\n",
       "      <th>earthquake_bin</th>\n",
       "      <th>extreme temperature _bin</th>\n",
       "      <th>landslide_bin</th>\n",
       "      <th>volcanic activity_bin</th>\n",
       "      <th>drought_bin</th>\n",
       "      <th>mass movement (dry)_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(37, 108)</td>\n",
       "      <td>1990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(42, 108)</td>\n",
       "      <td>2017</td>\n",
       "      <td>2211.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(42, 111)</td>\n",
       "      <td>1991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(44, 107)</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(44, 107)</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8675</th>\n",
       "      <td>(157, 311)</td>\n",
       "      <td>1998</td>\n",
       "      <td>5818.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8676</th>\n",
       "      <td>(157, 311)</td>\n",
       "      <td>2007</td>\n",
       "      <td>33655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8677</th>\n",
       "      <td>(157, 311)</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8678</th>\n",
       "      <td>(158, 207)</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8679</th>\n",
       "      <td>(159, 45)</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8680 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         grid_id  year  flood_amt  storm_amt  earthquake_amt  \\\n",
       "0      (37, 108)  1990        0.0        0.0             0.0   \n",
       "1      (42, 108)  2017     2211.0        0.0             0.0   \n",
       "2      (42, 111)  1991        0.0        0.0             0.0   \n",
       "3      (44, 107)  2007        0.0        0.0             0.0   \n",
       "4      (44, 107)  2010        0.0        0.0             0.0   \n",
       "...          ...   ...        ...        ...             ...   \n",
       "8675  (157, 311)  1998     5818.0        0.0             0.0   \n",
       "8676  (157, 311)  2007    33655.0        0.0             0.0   \n",
       "8677  (157, 311)  2012        0.0        0.0             0.0   \n",
       "8678  (158, 207)  2005        0.0        0.0             0.0   \n",
       "8679   (159, 45)  2006        0.0        0.0             0.0   \n",
       "\n",
       "      extreme temperature _amt  landslide_amt  volcanic activity_amt  \\\n",
       "0                          0.0            0.0                    0.0   \n",
       "1                          0.0            0.0                    0.0   \n",
       "2                          0.0            0.0                    0.0   \n",
       "3                          0.0            0.0                    0.0   \n",
       "4                          0.0            0.0                    0.0   \n",
       "...                        ...            ...                    ...   \n",
       "8675                       0.0            0.0                    0.0   \n",
       "8676                       0.0            0.0                    0.0   \n",
       "8677                       0.0            0.0                    0.0   \n",
       "8678                       0.0            0.0                    0.0   \n",
       "8679                       0.0            0.0                    0.0   \n",
       "\n",
       "      drought_amt  mass movement (dry)_amt  ...  drought_ct  \\\n",
       "0             0.0                      0.0  ...           0   \n",
       "1             0.0                      0.0  ...           0   \n",
       "2             0.0                      0.0  ...           0   \n",
       "3             0.0                      0.0  ...           0   \n",
       "4             0.0                      0.0  ...           0   \n",
       "...           ...                      ...  ...         ...   \n",
       "8675          0.0                      0.0  ...           0   \n",
       "8676          0.0                      0.0  ...           0   \n",
       "8677          0.0                      0.0  ...           0   \n",
       "8678          0.0                      0.0  ...           0   \n",
       "8679          0.0                      0.0  ...           0   \n",
       "\n",
       "      mass movement (dry)_ct  flood_bin  storm_bin  earthquake_bin  \\\n",
       "0                          0          1          0               0   \n",
       "1                          0          1          0               0   \n",
       "2                          0          0          0               0   \n",
       "3                          0          0          0               1   \n",
       "4                          0          0          0               0   \n",
       "...                      ...        ...        ...             ...   \n",
       "8675                       0          1          0               0   \n",
       "8676                       0          1          0               0   \n",
       "8677                       0          0          0               0   \n",
       "8678                       0          1          0               0   \n",
       "8679                       0          1          0               0   \n",
       "\n",
       "      extreme temperature _bin  landslide_bin  volcanic activity_bin  \\\n",
       "0                            0              0                      0   \n",
       "1                            0              0                      0   \n",
       "2                            0              0                      1   \n",
       "3                            0              0                      0   \n",
       "4                            1              0                      0   \n",
       "...                        ...            ...                    ...   \n",
       "8675                         0              0                      0   \n",
       "8676                         0              0                      0   \n",
       "8677                         1              0                      0   \n",
       "8678                         0              0                      0   \n",
       "8679                         0              0                      0   \n",
       "\n",
       "      drought_bin  mass movement (dry)_bin  \n",
       "0               0                        0  \n",
       "1               0                        0  \n",
       "2               0                        0  \n",
       "3               0                        0  \n",
       "4               0                        0  \n",
       "...           ...                      ...  \n",
       "8675            0                        0  \n",
       "8676            0                        0  \n",
       "8677            0                        0  \n",
       "8678            0                        0  \n",
       "8679            0                        0  \n",
       "\n",
       "[8680 rows x 26 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yrly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'flood_ct'}>]], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#count how many flood for each grid over all data \n",
    "df_yrly.groupby('grid_id').agg({'flood_ct':'sum'}).hist() #[['grid_id','flood_ct']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disaster list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_col =  [col for col in df_yrly.columns if '_bin' in col]\n",
    "df_yrly_bin = df_yrly[['grid_id','year'] + bin_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #get a list of disasters and flood_id \n",
    "# all_dis = gdis[['grid_id','Year','disastertype']]\n",
    "\n",
    "# #\n",
    "# flood = all_dis.loc[all_dis['disastertype']=='flood']\n",
    "# flood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1960.0 2018.0\n",
      "168268\n"
     ]
    }
   ],
   "source": [
    "# get a list of grid_ids \n",
    "grid_id = gdis['grid_id'].unique()\n",
    "# get a list of year information \n",
    "print(gdis.Year.min(), gdis.Year.max())\n",
    "year_id = np.arange(1960, 2019, 1) \n",
    "#create multi-index: each grid id, spanning over the years \n",
    "idd = pd.MultiIndex.from_product([grid_id, year_id],\n",
    "                           names=['grid_id', 'year'])\n",
    "\n",
    "#length should be |years| * |grid_ids| \n",
    "print(len(idd))\n",
    "#get dataframe \n",
    "idd = idd.to_frame().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#master disaster targets for all years and all ids: \n",
    "#merge with df_yrly \n",
    "y_master = pd.merge(idd, df_yrly_bin, on=['grid_id','year'], how='left').fillna(0)\n",
    "\n",
    "#keep just the binary\n",
    "# y_master.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4007.0\n",
      "4274\n"
     ]
    }
   ],
   "source": [
    "#check: \n",
    "print(y_master['flood_bin'].sum()) #total number of binary flood targets \n",
    "\n",
    "#total number of flood incidents: \n",
    "print(gdis.loc[gdis['disastertype']=='flood'].shape[0])\n",
    "\n",
    "#the two numbers are slightly different, but that's because some country have more than 1 flood per year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_id</th>\n",
       "      <th>year</th>\n",
       "      <th>flood_bin</th>\n",
       "      <th>storm_bin</th>\n",
       "      <th>earthquake_bin</th>\n",
       "      <th>extreme temperature _bin</th>\n",
       "      <th>landslide_bin</th>\n",
       "      <th>volcanic activity_bin</th>\n",
       "      <th>drought_bin</th>\n",
       "      <th>mass movement (dry)_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(133, 200)</td>\n",
       "      <td>1960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(133, 200)</td>\n",
       "      <td>1961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(133, 200)</td>\n",
       "      <td>1962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(133, 200)</td>\n",
       "      <td>1963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(133, 200)</td>\n",
       "      <td>1964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168263</th>\n",
       "      <td>(99, 210)</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168264</th>\n",
       "      <td>(99, 210)</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168265</th>\n",
       "      <td>(99, 210)</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168266</th>\n",
       "      <td>(99, 210)</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168267</th>\n",
       "      <td>(99, 210)</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168268 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           grid_id  year  flood_bin  storm_bin  earthquake_bin  \\\n",
       "0       (133, 200)  1960        0.0        0.0             0.0   \n",
       "1       (133, 200)  1961        0.0        0.0             0.0   \n",
       "2       (133, 200)  1962        0.0        0.0             0.0   \n",
       "3       (133, 200)  1963        0.0        0.0             0.0   \n",
       "4       (133, 200)  1964        0.0        0.0             0.0   \n",
       "...            ...   ...        ...        ...             ...   \n",
       "168263   (99, 210)  2014        0.0        0.0             0.0   \n",
       "168264   (99, 210)  2015        0.0        0.0             0.0   \n",
       "168265   (99, 210)  2016        0.0        0.0             0.0   \n",
       "168266   (99, 210)  2017        0.0        0.0             0.0   \n",
       "168267   (99, 210)  2018        0.0        0.0             0.0   \n",
       "\n",
       "        extreme temperature _bin  landslide_bin  volcanic activity_bin  \\\n",
       "0                            0.0            0.0                    0.0   \n",
       "1                            0.0            0.0                    0.0   \n",
       "2                            0.0            0.0                    0.0   \n",
       "3                            0.0            0.0                    0.0   \n",
       "4                            0.0            0.0                    0.0   \n",
       "...                          ...            ...                    ...   \n",
       "168263                       0.0            0.0                    0.0   \n",
       "168264                       0.0            0.0                    0.0   \n",
       "168265                       0.0            0.0                    0.0   \n",
       "168266                       0.0            0.0                    0.0   \n",
       "168267                       0.0            0.0                    0.0   \n",
       "\n",
       "        drought_bin  mass movement (dry)_bin  \n",
       "0               0.0                      0.0  \n",
       "1               0.0                      0.0  \n",
       "2               0.0                      0.0  \n",
       "3               0.0                      0.0  \n",
       "4               0.0                      0.0  \n",
       "...             ...                      ...  \n",
       "168263          0.0                      0.0  \n",
       "168264          0.0                      0.0  \n",
       "168265          0.0                      0.0  \n",
       "168266          0.0                      0.0  \n",
       "168267          0.0                      0.0  \n",
       "\n",
       "[168268 rows x 10 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct next n year target -> look up this table \n",
    "y_master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add target, next year flood \n",
    "disaster = 'flood'\n",
    "next_n = 1 \n",
    "\n",
    "\n",
    "idd = (37, 108)\n",
    "year = 1960 \n",
    "\n",
    "# #given y_master, search for particular grid_id, year, next_n years \n",
    "# def attach_target(idd, year, disaster, next_n): \n",
    "#     #sub to particular id and year \n",
    "#     y_sub = y_master.loc[ (y_master['grid_id']==idd) & (y_master['year']==year + next_n)]\n",
    "#     if len(y_sub) > 0: \n",
    "#         #sub to particular disaster \n",
    "#         target = y_sub[disaster+'_bin'].iloc[0]\n",
    "#     else:\n",
    "#         target = np.nan\n",
    "#     return target \n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "# attach_target()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8680, 26)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yrly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imbalance 0.08908317580340265\n"
     ]
    }
   ],
   "source": [
    "#attach target for a particular disease for next n years \n",
    "def attach_target(x_df, y_master, disaster, next_n): \n",
    "    y = y_master.copy()\n",
    "    #shift years\n",
    "    y['year'] = y['year'] - next_n\n",
    "    #keep for particular disaster \n",
    "    y = y[['grid_id','year',disaster+'_bin']]\n",
    "    y = y.rename(columns={disaster +'_bin': 'target_' + disaster + '_'+ str(next_n)})\n",
    "    xy_df = pd.merge(x_df, y, on = ['grid_id','year'], how='inner')\n",
    "    return xy_df\n",
    "xy_df = attach_target(df_yrly, y_master, 'flood', 1)\n",
    "\n",
    "print('imbalance', xy_df['target_flood_1'].sum()/len(xy_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_id</th>\n",
       "      <th>year</th>\n",
       "      <th>flood_amt</th>\n",
       "      <th>storm_amt</th>\n",
       "      <th>earthquake_amt</th>\n",
       "      <th>extreme temperature _amt</th>\n",
       "      <th>landslide_amt</th>\n",
       "      <th>volcanic activity_amt</th>\n",
       "      <th>drought_amt</th>\n",
       "      <th>mass movement (dry)_amt</th>\n",
       "      <th>...</th>\n",
       "      <th>mass movement (dry)_ct</th>\n",
       "      <th>flood_bin</th>\n",
       "      <th>storm_bin</th>\n",
       "      <th>earthquake_bin</th>\n",
       "      <th>extreme temperature _bin</th>\n",
       "      <th>landslide_bin</th>\n",
       "      <th>volcanic activity_bin</th>\n",
       "      <th>drought_bin</th>\n",
       "      <th>mass movement (dry)_bin</th>\n",
       "      <th>target_flood_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(37, 108)</td>\n",
       "      <td>1990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(42, 108)</td>\n",
       "      <td>2017</td>\n",
       "      <td>2211.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(42, 111)</td>\n",
       "      <td>1991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(44, 107)</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(44, 107)</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8459</th>\n",
       "      <td>(157, 311)</td>\n",
       "      <td>1998</td>\n",
       "      <td>5818.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8460</th>\n",
       "      <td>(157, 311)</td>\n",
       "      <td>2007</td>\n",
       "      <td>33655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8461</th>\n",
       "      <td>(157, 311)</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8462</th>\n",
       "      <td>(158, 207)</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8463</th>\n",
       "      <td>(159, 45)</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8464 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         grid_id  year  flood_amt  storm_amt  earthquake_amt  \\\n",
       "0      (37, 108)  1990        0.0        0.0             0.0   \n",
       "1      (42, 108)  2017     2211.0        0.0             0.0   \n",
       "2      (42, 111)  1991        0.0        0.0             0.0   \n",
       "3      (44, 107)  2007        0.0        0.0             0.0   \n",
       "4      (44, 107)  2010        0.0        0.0             0.0   \n",
       "...          ...   ...        ...        ...             ...   \n",
       "8459  (157, 311)  1998     5818.0        0.0             0.0   \n",
       "8460  (157, 311)  2007    33655.0        0.0             0.0   \n",
       "8461  (157, 311)  2012        0.0        0.0             0.0   \n",
       "8462  (158, 207)  2005        0.0        0.0             0.0   \n",
       "8463   (159, 45)  2006        0.0        0.0             0.0   \n",
       "\n",
       "      extreme temperature _amt  landslide_amt  volcanic activity_amt  \\\n",
       "0                          0.0            0.0                    0.0   \n",
       "1                          0.0            0.0                    0.0   \n",
       "2                          0.0            0.0                    0.0   \n",
       "3                          0.0            0.0                    0.0   \n",
       "4                          0.0            0.0                    0.0   \n",
       "...                        ...            ...                    ...   \n",
       "8459                       0.0            0.0                    0.0   \n",
       "8460                       0.0            0.0                    0.0   \n",
       "8461                       0.0            0.0                    0.0   \n",
       "8462                       0.0            0.0                    0.0   \n",
       "8463                       0.0            0.0                    0.0   \n",
       "\n",
       "      drought_amt  mass movement (dry)_amt  ...  mass movement (dry)_ct  \\\n",
       "0             0.0                      0.0  ...                       0   \n",
       "1             0.0                      0.0  ...                       0   \n",
       "2             0.0                      0.0  ...                       0   \n",
       "3             0.0                      0.0  ...                       0   \n",
       "4             0.0                      0.0  ...                       0   \n",
       "...           ...                      ...  ...                     ...   \n",
       "8459          0.0                      0.0  ...                       0   \n",
       "8460          0.0                      0.0  ...                       0   \n",
       "8461          0.0                      0.0  ...                       0   \n",
       "8462          0.0                      0.0  ...                       0   \n",
       "8463          0.0                      0.0  ...                       0   \n",
       "\n",
       "      flood_bin  storm_bin  earthquake_bin  extreme temperature _bin  \\\n",
       "0             1          0               0                         0   \n",
       "1             1          0               0                         0   \n",
       "2             0          0               0                         0   \n",
       "3             0          0               1                         0   \n",
       "4             0          0               0                         1   \n",
       "...         ...        ...             ...                       ...   \n",
       "8459          1          0               0                         0   \n",
       "8460          1          0               0                         0   \n",
       "8461          0          0               0                         1   \n",
       "8462          1          0               0                         0   \n",
       "8463          1          0               0                         0   \n",
       "\n",
       "      landslide_bin  volcanic activity_bin  drought_bin  \\\n",
       "0                 0                      0            0   \n",
       "1                 0                      0            0   \n",
       "2                 0                      1            0   \n",
       "3                 0                      0            0   \n",
       "4                 0                      0            0   \n",
       "...             ...                    ...          ...   \n",
       "8459              0                      0            0   \n",
       "8460              0                      0            0   \n",
       "8461              0                      0            0   \n",
       "8462              0                      0            0   \n",
       "8463              0                      0            0   \n",
       "\n",
       "      mass movement (dry)_bin  target_flood_1  \n",
       "0                           0             0.0  \n",
       "1                           0             0.0  \n",
       "2                           0             0.0  \n",
       "3                           0             0.0  \n",
       "4                           0             0.0  \n",
       "...                       ...             ...  \n",
       "8459                        0             0.0  \n",
       "8460                        0             0.0  \n",
       "8461                        0             0.0  \n",
       "8462                        0             0.0  \n",
       "8463                        0             0.0  \n",
       "\n",
       "[8464 rows x 27 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of grid_ids with historical flood 1798\n",
      "106082\n"
     ]
    }
   ],
   "source": [
    "#step 1: filter xy_df to those grid_ids with previous flooding history \n",
    "agg = xy_df.groupby('grid_id').agg({'flood_bin':'max'})\n",
    "grid_id_ls = agg.loc[agg['flood_bin']==1].index.tolist()\n",
    "print('no of grid_ids with historical flood', len(grid_id_ls))\n",
    "xy_df_sub = xy_df.loc[xy_df['grid_id'].isin(grid_id_ls)]\n",
    "\n",
    "#step 2: interpolate years to record all years, fill with 0 without any flood using idd \n",
    "#create multi-index: each grid id, spanning over the years \n",
    "year_id = np.arange(1960, 2019, 1) \n",
    "idd = pd.MultiIndex.from_product([grid_id_ls, year_id],\n",
    "                           names=['grid_id', 'year'])\n",
    "\n",
    "#length should be |years| * |grid_ids| \n",
    "print(len(idd))\n",
    "#get dataframe \n",
    "idd = idd.to_frame().reset_index(drop=True)\n",
    "xy_df_sub = pd.merge(idd, xy_df_sub, on=['grid_id','year'], how='left').fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split training and testing \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "x = xy_df_sub.drop(xy_df_sub.filter(regex='target').columns, axis=1)#drop target col \n",
    "x = x.select_dtypes(['number'])#drop index col\n",
    "y = xy_df_sub.filter(regex='target') #filter to cols containing target \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'flood_amt', 'storm_amt', 'earthquake_amt',\n",
       "       'extreme temperature _amt', 'landslide_amt', 'volcanic activity_amt',\n",
       "       'drought_amt', 'mass movement (dry)_amt', 'flood_ct', 'storm_ct',\n",
       "       'earthquake_ct', 'extreme temperature _ct', 'landslide_ct',\n",
       "       'volcanic activity_ct', 'drought_ct', 'mass movement (dry)_ct',\n",
       "       'flood_bin', 'storm_bin', 'earthquake_bin', 'extreme temperature _bin',\n",
       "       'landslide_bin', 'volcanic activity_bin', 'drought_bin',\n",
       "       'mass movement (dry)_bin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imbalance target_flood_1    0.007541\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>flood_amt</th>\n",
       "      <th>storm_amt</th>\n",
       "      <th>earthquake_amt</th>\n",
       "      <th>extreme temperature _amt</th>\n",
       "      <th>landslide_amt</th>\n",
       "      <th>volcanic activity_amt</th>\n",
       "      <th>drought_amt</th>\n",
       "      <th>mass movement (dry)_amt</th>\n",
       "      <th>flood_ct</th>\n",
       "      <th>...</th>\n",
       "      <th>drought_ct</th>\n",
       "      <th>mass movement (dry)_ct</th>\n",
       "      <th>flood_bin</th>\n",
       "      <th>storm_bin</th>\n",
       "      <th>earthquake_bin</th>\n",
       "      <th>extreme temperature _bin</th>\n",
       "      <th>landslide_bin</th>\n",
       "      <th>volcanic activity_bin</th>\n",
       "      <th>drought_bin</th>\n",
       "      <th>mass movement (dry)_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4346</th>\n",
       "      <td>1999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102992</th>\n",
       "      <td>1997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101847</th>\n",
       "      <td>1973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85611</th>\n",
       "      <td>1962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41398</th>\n",
       "      <td>1999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        year  flood_amt  storm_amt  earthquake_amt  extreme temperature _amt  \\\n",
       "4346    1999        0.0        0.0             0.0                       0.0   \n",
       "102992  1997        0.0        0.0             0.0                       0.0   \n",
       "101847  1973        0.0        0.0             0.0                       0.0   \n",
       "85611   1962        0.0        0.0             0.0                       0.0   \n",
       "41398   1999        0.0        0.0             0.0                       0.0   \n",
       "\n",
       "        landslide_amt  volcanic activity_amt  drought_amt  \\\n",
       "4346              0.0                    0.0          0.0   \n",
       "102992            0.0                    0.0          0.0   \n",
       "101847            0.0                    0.0          0.0   \n",
       "85611             0.0                    0.0          0.0   \n",
       "41398             0.0                    0.0          0.0   \n",
       "\n",
       "        mass movement (dry)_amt  flood_ct  ...  drought_ct  \\\n",
       "4346                        0.0       0.0  ...         0.0   \n",
       "102992                      0.0       0.0  ...         0.0   \n",
       "101847                      0.0       0.0  ...         0.0   \n",
       "85611                       0.0       0.0  ...         0.0   \n",
       "41398                       0.0       0.0  ...         0.0   \n",
       "\n",
       "        mass movement (dry)_ct  flood_bin  storm_bin  earthquake_bin  \\\n",
       "4346                       0.0        0.0        0.0             0.0   \n",
       "102992                     0.0        0.0        0.0             0.0   \n",
       "101847                     0.0        0.0        0.0             0.0   \n",
       "85611                      0.0        0.0        0.0             0.0   \n",
       "41398                      0.0        0.0        0.0             0.0   \n",
       "\n",
       "        extreme temperature _bin  landslide_bin  volcanic activity_bin  \\\n",
       "4346                         0.0            0.0                    0.0   \n",
       "102992                       0.0            0.0                    0.0   \n",
       "101847                       0.0            0.0                    0.0   \n",
       "85611                        0.0            0.0                    0.0   \n",
       "41398                        0.0            0.0                    0.0   \n",
       "\n",
       "        drought_bin  mass movement (dry)_bin  \n",
       "4346            0.0                      0.0  \n",
       "102992          0.0                      0.0  \n",
       "101847          0.0                      0.0  \n",
       "85611           0.0                      0.0  \n",
       "41398           0.0                      0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check data imbalance \n",
    "print('imbalance', y_train.sum()/len(y_train))\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run some models \n",
    "\n",
    "#try classification\n",
    "def run_logreg(x_train, y_train, x_test):\n",
    "    print('running log reg...')\n",
    "    gs_metric = 'roc_auc'\n",
    "    cv_folds = 3\n",
    "    param_grid = {'C': np.arange(0.0, 1, 0.2), 'penalty': ['l2','l1']}\n",
    "    est = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "    #grid search\n",
    "    gs = GridSearchCV(estimator = est, param_grid=param_grid, scoring=gs_metric, cv= cv_folds, verbose=0)\n",
    "    gs.fit(x_train, y_train)\n",
    "\n",
    "    #training auc\n",
    "    print(\"Train AUC: \", metrics.roc_auc_score(y_train, gs.predict_proba(x_train)[:,1]))\n",
    "\n",
    "    y_pred_prob = gs.predict_proba(x_test)\n",
    "    y_pred = gs.predict(x_test)\n",
    "\n",
    "    return y_pred, y_pred_prob[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running log reg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:760: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  args=(X, target, 1. / C, sample_weight),\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:123: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  out = -np.sum(sample_weight * log_logistic(yz)) + .5 * alpha * np.dot(w, w)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:128: RuntimeWarning: invalid value encountered in multiply\n",
      "  grad[:n_features] = safe_sparse_dot(X.T, z0) + alpha * w\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1406, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 758, in _logistic_regression_path\n",
      "    opt_res = optimize.minimize(\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/_minimize.py\", line 619, in minimize\n",
      "    return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/lbfgsb.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 260, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 226, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 133, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 130, in fun_wrapped\n",
      "    return fun(x, *args)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 74, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 68, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 123, in _logistic_loss_and_grad\n",
      "    out = -np.sum(sample_weight * log_logistic(yz)) + .5 * alpha * np.dot(w, w)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/utils/extmath.py\", line 581, in log_logistic\n",
      "    X = check_array(X, dtype=np.float64)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:760: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  args=(X, target, 1. / C, sample_weight),\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:123: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  out = -np.sum(sample_weight * log_logistic(yz)) + .5 * alpha * np.dot(w, w)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:128: RuntimeWarning: invalid value encountered in multiply\n",
      "  grad[:n_features] = safe_sparse_dot(X.T, z0) + alpha * w\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1406, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 758, in _logistic_regression_path\n",
      "    opt_res = optimize.minimize(\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/_minimize.py\", line 619, in minimize\n",
      "    return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/lbfgsb.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 260, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 226, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 133, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 130, in fun_wrapped\n",
      "    return fun(x, *args)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 74, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 68, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 123, in _logistic_loss_and_grad\n",
      "    out = -np.sum(sample_weight * log_logistic(yz)) + .5 * alpha * np.dot(w, w)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/utils/extmath.py\", line 581, in log_logistic\n",
      "    X = check_array(X, dtype=np.float64)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:760: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  args=(X, target, 1. / C, sample_weight),\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:123: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  out = -np.sum(sample_weight * log_logistic(yz)) + .5 * alpha * np.dot(w, w)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:128: RuntimeWarning: invalid value encountered in multiply\n",
      "  grad[:n_features] = safe_sparse_dot(X.T, z0) + alpha * w\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1406, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 758, in _logistic_regression_path\n",
      "    opt_res = optimize.minimize(\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/_minimize.py\", line 619, in minimize\n",
      "    return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/lbfgsb.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 260, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 226, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 133, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 130, in fun_wrapped\n",
      "    return fun(x, *args)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 74, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 68, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 123, in _logistic_loss_and_grad\n",
      "    out = -np.sum(sample_weight * log_logistic(yz)) + .5 * alpha * np.dot(w, w)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/utils/extmath.py\", line 581, in log_logistic\n",
      "    X = check_array(X, dtype=np.float64)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.83553124        nan 0.83550367        nan\n",
      " 0.83551036        nan 0.83556993        nan]\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC:  0.5527291768030875\n",
      "Test AUC 0.583750697791441\n"
     ]
    }
   ],
   "source": [
    "y_pred, y_pred_prob = run_logreg(x_train, y_train, x_test)\n",
    "print('Test AUC', metrics.roc_auc_score(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-ec34ccd4196c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0myear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattach_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisaster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'grid_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0midd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnext_n\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "# df_yrly\n",
    "\n",
    "# for index, row in df_yrly.iterrows():\n",
    "#     y = df_yrly[['grid_id','year']]\n",
    "#     idd = row['grid_id']\n",
    "#     year = row['year']\n",
    "#     target = attach_target(idd, year, disaster, next_n)\n",
    "#     y.loc[(y['grid_id']==idd) & (y['year']==year)]['target_' + next_n] = target \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding climate data:\n",
    "- https://psl.noaa.gov/data/gridded/ \n",
    "- https://psl.noaa.gov/data/gridded/data.cmap.html \n",
    "- https://confluence.ecmwf.int/display/CKB/ERA5-Land%3A+data+documentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "import xarray as xr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>precip</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">88.75</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1.25</th>\n",
       "      <th>1979-01-01</th>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-02-01</th>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-03-01</th>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-04-01</th>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979-05-01</th>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">-88.75</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">358.75</th>\n",
       "      <th>2022-04-01</th>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-01</th>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-01</th>\n",
       "      <td>3.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-01</th>\n",
       "      <td>17.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5432832 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          precip\n",
       "lat    lon    time              \n",
       " 88.75 1.25   1979-01-01    0.21\n",
       "              1979-02-01    0.30\n",
       "              1979-03-01    0.15\n",
       "              1979-04-01    0.22\n",
       "              1979-05-01    0.30\n",
       "...                          ...\n",
       "-88.75 358.75 2022-04-01    2.90\n",
       "              2022-05-01    0.27\n",
       "              2022-06-01    3.13\n",
       "              2022-07-01   17.17\n",
       "              2022-08-01    0.01\n",
       "\n",
       "[5432832 rows x 1 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import monthly precipation data \n",
    "ds = xr.open_dataset('../data/precip.mon.mean.nc')\n",
    "df = ds.to_dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4_CLASSIC data model, file format HDF5):\n",
      "    Conventions: COARDS\n",
      "    title: CPC Merged Analysis of Precipitation (includes NCEP Reanalysis)\n",
      "    platform: Analyses\n",
      "    source: ftp ftp.cpc.ncep.noaa.gov precip/cmap/monthly\n",
      "    dataset_title: CPC Merged Analysis of Precipitation\n",
      "    documentation: https://www.esrl.noaa.gov/psd/data/gridded/data.cmap.html\n",
      "    date_modified: 26 Feb 2019\n",
      "    References: https://www.psl.noaa.gov/data/gridded/data.cmap.html\n",
      "    version: V2209\n",
      "    history: update 09/2022 V2209\n",
      "    data_modified: 2022-09-09\n",
      "    dimensions(sizes): lon(144), lat(72), time(524)\n",
      "    variables(dimensions): float32 lat(lat), float32 lon(lon), float64 time(time), float32 precip(time, lat, lon)\n",
      "    groups: \n"
     ]
    }
   ],
   "source": [
    "f = netCDF4.Dataset('../data/precip.mon.mean.nc')\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['lat', 'lon', 'time', 'precip'])\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float64 time(time)\n",
      "    units: hours since 1800-01-01 00:00:0.0\n",
      "    long_name: Time\n",
      "    delta_t: 0000-01-00 00:00:00\n",
      "    avg_period: 0000-01-00 00:00:00\n",
      "    standard_name: time\n",
      "    axis: T\n",
      "    actual_range: [1569072. 1951104.]\n",
      "unlimited dimensions: time\n",
      "current shape = (524,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n"
     ]
    }
   ],
   "source": [
    "print(f.variables.keys()) # get all variable names\n",
    "time = f.variables['time']\n",
    "print(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add text data from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "#doc: https://pypi.org/project/wikipedia/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #set up wiki api \n",
    "# wiki_wiki = wikipediaapi.Wikipedia('en')\n",
    "\n",
    "# location = 'Anhui'\n",
    "# page_py = wiki_wiki.page('Anhui')\n",
    "# section_py = page_py.section_by_title('Geography')\n",
    "# txt= section_py.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GitHub, Inc. () is an Internet hosting service for software development and version control using Git. It provides the distributed version control of Git plus access control, bug tracking, software feature requests, task management, continuous integration, and wikis for every project. Headquartered in California, it has been a subsidiary of Microsoft since 2018.It is commonly used to host open source software development projects. As of June 2022, GitHub reported having over 83 million developers  and more than 200 million repositories, including at least 28 million public repositories. It is the largest source code host as of November 2021.'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# page_py.sections\n",
    "wikipedia.summary(\"GitHub\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grid_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(37, 108)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(117, 244)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(117, 236)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(117, 235)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(117, 102)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(110, 108)</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(105, 301)</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(121, 283)</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(115, 282)</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(113, 295)</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2852 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            location\n",
       "grid_id             \n",
       "(37, 108)          1\n",
       "(117, 244)         1\n",
       "(117, 236)         1\n",
       "(117, 235)         1\n",
       "(117, 102)         1\n",
       "...              ...\n",
       "(110, 108)        22\n",
       "(105, 301)        22\n",
       "(121, 283)        23\n",
       "(115, 282)        23\n",
       "(113, 295)        34\n",
       "\n",
       "[2852 rows x 1 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count number of locations in each grid_id \n",
    "gdis.groupby('grid_id').agg({'location':'nunique'}).sort_values(by='location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>country</th>\n",
       "      <th>iso3</th>\n",
       "      <th>gwno</th>\n",
       "      <th>year</th>\n",
       "      <th>geo_id</th>\n",
       "      <th>geolocation</th>\n",
       "      <th>level</th>\n",
       "      <th>adm1</th>\n",
       "      <th>adm2</th>\n",
       "      <th>...</th>\n",
       "      <th>location</th>\n",
       "      <th>historical</th>\n",
       "      <th>hist_country</th>\n",
       "      <th>disastertype</th>\n",
       "      <th>disasterno</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>lat_grid</th>\n",
       "      <th>lon_grid</th>\n",
       "      <th>grid_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7075</th>\n",
       "      <td>02-129</td>\n",
       "      <td>China</td>\n",
       "      <td>CHN</td>\n",
       "      <td>710.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>30787</td>\n",
       "      <td>Shenzhen</td>\n",
       "      <td>2</td>\n",
       "      <td>Guangdong</td>\n",
       "      <td>Shenzhen</td>\n",
       "      <td>...</td>\n",
       "      <td>Shenzhen</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>storm</td>\n",
       "      <td>2017-0352</td>\n",
       "      <td>22.654701</td>\n",
       "      <td>114.135194</td>\n",
       "      <td>113</td>\n",
       "      <td>295</td>\n",
       "      <td>(113, 295)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30259</th>\n",
       "      <td>01-576</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999.0</td>\n",
       "      <td>1960</td>\n",
       "      <td>29833</td>\n",
       "      <td>North</td>\n",
       "      <td>1</td>\n",
       "      <td>North</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>New Territories</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flood</td>\n",
       "      <td>1960-0040</td>\n",
       "      <td>22.515480</td>\n",
       "      <td>114.185724</td>\n",
       "      <td>113</td>\n",
       "      <td>295</td>\n",
       "      <td>(113, 295)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30263</th>\n",
       "      <td>01-578</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999.0</td>\n",
       "      <td>1961</td>\n",
       "      <td>29837</td>\n",
       "      <td>North</td>\n",
       "      <td>1</td>\n",
       "      <td>North</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>New Territories</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flood</td>\n",
       "      <td>1961-0030</td>\n",
       "      <td>22.515480</td>\n",
       "      <td>114.185724</td>\n",
       "      <td>113</td>\n",
       "      <td>295</td>\n",
       "      <td>(113, 295)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30270</th>\n",
       "      <td>01-580</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999.0</td>\n",
       "      <td>1962</td>\n",
       "      <td>29844</td>\n",
       "      <td>Tai Po</td>\n",
       "      <td>1</td>\n",
       "      <td>Tai Po</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Tai Po</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>storm</td>\n",
       "      <td>1962-0015</td>\n",
       "      <td>22.453359</td>\n",
       "      <td>114.239223</td>\n",
       "      <td>113</td>\n",
       "      <td>295</td>\n",
       "      <td>(113, 295)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30273</th>\n",
       "      <td>01-583</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>29847</td>\n",
       "      <td>North</td>\n",
       "      <td>1</td>\n",
       "      <td>North</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>New Territories</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>storm</td>\n",
       "      <td>1965-0085</td>\n",
       "      <td>22.515480</td>\n",
       "      <td>114.185724</td>\n",
       "      <td>113</td>\n",
       "      <td>295</td>\n",
       "      <td>(113, 295)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id    country iso3   gwno  year  geo_id geolocation  level  \\\n",
       "7075   02-129      China  CHN  710.0  2017   30787    Shenzhen      2   \n",
       "30259  01-576  Hong Kong  NaN  999.0  1960   29833       North      1   \n",
       "30263  01-578  Hong Kong  NaN  999.0  1961   29837       North      1   \n",
       "30270  01-580  Hong Kong  NaN  999.0  1962   29844      Tai Po      1   \n",
       "30273  01-583  Hong Kong  NaN  999.0  1965   29847       North      1   \n",
       "\n",
       "            adm1      adm2  ...         location historical  hist_country  \\\n",
       "7075   Guangdong  Shenzhen  ...         Shenzhen          0           NaN   \n",
       "30259      North       NaN  ...  New Territories          0           NaN   \n",
       "30263      North       NaN  ...  New Territories          0           NaN   \n",
       "30270     Tai Po       NaN  ...           Tai Po          0           NaN   \n",
       "30273      North       NaN  ...  New Territories          0           NaN   \n",
       "\n",
       "      disastertype disasterno   latitude   longitude  lat_grid  lon_grid  \\\n",
       "7075         storm  2017-0352  22.654701  114.135194       113       295   \n",
       "30259        flood  1960-0040  22.515480  114.185724       113       295   \n",
       "30263        flood  1961-0030  22.515480  114.185724       113       295   \n",
       "30270        storm  1962-0015  22.453359  114.239223       113       295   \n",
       "30273        storm  1965-0085  22.515480  114.185724       113       295   \n",
       "\n",
       "          grid_id  \n",
       "7075   (113, 295)  \n",
       "30259  (113, 295)  \n",
       "30263  (113, 295)  \n",
       "30270  (113, 295)  \n",
       "30273  (113, 295)  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the grid with most regions \n",
    "gdis.loc[gdis['grid_id']==(113, 295)].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grid_id\n",
       "(37, 108)                                        [Punta Arenas]\n",
       "(42, 108)                                          [ O'Higgins]\n",
       "(42, 111)                                          [Santa Cruz]\n",
       "(44, 107)     [Aysen region, Aisen del Gral. Carlos Ibañez d...\n",
       "(44, 349)                                  [Gore, Invercargill]\n",
       "                                    ...                        \n",
       "(156, 217)                            [Eastern Maritime region]\n",
       "(157, 157)                                           [Flateyri]\n",
       "(157, 311)      [Sakha-Yakutia, Yakutia,  Sakha Rep. provinces]\n",
       "(158, 207)                                    [Finnish Lapland]\n",
       "(159, 45)                                             [Aklavik]\n",
       "Name: location, Length: 2852, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for each grid, get the most common location \n",
    "#process grid_id and location pairs \n",
    "grid_loc = gdis[['grid_id','location']]\n",
    "#keep the first location in each grid \n",
    "# grid_loc = grid_loc.drop_duplicates(subset=['grid_id'], keep='first')\n",
    "grid_loc.groupby('grid_id')['location'].agg(list)\n",
    "# grid_loc['location'] = grid_loc['location'].str.split(',').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO: deal with duplicated locations -> use the list to attach txt, keep if geography is present. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_id</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(133, 200)</td>\n",
       "      <td>Ana E Malit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(73, 196)</td>\n",
       "      <td>Onjiva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(74, 196)</td>\n",
       "      <td>Evale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(74, 196)</td>\n",
       "      <td>Evale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(113, 272)</td>\n",
       "      <td>Hatiya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39938</th>\n",
       "      <td>(86, 325)</td>\n",
       "      <td>Manam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39939</th>\n",
       "      <td>(99, 210)</td>\n",
       "      <td>Unity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39945</th>\n",
       "      <td>(99, 207)</td>\n",
       "      <td>Bar El Ghazal Province</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39946</th>\n",
       "      <td>(104, 224)</td>\n",
       "      <td>Taiz-Torba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39947</th>\n",
       "      <td>(106, 119)</td>\n",
       "      <td>St. Joseph province</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9924 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          grid_id                location\n",
       "0      (133, 200)             Ana E Malit\n",
       "2       (73, 196)                  Onjiva\n",
       "3       (74, 196)                   Evale\n",
       "6       (74, 196)                   Evale\n",
       "8      (113, 272)                  Hatiya\n",
       "...           ...                     ...\n",
       "39938   (86, 325)                   Manam\n",
       "39939   (99, 210)                   Unity\n",
       "39945   (99, 207)  Bar El Ghazal Province\n",
       "39946  (104, 224)              Taiz-Torba\n",
       "39947  (106, 119)     St. Joseph province\n",
       "\n",
       "[9924 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Anhui is topographically diverse. The north is part of the North China Plain while the north-central areas are part of the Huai River watershed. Both regions are flat, and densely populated. The land becomes more uneven further south, with the Dabie Mountains occupying much of southwestern Anhui and a series of hills and ranges cutting through southeastern Anhui, between which is the Yangtze River. The highest peak in Anhui is Lotus Peak, part of Huangshan in southeastern Anhui. It has an altitude of 1873 m.\\nMajor rivers include the Huai River in the north and the Yangtze in the south. The largest lake is Lake Chaohu situated in the center of the province, with an area of about 800 km2 (310 sq mi). The southeastern part of the province near the Yangtze River has many lakes as well.\\nAs with topography, the province differs in climate from north to south. The north is more temperate with more distinct seasons. January temperatures average at around −1 to 2 °C north of the Huai River, and 0 to 3 °C south of the Huai River; in July temperatures average 27 °C or above. Plum rains occur in June and July and may cause flooding.\\nAnhui has 16 cities. Economically, top 3 cities are, Hefei, Wuhu and Anqing.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#attach wikipedia texts \n",
    "\n",
    "\n",
    "location = 'Anhui'\n",
    "def get_wiki(location):\n",
    "#initiaise txt with empty string \n",
    "    txt= np.nan \n",
    "    #search similar ords in wikipedia \n",
    "    similar_words = wikipedia.search(location)   \n",
    "    for similar in similar_words:\n",
    "        #try getting geographical information \n",
    "        try:\n",
    "            txt_geo = wikipedia.WikipediaPage(similar).section('Geography')\n",
    "        except:\n",
    "            txt_geo = np.nan\n",
    "        #\n",
    "        if txt_geo != np.nan:\n",
    "            txt = txt_geo\n",
    "            break \n",
    "    return txt \n",
    "\n",
    "get_wiki(location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Greenwell Matongo is a suburb in the city of Windhoek, the capital city of Namibia. Greenwell Matongo is named after a liberation fighter, Greenwell Simasiku Matongo, who was born in 1945.  Matongo was a former People Liberation Army of Namibia (PLAN), who died in combat between United National Union of the Total Indipendence of Angola (UNITA) and South African forces at Angola in Onjiva in 15 June 1979. This residential area is known for its many shebeens and bars.Despite its synonymous association with informal entertainment areas, Greenwell Matongo is host to a community library, the Greenwell Matongo Community Library for the benefit of its residents.'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#attach wikipedia texts, using summary if no geographical information is found \n",
    "def get_wiki2(location):\n",
    "#initiaise txt with empty string \n",
    "    txt= None \n",
    "    \n",
    "    #search similar words in wikipedia \n",
    "    similar_words = wikipedia.search(location)   \n",
    "    \n",
    "    #first try getting geographical information looping over similar words \n",
    "    for similar in similar_words:\n",
    "        try: \n",
    "            txt = wikipedia.WikipediaPage(similar).section('Geography')\n",
    "        except: \n",
    "            pass \n",
    "        #break the loop if one of the similar words have geography section \n",
    "        if txt is not None:\n",
    "            break \n",
    "    \n",
    "    #if no Geography section among all words, use the summary section \n",
    "    if txt is None: \n",
    "        for similar in similar_words:\n",
    "            try: \n",
    "                txt = wikipedia.summary(similar)\n",
    "            except: \n",
    "                pass \n",
    "            #break the loop if one of the similar words have geography section \n",
    "            if txt is not None:\n",
    "                break \n",
    "        \n",
    "    return txt \n",
    "\n",
    "get_wiki2('Onjiva')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "101\n",
      "201\n",
      "301\n",
      "401\n",
      "501\n",
      "601\n",
      "701\n",
      "801\n",
      "901\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    if i in range(1,1000,100):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pandas/core/indexing.py:1598: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = infer_fill_value(value)\n",
      "/usr/local/lib/python3.9/site-packages/pandas/core/indexing.py:1719: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /usr/local/lib/python3.9/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "201\n",
      "301\n",
      "401\n",
      "501\n",
      "601\n",
      "701\n",
      "801\n",
      "901\n",
      "1001\n",
      "1101\n",
      "1201\n",
      "1301\n",
      "1401\n",
      "1501\n",
      "1601\n",
      "1701\n",
      "1801\n",
      "1901\n",
      "2001\n",
      "2101\n",
      "2201\n",
      "2301\n",
      "2401\n",
      "2501\n",
      "2601\n",
      "2701\n",
      "2801\n",
      "2901\n",
      "3001\n",
      "3101\n",
      "3201\n",
      "3301\n",
      "3401\n",
      "3501\n",
      "3601\n",
      "3701\n",
      "3801\n",
      "3901\n",
      "4001\n",
      "4101\n",
      "4201\n",
      "4301\n",
      "4401\n",
      "4501\n",
      "4601\n",
      "4701\n",
      "4801\n",
      "4901\n",
      "5001\n",
      "5101\n",
      "5201\n",
      "5301\n",
      "5401\n",
      "5501\n",
      "5601\n",
      "5701\n",
      "5801\n",
      "5901\n",
      "6001\n",
      "6101\n",
      "6201\n",
      "6301\n",
      "6401\n",
      "6501\n",
      "6601\n",
      "6701\n",
      "6801\n",
      "6901\n",
      "7001\n",
      "7101\n",
      "7201\n",
      "7301\n",
      "7401\n",
      "7501\n",
      "7601\n",
      "7701\n",
      "7801\n",
      "7901\n",
      "8001\n",
      "8101\n",
      "8201\n",
      "8301\n",
      "8401\n",
      "8501\n",
      "8601\n",
      "8701\n",
      "8801\n",
      "8901\n",
      "9001\n",
      "9101\n",
      "9201\n",
      "9301\n",
      "9401\n",
      "9501\n",
      "9601\n",
      "9701\n",
      "9801\n",
      "9901\n"
     ]
    }
   ],
   "source": [
    "i = 0 \n",
    "for index, row in grid_loc.iterrows():\n",
    "    loc = row['location']\n",
    "    txt = get_wiki2(loc)\n",
    "    grid_loc.loc[index, 'txt'] = txt \n",
    "    \n",
    "    i +=1 \n",
    "#     #save output every 100 iterations \n",
    "#     if i in range(1,10000,100):\n",
    "#         print(i)\n",
    "#         file = open('../data/grid_loc_txt.pkl', 'wb')\n",
    "#         # dump information to that file\n",
    "#         pickle.dump(grid_loc, file )\n",
    "#         # close the file\n",
    "#         file.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = open('../data/grid_loc_txt.pkl', 'wb')\n",
    "# # dump information to that file\n",
    "# pickle.dump(grid_loc,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# dump information to that file\n",
    "grid_txt = pickle.load(open('../data/grid_loc_txt.pkl', 'rb'))\n",
    "# close the file\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "421"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_txt['txt'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_id</th>\n",
       "      <th>location</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(133, 200)</td>\n",
       "      <td>Ana E Malit</td>\n",
       "      <td>The Ana Malit region is located between Lake S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(73, 196)</td>\n",
       "      <td>Onjiva</td>\n",
       "      <td>Greenwell Matongo is a suburb in the city of W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(74, 196)</td>\n",
       "      <td>Evale</td>\n",
       "      <td>Evil, in a general sense, is defined as the op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(74, 196)</td>\n",
       "      <td>Evale</td>\n",
       "      <td>Evil, in a general sense, is defined as the op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(113, 272)</td>\n",
       "      <td>Hatiya</td>\n",
       "      <td>Hatiya Upazila is located at 22.3667°N 91.1250...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39938</th>\n",
       "      <td>(86, 325)</td>\n",
       "      <td>Manam</td>\n",
       "      <td>Mam is a 2010 British short film by writer Viv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39939</th>\n",
       "      <td>(99, 210)</td>\n",
       "      <td>Unity</td>\n",
       "      <td>Unity is a cross-platform game engine develope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39945</th>\n",
       "      <td>(99, 207)</td>\n",
       "      <td>Bar El Ghazal Province</td>\n",
       "      <td>South Sudan lies between latitudes 3° and 13°N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39946</th>\n",
       "      <td>(104, 224)</td>\n",
       "      <td>Taiz-Torba</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39947</th>\n",
       "      <td>(106, 119)</td>\n",
       "      <td>St. Joseph province</td>\n",
       "      <td>The Sisters of St. Joseph of Saint-Marc are a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9924 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          grid_id                location  \\\n",
       "0      (133, 200)             Ana E Malit   \n",
       "2       (73, 196)                  Onjiva   \n",
       "3       (74, 196)                   Evale   \n",
       "6       (74, 196)                   Evale   \n",
       "8      (113, 272)                  Hatiya   \n",
       "...           ...                     ...   \n",
       "39938   (86, 325)                   Manam   \n",
       "39939   (99, 210)                   Unity   \n",
       "39945   (99, 207)  Bar El Ghazal Province   \n",
       "39946  (104, 224)              Taiz-Torba   \n",
       "39947  (106, 119)     St. Joseph province   \n",
       "\n",
       "                                                     txt  \n",
       "0      The Ana Malit region is located between Lake S...  \n",
       "2      Greenwell Matongo is a suburb in the city of W...  \n",
       "3      Evil, in a general sense, is defined as the op...  \n",
       "6      Evil, in a general sense, is defined as the op...  \n",
       "8      Hatiya Upazila is located at 22.3667°N 91.1250...  \n",
       "...                                                  ...  \n",
       "39938  Mam is a 2010 British short film by writer Viv...  \n",
       "39939  Unity is a cross-platform game engine develope...  \n",
       "39945  South Sudan lies between latitudes 3° and 13°N...  \n",
       "39946                                               None  \n",
       "39947  The Sisters of St. Joseph of Saint-Marc are a ...  \n",
       "\n",
       "[9924 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #here save the processed file to pickle \n",
    "# import pickle \n",
    "# file = open('../data/grid_loc_txt.pkl', 'wb')\n",
    "# # dump information to that file\n",
    "# pickle.dump(grid_loc, file )\n",
    "# # close the file\n",
    "# file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pandas/core/indexing.py:1719: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Ana Malit region is located between Lake Skadar and Lake Šas. It is divided by the Albania/Montenegro border (Ana e Malit is in Albania) and the Adriatic Sea.\n",
      "In the north is Mount Lipoja and from the other side are the villages and region of Kraja with Ostros as center, which is also Albanian. In the south Anamalit's border goes across the Medjurecje River through Krytha, Kllezna, and up to Lake Shasi which belongs to Anamali, to the village of Saint George and the Albanian border. In the east is the Albanian/Montenegrin border and a large part of Anamalit continues up to the city of Scodra (Scutari).\n",
      "It's villages include:\n",
      "\n",
      "Vladimir\n",
      "Kravari\n",
      "Krytha\n",
      "Kllezna\n",
      "Milla\n",
      "Lulaj\n",
      "Shasi\n",
      "Amulli\n",
      "Gjonza\n",
      "Dragina\n",
      "Brajsha\n",
      "Sukubina\n",
      "Selita\n",
      "Shtodra\n",
      "Rashtisha.\n",
      "None\n",
      "None\n",
      "None\n",
      "Hatiya Upazila is located at 22.3667°N 91.1250°E﻿ / 22.3667; 91.1250. It has 47,970 household units and a total area of 2,100 square kilometres. It is bounded by the Subarnachar Upazila to its north, Ramgati Upazila to its northwest, the Bay of Bengal to the east and south, and Manpura Upazila to its west.\n"
     ]
    }
   ],
   "source": [
    "#attach location for each grid_location pair \n",
    "for loc in grid_loc['location'].tolist():\n",
    "    #get wiki text \n",
    "    txt = get_wiki(loc) \n",
    "    #record data \n",
    "    grid_loc.loc[grid_loc['location']==loc, 'txt'] = txt \n",
    "    print(txt)\n",
    "    \n",
    "    \n",
    "# grid_loc['wiki'] = grid_loc.apply(lambda row: attach_wiki(row['location']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_id</th>\n",
       "      <th>location</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(133, 200)</td>\n",
       "      <td>Ana E Malit</td>\n",
       "      <td>The Ana Malit region is located between Lake S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(73, 196)</td>\n",
       "      <td>Onjiva</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(74, 196)</td>\n",
       "      <td>Evale</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(74, 196)</td>\n",
       "      <td>Evale</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(113, 272)</td>\n",
       "      <td>Hatiya</td>\n",
       "      <td>Hatiya Upazila is located at 22.3667°N 91.1250...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39938</th>\n",
       "      <td>(86, 325)</td>\n",
       "      <td>Manam</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39939</th>\n",
       "      <td>(99, 210)</td>\n",
       "      <td>Unity</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39945</th>\n",
       "      <td>(99, 207)</td>\n",
       "      <td>Bar El Ghazal Province</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39946</th>\n",
       "      <td>(104, 224)</td>\n",
       "      <td>Taiz-Torba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39947</th>\n",
       "      <td>(106, 119)</td>\n",
       "      <td>St. Joseph province</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9924 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          grid_id                location  \\\n",
       "0      (133, 200)             Ana E Malit   \n",
       "2       (73, 196)                  Onjiva   \n",
       "3       (74, 196)                   Evale   \n",
       "6       (74, 196)                   Evale   \n",
       "8      (113, 272)                  Hatiya   \n",
       "...           ...                     ...   \n",
       "39938   (86, 325)                   Manam   \n",
       "39939   (99, 210)                   Unity   \n",
       "39945   (99, 207)  Bar El Ghazal Province   \n",
       "39946  (104, 224)              Taiz-Torba   \n",
       "39947  (106, 119)     St. Joseph province   \n",
       "\n",
       "                                                     txt  \n",
       "0      The Ana Malit region is located between Lake S...  \n",
       "2                                                   None  \n",
       "3                                                   None  \n",
       "6                                                   None  \n",
       "8      Hatiya Upazila is located at 22.3667°N 91.1250...  \n",
       "...                                                  ...  \n",
       "39938                                                NaN  \n",
       "39939                                                NaN  \n",
       "39945                                                NaN  \n",
       "39946                                                NaN  \n",
       "39947                                                NaN  \n",
       "\n",
       "[9924 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_id</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(133, 200)</td>\n",
       "      <td>Ana E Malit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(73, 196)</td>\n",
       "      <td>Onjiva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(74, 196)</td>\n",
       "      <td>Evale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(74, 196)</td>\n",
       "      <td>Evale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(113, 272)</td>\n",
       "      <td>Hatiya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39938</th>\n",
       "      <td>(86, 325)</td>\n",
       "      <td>Manam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39939</th>\n",
       "      <td>(99, 210)</td>\n",
       "      <td>Unity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39945</th>\n",
       "      <td>(99, 207)</td>\n",
       "      <td>Bar El Ghazal Province</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39946</th>\n",
       "      <td>(104, 224)</td>\n",
       "      <td>Taiz-Torba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39947</th>\n",
       "      <td>(106, 119)</td>\n",
       "      <td>St. Joseph province</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9924 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          grid_id                location\n",
       "0      (133, 200)             Ana E Malit\n",
       "2       (73, 196)                  Onjiva\n",
       "3       (74, 196)                   Evale\n",
       "6       (74, 196)                   Evale\n",
       "8      (113, 272)                  Hatiya\n",
       "...           ...                     ...\n",
       "39938   (86, 325)                   Manam\n",
       "39939   (99, 210)                   Unity\n",
       "39945   (99, 207)  Bar El Ghazal Province\n",
       "39946  (104, 224)              Taiz-Torba\n",
       "39947  (106, 119)     St. Joseph province\n",
       "\n",
       "[9924 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /usr/local/lib/python3.9/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "ename": "WikipediaException",
     "evalue": "An unknown error occured: \"Search is currently too busy. Please try again later.\". Please report it on GitHub!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWikipediaException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-b4325444e314>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid_loc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wiki'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_loc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_wiki\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'location'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   7763\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7764\u001b[0m         )\n\u001b[0;32m-> 7765\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7767\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-b4325444e314>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid_loc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wiki'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_loc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_wiki\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'location'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-4428e914fb2d>\u001b[0m in \u001b[0;36mget_wiki\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtxt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#search similar words in wikipedia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0msimilar_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwikipedia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msimilar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msimilar_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/wikipedia/util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(query, results, suggestion)\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mHTTPTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mWikipediaException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'info'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0msearch_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'query'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'search'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWikipediaException\u001b[0m: An unknown error occured: \"Search is currently too busy. Please try again later.\". Please report it on GitHub!"
     ]
    }
   ],
   "source": [
    "grid_loc['wiki'] = grid_loc.apply(lambda row: get_wiki(row['location']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Greenwell Matongo']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_id</th>\n",
       "      <th>location</th>\n",
       "      <th>wiki</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(133, 200)</td>\n",
       "      <td>Ana E Malit</td>\n",
       "      <td>The Ana Malit region is located between Lake S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(73, 196)</td>\n",
       "      <td>Onjiva</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(74, 196)</td>\n",
       "      <td>Evale</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(74, 196)</td>\n",
       "      <td>Evale</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(113, 272)</td>\n",
       "      <td>Hatiya</td>\n",
       "      <td>Hatiya Upazila is located at 22.3667°N 91.1250...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39938</th>\n",
       "      <td>(86, 325)</td>\n",
       "      <td>Manam</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39939</th>\n",
       "      <td>(99, 210)</td>\n",
       "      <td>Unity</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39945</th>\n",
       "      <td>(99, 207)</td>\n",
       "      <td>Bar El Ghazal Province</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39946</th>\n",
       "      <td>(104, 224)</td>\n",
       "      <td>Taiz-Torba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39947</th>\n",
       "      <td>(106, 119)</td>\n",
       "      <td>St. Joseph province</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9924 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          grid_id                location  \\\n",
       "0      (133, 200)             Ana E Malit   \n",
       "2       (73, 196)                  Onjiva   \n",
       "3       (74, 196)                   Evale   \n",
       "6       (74, 196)                   Evale   \n",
       "8      (113, 272)                  Hatiya   \n",
       "...           ...                     ...   \n",
       "39938   (86, 325)                   Manam   \n",
       "39939   (99, 210)                   Unity   \n",
       "39945   (99, 207)  Bar El Ghazal Province   \n",
       "39946  (104, 224)              Taiz-Torba   \n",
       "39947  (106, 119)     St. Joseph province   \n",
       "\n",
       "                                                    wiki  \n",
       "0      The Ana Malit region is located between Lake S...  \n",
       "2                                                         \n",
       "3                                                         \n",
       "6                                                         \n",
       "8      Hatiya Upazila is located at 22.3667°N 91.1250...  \n",
       "...                                                  ...  \n",
       "39938                                                NaN  \n",
       "39939                                                NaN  \n",
       "39945                                                NaN  \n",
       "39946                                                NaN  \n",
       "39947                                                NaN  \n",
       "\n",
       "[9924 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hatiya',\n",
       " 'Hatiya Upazila',\n",
       " 'Hatiya Island',\n",
       " 'Hatiya Municipality',\n",
       " 'Bhasan Char',\n",
       " 'Hatiya, Sankhuwasabha',\n",
       " 'Noakhali District',\n",
       " 'List of Bangladesh tropical cyclones',\n",
       " 'Hatiya, Makwanpur',\n",
       " 'Hatiya, Baglung']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia.search('Hatiya')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "DisambiguationError",
     "evalue": "\"Hatiya\" may refer to: \nHatiya Upazila\nHatiya Island\nHatiya, Baglung\nHatiya, Sankhuwasabha\nHatiya, Makwanpur\nHatia",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDisambiguationError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-4080416ddf0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwikipedia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWikipediaPage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Hatiya'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Geography'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, title, pageid, redirect, preload, original_title)\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Either a title or a pageid must be specified\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mredirect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self, redirect, preload)\u001b[0m\n\u001b[1;32m    391\u001b[0m       \u001b[0mmay_refer_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mli\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mli\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiltered_lis\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mli\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mDisambiguationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'title'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmay_refer_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDisambiguationError\u001b[0m: \"Hatiya\" may refer to: \nHatiya Upazila\nHatiya Island\nHatiya, Baglung\nHatiya, Sankhuwasabha\nHatiya, Makwanpur\nHatia"
     ]
    }
   ],
   "source": [
    "wikipedia.WikipediaPage('Hatiya').section('Geography')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_loc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Punta Arenas (id: ??, ns: 0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term = 'Punta Arenas'\n",
    "wiki_wiki.page(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Punta Arenas (id: ??, ns: 0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_wiki.page(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
