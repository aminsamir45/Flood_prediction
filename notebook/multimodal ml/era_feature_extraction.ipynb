{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reading raw data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-1a121b5983b0>:4: DtypeWarning: Columns (8,16,17,18,19,24,25,26,27,46,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  emdat = pd.read_csv('../../data/emdat_public_2022_09_21_query_uid-47Yzpr.csv', skiprows=[0,1,2,3,4,5])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>country</th>\n",
       "      <th>iso3</th>\n",
       "      <th>gwno</th>\n",
       "      <th>year</th>\n",
       "      <th>geo_id</th>\n",
       "      <th>geolocation</th>\n",
       "      <th>level</th>\n",
       "      <th>adm1</th>\n",
       "      <th>adm2</th>\n",
       "      <th>adm3</th>\n",
       "      <th>location</th>\n",
       "      <th>historical</th>\n",
       "      <th>hist_country</th>\n",
       "      <th>disastertype</th>\n",
       "      <th>disasterno</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109</td>\n",
       "      <td>Albania</td>\n",
       "      <td>ALB</td>\n",
       "      <td>339.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>346</td>\n",
       "      <td>Ana E Malit</td>\n",
       "      <td>3</td>\n",
       "      <td>Shkoder</td>\n",
       "      <td>Shkodres</td>\n",
       "      <td>Ana E Malit</td>\n",
       "      <td>Ana E Malit</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flood</td>\n",
       "      <td>2009-0631</td>\n",
       "      <td>42.020948</td>\n",
       "      <td>19.418317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>Albania</td>\n",
       "      <td>ALB</td>\n",
       "      <td>339.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>351</td>\n",
       "      <td>Bushat</td>\n",
       "      <td>3</td>\n",
       "      <td>Shkoder</td>\n",
       "      <td>Shkodres</td>\n",
       "      <td>Bushat</td>\n",
       "      <td>Bushat</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flood</td>\n",
       "      <td>2009-0631</td>\n",
       "      <td>41.959294</td>\n",
       "      <td>19.514309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  country iso3   gwno  year  geo_id  geolocation  level     adm1  \\\n",
       "0  109  Albania  ALB  339.0  2009     346  Ana E Malit      3  Shkoder   \n",
       "1  109  Albania  ALB  339.0  2009     351       Bushat      3  Shkoder   \n",
       "\n",
       "       adm2         adm3     location  historical hist_country disastertype  \\\n",
       "0  Shkodres  Ana E Malit  Ana E Malit           0          NaN        flood   \n",
       "1  Shkodres       Bushat       Bushat           0          NaN        flood   \n",
       "\n",
       "  disasterno   latitude  longitude  \n",
       "0  2009-0631  42.020948  19.418317  \n",
       "1  2009-0631  41.959294  19.514309  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gdis data \n",
    "gdis = pd.read_csv('../../data/pend-gdis-1960-2018-disasterlocations.csv')\n",
    "#get emdat dataset\n",
    "emdat = pd.read_csv('../../data/emdat_public_2022_09_21_query_uid-47Yzpr.csv', skiprows=[0,1,2,3,4,5])\n",
    "gdis.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dis No</th>\n",
       "      <th>Year</th>\n",
       "      <th>Seq</th>\n",
       "      <th>Glide</th>\n",
       "      <th>Disaster Group</th>\n",
       "      <th>Disaster Subgroup</th>\n",
       "      <th>Disaster Type</th>\n",
       "      <th>Disaster Subtype</th>\n",
       "      <th>Disaster Subsubtype</th>\n",
       "      <th>Event Name</th>\n",
       "      <th>...</th>\n",
       "      <th>Reconstruction Costs, Adjusted ('000 US$)</th>\n",
       "      <th>Insured Damages ('000 US$)</th>\n",
       "      <th>Insured Damages, Adjusted ('000 US$)</th>\n",
       "      <th>Total Damages ('000 US$)</th>\n",
       "      <th>Total Damages, Adjusted ('000 US$)</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Adm Level</th>\n",
       "      <th>Admin1 Code</th>\n",
       "      <th>Admin2 Code</th>\n",
       "      <th>Geo Locations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900-9002-CPV</td>\n",
       "      <td>1900</td>\n",
       "      <td>9002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Climatological</td>\n",
       "      <td>Drought</td>\n",
       "      <td>Drought</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.077091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1900-9001-IND</td>\n",
       "      <td>1900</td>\n",
       "      <td>9001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Climatological</td>\n",
       "      <td>Drought</td>\n",
       "      <td>Drought</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.077091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Dis No  Year   Seq Glide Disaster Group Disaster Subgroup  \\\n",
       "0  1900-9002-CPV  1900  9002   NaN        Natural    Climatological   \n",
       "1  1900-9001-IND  1900  9001   NaN        Natural    Climatological   \n",
       "\n",
       "  Disaster Type Disaster Subtype Disaster Subsubtype Event Name  ...  \\\n",
       "0       Drought          Drought                 NaN        NaN  ...   \n",
       "1       Drought          Drought                 NaN        NaN  ...   \n",
       "\n",
       "  Reconstruction Costs, Adjusted ('000 US$) Insured Damages ('000 US$)  \\\n",
       "0                                       NaN                        NaN   \n",
       "1                                       NaN                        NaN   \n",
       "\n",
       "  Insured Damages, Adjusted ('000 US$) Total Damages ('000 US$)  \\\n",
       "0                                  NaN                      NaN   \n",
       "1                                  NaN                      NaN   \n",
       "\n",
       "  Total Damages, Adjusted ('000 US$)       CPI Adm Level Admin1 Code  \\\n",
       "0                                NaN  3.077091       NaN         NaN   \n",
       "1                                NaN  3.077091       NaN         NaN   \n",
       "\n",
       "  Admin2 Code Geo Locations  \n",
       "0         NaN           NaN  \n",
       "1         NaN           NaN  \n",
       "\n",
       "[2 rows x 50 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is where we obtain the statistical features\n",
    "emdat.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select certain columns from emdat and join with gdis \n",
    "# we grab the disaster number and convert it into string format and grab everything except for the last 4 ( so only the dates)\n",
    "emdat['disasterno'] = emdat['Dis No'].str[:-4] #format disasterno to merge  \n",
    "\n",
    "#These are the columns that we want to keep  , the features below are left out!\n",
    "cols = ['disasterno', 'Year', 'Event Name', \n",
    "#         'Disaster Type', 'Disaster Subtype', \n",
    "#         'Region', 'Continent', #'Location',\n",
    "        'Start Year', 'Start Month', 'Start Day', \n",
    "        'End Year', 'End Month','End Day',  \n",
    "        \"Total Damages, Adjusted ('000 US$)\"] \n",
    "\n",
    "emdat = emdat[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join emdat and gdis into one dataframe\n",
    "gdis = pd.merge(emdat, gdis, on = 'disasterno', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disasterno</th>\n",
       "      <th>Year</th>\n",
       "      <th>Event Name</th>\n",
       "      <th>Start Year</th>\n",
       "      <th>Start Month</th>\n",
       "      <th>Start Day</th>\n",
       "      <th>End Year</th>\n",
       "      <th>End Month</th>\n",
       "      <th>End Day</th>\n",
       "      <th>Total Damages, Adjusted ('000 US$)</th>\n",
       "      <th>...</th>\n",
       "      <th>level</th>\n",
       "      <th>adm1</th>\n",
       "      <th>adm2</th>\n",
       "      <th>adm3</th>\n",
       "      <th>location</th>\n",
       "      <th>historical</th>\n",
       "      <th>hist_country</th>\n",
       "      <th>disastertype</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-0631</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Shkoder</td>\n",
       "      <td>Shkodres</td>\n",
       "      <td>Ana E Malit</td>\n",
       "      <td>Ana E Malit</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flood</td>\n",
       "      <td>42.020948</td>\n",
       "      <td>19.418317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-0631</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Shkoder</td>\n",
       "      <td>Shkodres</td>\n",
       "      <td>Bushat</td>\n",
       "      <td>Bushat</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flood</td>\n",
       "      <td>41.959294</td>\n",
       "      <td>19.514309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-0146</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Cunene</td>\n",
       "      <td>Cuanhama</td>\n",
       "      <td>Onjiva</td>\n",
       "      <td>Onjiva</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flood</td>\n",
       "      <td>-17.093484</td>\n",
       "      <td>15.665758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  disasterno    Year Event Name  Start Year  Start Month  Start Day  End Year  \\\n",
       "0  2009-0631  2009.0        NaN      2009.0         12.0       27.0    2010.0   \n",
       "1  2009-0631  2009.0        NaN      2009.0         12.0       27.0    2010.0   \n",
       "2  2001-0146  2001.0        NaN      2001.0          4.0        2.0    2001.0   \n",
       "\n",
       "   End Month  End Day  Total Damages, Adjusted ('000 US$)  ... level     adm1  \\\n",
       "0        1.0      8.0                                 NaN  ...     3  Shkoder   \n",
       "1        1.0      8.0                                 NaN  ...     3  Shkoder   \n",
       "2        4.0      9.0                                 NaN  ...     3   Cunene   \n",
       "\n",
       "       adm2         adm3     location  historical hist_country  disastertype  \\\n",
       "0  Shkodres  Ana E Malit  Ana E Malit           0          NaN         flood   \n",
       "1  Shkodres       Bushat       Bushat           0          NaN         flood   \n",
       "2  Cuanhama       Onjiva       Onjiva           0          NaN         flood   \n",
       "\n",
       "    latitude  longitude  \n",
       "0  42.020948  19.418317  \n",
       "1  41.959294  19.514309  \n",
       "2 -17.093484  15.665758  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdis.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (9924, 27)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disasterno</th>\n",
       "      <th>Year</th>\n",
       "      <th>Event Name</th>\n",
       "      <th>Start Year</th>\n",
       "      <th>Start Month</th>\n",
       "      <th>Start Day</th>\n",
       "      <th>End Year</th>\n",
       "      <th>End Month</th>\n",
       "      <th>End Day</th>\n",
       "      <th>Total Damages, Adjusted ('000 US$)</th>\n",
       "      <th>...</th>\n",
       "      <th>level</th>\n",
       "      <th>adm1</th>\n",
       "      <th>adm2</th>\n",
       "      <th>adm3</th>\n",
       "      <th>location</th>\n",
       "      <th>historical</th>\n",
       "      <th>hist_country</th>\n",
       "      <th>disastertype</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-0631</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Shkoder</td>\n",
       "      <td>Shkodres</td>\n",
       "      <td>Ana E Malit</td>\n",
       "      <td>Ana E Malit</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flood</td>\n",
       "      <td>42.020948</td>\n",
       "      <td>19.418317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-0146</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Cunene</td>\n",
       "      <td>Cuanhama</td>\n",
       "      <td>Onjiva</td>\n",
       "      <td>Onjiva</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flood</td>\n",
       "      <td>-17.093484</td>\n",
       "      <td>15.665758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  disasterno    Year Event Name  Start Year  Start Month  Start Day  End Year  \\\n",
       "0  2009-0631  2009.0        NaN      2009.0         12.0       27.0    2010.0   \n",
       "2  2001-0146  2001.0        NaN      2001.0          4.0        2.0    2001.0   \n",
       "\n",
       "   End Month  End Day  Total Damages, Adjusted ('000 US$)  ... level     adm1  \\\n",
       "0        1.0      8.0                                 NaN  ...     3  Shkoder   \n",
       "2        4.0      9.0                                 NaN  ...     3   Cunene   \n",
       "\n",
       "       adm2         adm3     location  historical hist_country  disastertype  \\\n",
       "0  Shkodres  Ana E Malit  Ana E Malit           0          NaN         flood   \n",
       "2  Cuanhama       Onjiva       Onjiva           0          NaN         flood   \n",
       "\n",
       "    latitude  longitude  \n",
       "0  42.020948  19.418317  \n",
       "2 -17.093484  15.665758  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print \n",
    "gdis = gdis.drop_duplicates(subset=['id'])\n",
    "print('shape', gdis.shape)\n",
    "gdis.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old grid_id \n",
    "#latitude range from -90 to 90, longitude range from -180 to 180 \n",
    "\n",
    "# #convert lat and long into 1 degree grid: correspond to 100*100km \n",
    "# gdis['lat_grid_old'] = np.digitize(np.array(gdis['latitude']),np.arange(-90,90,1))\n",
    "# gdis['lon_grid_old'] = np.digitize(np.array(gdis['longitude']),np.arange(-180,180,1)) \n",
    "# #compute the grid pair id \n",
    "# gdis['grid_id_old'] = list(zip(gdis['lat_grid_old'],gdis['lon_grid_old']))\n",
    "# print('total number of grid pairs', len(gdis.grid_id.value_counts()))\n",
    "# gdis[['grid_id_old','grid_id']].to_csv('grid_id_conversion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of grid pairs 2827\n",
      "lon range -178 180\n",
      "lat range -54 68\n"
     ]
    }
   ],
   "source": [
    "#new grid_id: round to integers \n",
    "gdis['lat_grid'] = gdis['latitude'].round().astype(int)\n",
    "gdis['lon_grid'] = gdis['longitude'].round().astype(int)\n",
    "gdis['grid_id'] = list(zip(gdis['lat_grid'],gdis['lon_grid'])) \n",
    "print('total number of grid pairs', len(gdis.grid_id.value_counts()))\n",
    "\n",
    "# check if they lie in range\n",
    "print('lon range', gdis['lon_grid'].min(), gdis['lon_grid'].max()) \n",
    "print('lat range', gdis['lat_grid'].min(), gdis['lat_grid'].max()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disasterno</th>\n",
       "      <th>Year</th>\n",
       "      <th>Event Name</th>\n",
       "      <th>Start Year</th>\n",
       "      <th>Start Month</th>\n",
       "      <th>Start Day</th>\n",
       "      <th>End Year</th>\n",
       "      <th>End Month</th>\n",
       "      <th>End Day</th>\n",
       "      <th>Total Damages, Adjusted ('000 US$)</th>\n",
       "      <th>...</th>\n",
       "      <th>adm3</th>\n",
       "      <th>location</th>\n",
       "      <th>historical</th>\n",
       "      <th>hist_country</th>\n",
       "      <th>disastertype</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>lat_grid</th>\n",
       "      <th>lon_grid</th>\n",
       "      <th>grid_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-0631</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Ana E Malit</td>\n",
       "      <td>Ana E Malit</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flood</td>\n",
       "      <td>42.020948</td>\n",
       "      <td>19.418317</td>\n",
       "      <td>42</td>\n",
       "      <td>19</td>\n",
       "      <td>(42, 19)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-0146</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Onjiva</td>\n",
       "      <td>Onjiva</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flood</td>\n",
       "      <td>-17.093484</td>\n",
       "      <td>15.665758</td>\n",
       "      <td>-17</td>\n",
       "      <td>16</td>\n",
       "      <td>(-17, 16)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  disasterno    Year Event Name  Start Year  Start Month  Start Day  End Year  \\\n",
       "0  2009-0631  2009.0        NaN      2009.0         12.0       27.0    2010.0   \n",
       "2  2001-0146  2001.0        NaN      2001.0          4.0        2.0    2001.0   \n",
       "\n",
       "   End Month  End Day  Total Damages, Adjusted ('000 US$)  ...         adm3  \\\n",
       "0        1.0      8.0                                 NaN  ...  Ana E Malit   \n",
       "2        4.0      9.0                                 NaN  ...       Onjiva   \n",
       "\n",
       "      location historical  hist_country  disastertype   latitude  longitude  \\\n",
       "0  Ana E Malit          0           NaN         flood  42.020948  19.418317   \n",
       "2       Onjiva          0           NaN         flood -17.093484  15.665758   \n",
       "\n",
       "   lat_grid lon_grid    grid_id  \n",
       "0        42       19   (42, 19)  \n",
       "2       -17       16  (-17, 16)  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdis.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #count number of locations in each grid_id: ideally just 1 location per grid_id, if not, I can make grid finer. \n",
    "# gdis.groupby('grid_id').agg({'location':'nunique'}).sort_values(by='location').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the grid with most regions \n",
    "# gdis.loc[gdis['grid_id']==(113, 295)].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Construct X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot function: change rows of info into tables \n",
    "def pivot(df_in, id_col='disastertype', id_list=['Flood']):\n",
    "    #Drop and reset the index column\n",
    "    df = df_in.reset_index(drop = True)\n",
    "\n",
    "    # one set of disaster\n",
    "    for id in id_list:\n",
    "        #initialize columns\n",
    "        df[id+'_bin'] = 0\n",
    "        df[id+'_amt'] = 0\n",
    "        df[id+'_ct'] = 0\n",
    "        \n",
    "        \n",
    "        # so if the flood happens and we find it, we create these columns and get the flood costs\n",
    "        df.loc[(df[id_col]==id), id+'_bin'] = 1\n",
    "        df.loc[(df[id_col]==id), id+'_amt'] = df[\"Total Damages, Adjusted ('000 US$)\"].astype(float)\n",
    "        df.loc[(df[id_col]==id), id+'_ct'] = 1\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flood', 'storm', 'earthquake', 'extreme temperature ', 'landslide', 'volcanic activity', 'drought', 'mass movement (dry)']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disasterno</th>\n",
       "      <th>Year</th>\n",
       "      <th>Event Name</th>\n",
       "      <th>Start Year</th>\n",
       "      <th>Start Month</th>\n",
       "      <th>Start Day</th>\n",
       "      <th>End Year</th>\n",
       "      <th>End Month</th>\n",
       "      <th>End Day</th>\n",
       "      <th>Total Damages, Adjusted ('000 US$)</th>\n",
       "      <th>...</th>\n",
       "      <th>landslide_ct</th>\n",
       "      <th>volcanic activity_bin</th>\n",
       "      <th>volcanic activity_amt</th>\n",
       "      <th>volcanic activity_ct</th>\n",
       "      <th>drought_bin</th>\n",
       "      <th>drought_amt</th>\n",
       "      <th>drought_ct</th>\n",
       "      <th>mass movement (dry)_bin</th>\n",
       "      <th>mass movement (dry)_amt</th>\n",
       "      <th>mass movement (dry)_ct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-0631</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-0146</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-0092</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-0105</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995-0082</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1422569.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9919</th>\n",
       "      <td>1960-0011</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>Manam</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9920</th>\n",
       "      <td>2009-9633</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9921</th>\n",
       "      <td>1990-9289</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9922</th>\n",
       "      <td>1969-9069</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73867.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>73867.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9923</th>\n",
       "      <td>2015-0375</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Hurricane Erika</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>551973.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9924 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     disasterno    Year       Event Name  Start Year  Start Month  Start Day  \\\n",
       "0     2009-0631  2009.0              NaN      2009.0         12.0       27.0   \n",
       "1     2001-0146  2001.0              NaN      2001.0          4.0        2.0   \n",
       "2     2009-0092  2009.0              NaN      2009.0          3.0        1.0   \n",
       "3     2010-0105  2010.0              NaN      2010.0          3.0        1.0   \n",
       "4     1995-0082  1995.0              NaN      1995.0          5.0       15.0   \n",
       "...         ...     ...              ...         ...          ...        ...   \n",
       "9919  1960-0011  1960.0            Manam      1960.0          3.0       17.0   \n",
       "9920  2009-9633  2009.0              NaN      2009.0          NaN        NaN   \n",
       "9921  1990-9289  1990.0              NaN      1990.0          NaN        NaN   \n",
       "9922  1969-9069  1969.0              NaN      1969.0          NaN        NaN   \n",
       "9923  2015-0375  2015.0  Hurricane Erika      2015.0          8.0       27.0   \n",
       "\n",
       "      End Year  End Month  End Day  Total Damages, Adjusted ('000 US$)  ...  \\\n",
       "0       2010.0        1.0      8.0                                 NaN  ...   \n",
       "1       2001.0        4.0      9.0                                 NaN  ...   \n",
       "2       2009.0        4.0     16.0                                 NaN  ...   \n",
       "3       2010.0        3.0     17.0                                 NaN  ...   \n",
       "4       1995.0        5.0     15.0                           1422569.0  ...   \n",
       "...        ...        ...      ...                                 ...  ...   \n",
       "9919    1960.0        3.0     17.0                                 NaN  ...   \n",
       "9920    2010.0        NaN      NaN                                 NaN  ...   \n",
       "9921    1990.0        NaN      NaN                                 NaN  ...   \n",
       "9922    1971.0        NaN      NaN                             73867.0  ...   \n",
       "9923    2015.0        8.0     27.0                            551973.0  ...   \n",
       "\n",
       "     landslide_ct volcanic activity_bin volcanic activity_amt  \\\n",
       "0               0                     0                   0.0   \n",
       "1               0                     0                   0.0   \n",
       "2               0                     0                   0.0   \n",
       "3               0                     0                   0.0   \n",
       "4               0                     0                   0.0   \n",
       "...           ...                   ...                   ...   \n",
       "9919            0                     1                   NaN   \n",
       "9920            0                     0                   0.0   \n",
       "9921            0                     0                   0.0   \n",
       "9922            0                     0                   0.0   \n",
       "9923            0                     0                   0.0   \n",
       "\n",
       "      volcanic activity_ct  drought_bin  drought_amt drought_ct  \\\n",
       "0                        0            0          0.0          0   \n",
       "1                        0            0          0.0          0   \n",
       "2                        0            0          0.0          0   \n",
       "3                        0            0          0.0          0   \n",
       "4                        0            0          0.0          0   \n",
       "...                    ...          ...          ...        ...   \n",
       "9919                     1            0          0.0          0   \n",
       "9920                     0            1          NaN          1   \n",
       "9921                     0            1          NaN          1   \n",
       "9922                     0            1      73867.0          1   \n",
       "9923                     0            0          0.0          0   \n",
       "\n",
       "      mass movement (dry)_bin mass movement (dry)_amt mass movement (dry)_ct  \n",
       "0                           0                     0.0                      0  \n",
       "1                           0                     0.0                      0  \n",
       "2                           0                     0.0                      0  \n",
       "3                           0                     0.0                      0  \n",
       "4                           0                     0.0                      0  \n",
       "...                       ...                     ...                    ...  \n",
       "9919                        0                     0.0                      0  \n",
       "9920                        0                     0.0                      0  \n",
       "9921                        0                     0.0                      0  \n",
       "9922                        0                     0.0                      0  \n",
       "9923                        0                     0.0                      0  \n",
       "\n",
       "[9924 rows x 54 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# id_list= df_sub['Disaster Type'].unique()\n",
    "id_list= gdis['disastertype'].unique().tolist()\n",
    "print(id_list)\n",
    "df_pivot= pivot(gdis, id_col = 'disastertype', id_list = id_list)\n",
    "df_pivot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['disasterno', 'Year', 'Event Name', 'Start Year', 'Start Month',\n",
       "       'Start Day', 'End Year', 'End Month', 'End Day',\n",
       "       'Total Damages, Adjusted ('000 US$)', 'id', 'country', 'iso3', 'gwno',\n",
       "       'year', 'geo_id', 'geolocation', 'level', 'adm1', 'adm2', 'adm3',\n",
       "       'location', 'historical', 'hist_country', 'disastertype', 'latitude',\n",
       "       'longitude', 'lat_grid', 'lon_grid', 'grid_id', 'flood_bin',\n",
       "       'flood_amt', 'flood_ct', 'storm_bin', 'storm_amt', 'storm_ct',\n",
       "       'earthquake_bin', 'earthquake_amt', 'earthquake_ct',\n",
       "       'extreme temperature _bin', 'extreme temperature _amt',\n",
       "       'extreme temperature _ct', 'landslide_bin', 'landslide_amt',\n",
       "       'landslide_ct', 'volcanic activity_bin', 'volcanic activity_amt',\n",
       "       'volcanic activity_ct', 'drought_bin', 'drought_amt', 'drought_ct',\n",
       "       'mass movement (dry)_bin', 'mass movement (dry)_amt',\n",
       "       'mass movement (dry)_ct'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate columns by year\n",
    "# We need to include the longitude and lattitude here \n",
    "def aggregate_yrly(df):\n",
    "    #aggregate count\n",
    "    col_ct = [col for col in df.columns if '_ct' in col]\n",
    "    df_ct = df.groupby(['grid_id','year'])[col_ct].agg('sum')\n",
    "    \n",
    "    #aggregate amount \n",
    "    col_amt = [col for col in df.columns if '_amt' in col]\n",
    "    df_amt = df.groupby(['grid_id','year'])[col_amt].agg('sum')\n",
    "    \n",
    "    #aggregate binary\n",
    "    col_bin = [col for col in df.columns if '_bin' in col]\n",
    "    df_bin= df.groupby(['grid_id','year'])[col_bin].agg('max')\n",
    "\n",
    "    #join\n",
    "    df1= pd.concat([df_amt, df_ct], axis=1)\n",
    "    df_out = pd.concat([df1, df_bin], axis=1)\n",
    "    return df_out.reset_index()\n",
    "\n",
    "\n",
    "\n",
    "df_yrly = aggregate_yrly(df_pivot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['grid_id', 'year', 'flood_amt', 'storm_amt', 'earthquake_amt',\n",
       "       'extreme temperature _amt', 'landslide_amt', 'volcanic activity_amt',\n",
       "       'drought_amt', 'mass movement (dry)_amt', 'flood_ct', 'storm_ct',\n",
       "       'earthquake_ct', 'extreme temperature _ct', 'landslide_ct',\n",
       "       'volcanic activity_ct', 'drought_ct', 'mass movement (dry)_ct',\n",
       "       'flood_bin', 'storm_bin', 'earthquake_bin', 'extreme temperature _bin',\n",
       "       'landslide_bin', 'volcanic activity_bin', 'drought_bin',\n",
       "       'mass movement (dry)_bin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yrly.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8691\n"
     ]
    }
   ],
   "source": [
    "print(len(df_yrly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7977\n"
     ]
    }
   ],
   "source": [
    "# We want to remove years that are before 1979 as we don't have data for those in google earths\n",
    "df_yrly = df_yrly.loc[df_yrly['year']>1979].copy().reset_index(drop=True)\n",
    "print(len(df_yrly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Google earth functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticating google earths and importing it\n",
    "import ee\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=uf3norfRtdGSynwcuOSjqkV1LLaENbWCWhDSYg1ygV4&tc=lKk-Fqv21JccYeMInaJOvfi_71VjWc7NB8r8YKeLyRw&cc=mga6-lD0mAFADF6lA8QbFa9_KXn2Yaukb6UlmAfz8ng>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=uf3norfRtdGSynwcuOSjqkV1LLaENbWCWhDSYg1ygV4&tc=lKk-Fqv21JccYeMInaJOvfi_71VjWc7NB8r8YKeLyRw&cc=mga6-lD0mAFADF6lA8QbFa9_KXn2Yaukb6UlmAfz8ng</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter verification code: 4/1AWtgzh5iKXFgD4DRocd6BJY667IX3Kt6p_xFxM997ejGt8eHTmP6icXHIGM\n",
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "# Trigger the authentication flow.\n",
    "ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the library.\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the right dataset\n",
    "era5_monthly = ee.ImageCollection(\"ECMWF/ERA5/MONTHLY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ee_array_to_df(arr, list_of_bands):\n",
    "    \"\"\"\n",
    "    This is a helper function that transforms client-side ee.Image.getRegion array to pandas.DataFrame. \n",
    "    Used in the main function later\n",
    "    Input:\n",
    "        Takes in the array and the list of bands we want to extract\n",
    "        Takes in the array we are dealing with \n",
    "    Returns:\n",
    "        Dataframe we want in time-series format\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(arr)\n",
    "\n",
    "    # Rearrange the header.\n",
    "    headers = df.iloc[0]\n",
    "    df = pd.DataFrame(df.values[1:], columns=headers)\n",
    "\n",
    "    # Remove rows without data inside.\n",
    "    df = df[['longitude', 'latitude', 'time', *list_of_bands]].dropna()\n",
    "\n",
    "    # Convert the data to numeric values.\n",
    "    for band in list_of_bands:\n",
    "        df[band] = pd.to_numeric(df[band], errors='coerce')\n",
    "\n",
    "    # Convert the time field into a datetime.\n",
    "    df['datetime'] = pd.to_datetime(df['time'], unit='ms')\n",
    "\n",
    "    # Keep the columns of interest.\n",
    "    df = df[['time','datetime',  *list_of_bands]]\n",
    "    \n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_df(i_date,f_date,imagecollec,long,lat,scale=100,list_of_bands = ['mean_2m_air_temperature','minimum_2m_air_temperature','maximum_2m_air_temperature','dewpoint_2m_temperature','total_precipitation','surface_pressure','mean_sea_level_pressure','u_component_of_wind_10m','v_component_of_wind_10m']):\n",
    "    \"\"\"\n",
    "    Function that produces the time-series in dataframe of the different features we need from the dataset \n",
    "    \n",
    "    Input:\n",
    "        - List of features\n",
    "        - Start and end date we are interested in with the format '2017-01-01'\n",
    "        - the image collection in question\n",
    "        - Longitude - Float\n",
    "        - Lattitude - Float\n",
    "        - Scale - Float\n",
    "    Returns:\n",
    "        Dataframe we want in time-series format\n",
    "    \"\"\"\n",
    "    # Filter by the dates\n",
    "    imagecollec_sel_dates = imagecollec.filterDate(i_date, f_date)\n",
    "    \n",
    "    # Creation of the geometry object\n",
    "\n",
    "    point = ee.Geometry.Point(long, lat)\n",
    "    \n",
    "    # To download the time-series data\n",
    "    time_series_list = imagecollec_sel_dates.getRegion(point, scale).getInfo()\n",
    "    \n",
    "    # Convert the time_series list to dataframe and return it\n",
    "    output_df = ee_array_to_df(time_series_list,list_of_bands)\n",
    "        \n",
    "    return output_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1_mean_2m_air_temperature</th>\n",
       "      <th>1_minimum_2m_air_temperature</th>\n",
       "      <th>1_maximum_2m_air_temperature</th>\n",
       "      <th>1_dewpoint_2m_temperature</th>\n",
       "      <th>1_total_precipitation</th>\n",
       "      <th>1_surface_pressure</th>\n",
       "      <th>1_mean_sea_level_pressure</th>\n",
       "      <th>1_u_component_of_wind_10m</th>\n",
       "      <th>1_v_component_of_wind_10m</th>\n",
       "      <th>2_mean_2m_air_temperature</th>\n",
       "      <th>...</th>\n",
       "      <th>11_v_component_of_wind_10m</th>\n",
       "      <th>12_mean_2m_air_temperature</th>\n",
       "      <th>12_minimum_2m_air_temperature</th>\n",
       "      <th>12_maximum_2m_air_temperature</th>\n",
       "      <th>12_dewpoint_2m_temperature</th>\n",
       "      <th>12_total_precipitation</th>\n",
       "      <th>12_surface_pressure</th>\n",
       "      <th>12_mean_sea_level_pressure</th>\n",
       "      <th>12_u_component_of_wind_10m</th>\n",
       "      <th>12_v_component_of_wind_10m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300.250275</td>\n",
       "      <td>298.078094</td>\n",
       "      <td>301.828064</td>\n",
       "      <td>296.496399</td>\n",
       "      <td>0.075643</td>\n",
       "      <td>101028.09375</td>\n",
       "      <td>101028.21875</td>\n",
       "      <td>0.688926</td>\n",
       "      <td>1.466673</td>\n",
       "      <td>300.750916</td>\n",
       "      <td>...</td>\n",
       "      <td>4.113983</td>\n",
       "      <td>299.566833</td>\n",
       "      <td>298.023041</td>\n",
       "      <td>301.030975</td>\n",
       "      <td>296.309631</td>\n",
       "      <td>0.128574</td>\n",
       "      <td>100978.570312</td>\n",
       "      <td>100978.6875</td>\n",
       "      <td>0.05138</td>\n",
       "      <td>3.885582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1_mean_2m_air_temperature  1_minimum_2m_air_temperature  \\\n",
       "0                 300.250275                    298.078094   \n",
       "\n",
       "   1_maximum_2m_air_temperature  1_dewpoint_2m_temperature  \\\n",
       "0                    301.828064                 296.496399   \n",
       "\n",
       "   1_total_precipitation  1_surface_pressure  1_mean_sea_level_pressure  \\\n",
       "0               0.075643        101028.09375               101028.21875   \n",
       "\n",
       "   1_u_component_of_wind_10m  1_v_component_of_wind_10m  \\\n",
       "0                   0.688926                   1.466673   \n",
       "\n",
       "   2_mean_2m_air_temperature  ...  11_v_component_of_wind_10m  \\\n",
       "0                 300.750916  ...                    4.113983   \n",
       "\n",
       "   12_mean_2m_air_temperature  12_minimum_2m_air_temperature  \\\n",
       "0                  299.566833                     298.023041   \n",
       "\n",
       "   12_maximum_2m_air_temperature  12_dewpoint_2m_temperature  \\\n",
       "0                     301.030975                  296.309631   \n",
       "\n",
       "   12_total_precipitation  12_surface_pressure  12_mean_sea_level_pressure  \\\n",
       "0                0.128574        100978.570312                 100978.6875   \n",
       "\n",
       "   12_u_component_of_wind_10m  12_v_component_of_wind_10m  \n",
       "0                     0.05138                    3.885582  \n",
       "\n",
       "[1 rows x 108 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reformat_features(era_features): \n",
    "    era_features['month'] = era_features['datetime'].dt.month.astype(str)\n",
    "    era_features = era_features.drop(['time','datetime'], axis=1).set_index('month')\n",
    "    row_data = era_features.stack().values\n",
    "    row_cols = era_features.stack().index.map('_'.join).tolist()\n",
    "    era_features_row = pd.DataFrame(columns=row_cols, data=row_data.reshape(1,-1))\n",
    "    return era_features_row \n",
    "\n",
    "year = 2005\n",
    "i_date = str(year)+'-01-01'\n",
    "f_date = str(year+1)+'-01-01' \n",
    "lat, long = (1,1)\n",
    "imagecollec = era5_monthly\n",
    "#call features_df to get era features for a range of dates at a particular lat and long \n",
    "era_features_one = features_df(i_date,f_date,imagecollec,long,lat) \n",
    "#convert this into a row of features, with column name being the month_feature_name \n",
    "era_features_row = reformat_features(era_features_one) \n",
    "era_features_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yrly.year.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of grid_ids selected 791\n",
      "791\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_id</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(-46, 168)</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(-46, 168)</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(-46, 168)</td>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(-46, 168)</td>\n",
       "      <td>1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(-46, 168)</td>\n",
       "      <td>1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32426</th>\n",
       "      <td>(66, 130)</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32427</th>\n",
       "      <td>(66, 130)</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32428</th>\n",
       "      <td>(66, 130)</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32429</th>\n",
       "      <td>(66, 130)</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32430</th>\n",
       "      <td>(66, 130)</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32431 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          grid_id  year\n",
       "0      (-46, 168)  1979\n",
       "1      (-46, 168)  1980\n",
       "2      (-46, 168)  1981\n",
       "3      (-46, 168)  1982\n",
       "4      (-46, 168)  1983\n",
       "...           ...   ...\n",
       "32426   (66, 130)  2015\n",
       "32427   (66, 130)  2016\n",
       "32428   (66, 130)  2017\n",
       "32429   (66, 130)  2018\n",
       "32430   (66, 130)  2019\n",
       "\n",
       "[32431 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#interpolate all years from 1979 (when ERA5 data is available)\n",
    "#filter to those grid_ids with previous frequent flooding history \n",
    "agg = df_yrly.groupby('grid_id').agg({'flood_bin':'sum'})\n",
    "grid_id_ls = agg.loc[agg['flood_bin']>=2].index.tolist()\n",
    "print('no of grid_ids selected', len(grid_id_ls))\n",
    "year_id = np.arange(1979, 2020, 1) \n",
    "print(len(grid_id_ls))\n",
    "idd = pd.MultiIndex.from_product([grid_id_ls, year_id],\n",
    "                           names=['grid_id', 'year']).to_frame().reset_index(drop=True)\n",
    "idd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32431/32431 [3:53:12<00:00,  2.32it/s]   \n"
     ]
    }
   ],
   "source": [
    "#I already ran this cell, it takes 1h \n",
    "i=0 \n",
    "era_features =pd.DataFrame()\n",
    "for index, row in tqdm(idd.iterrows(), total=idd.shape[0]):\n",
    "    year = row['year']\n",
    "    i_date = str(year)+'-01-01'\n",
    "    f_date = str(year+1)+'-01-01' \n",
    "    lat, long = row['grid_id']\n",
    "    #call features_df to get era features for a range of dates at a particular lat and long \n",
    "    era_features_one = features_df(i_date,f_date,imagecollec, long+0.5, lat+0.5) \n",
    "    #convert this into a row of features, with column name being the month_feature_name \n",
    "    era_features_row = reformat_features(era_features_one) \n",
    "    #append year, lat and long info to get grid_id \n",
    "    era_features_row[['year', 'lat', 'long']] = year, lat, long\n",
    "\n",
    "    era_features = era_features.append(era_features_row, ignore_index=True)\n",
    "    i +=1 \n",
    "    #save output every 1000 iterations \n",
    "    if i in range(1,len(idd),5000):\n",
    "        era_features.to_csv('era_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save extracted features into csv \n",
    "era_features\n",
    "era_features.to_csv('era_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1_mean_2m_air_temperature</th>\n",
       "      <th>1_minimum_2m_air_temperature</th>\n",
       "      <th>1_maximum_2m_air_temperature</th>\n",
       "      <th>1_dewpoint_2m_temperature</th>\n",
       "      <th>1_total_precipitation</th>\n",
       "      <th>1_surface_pressure</th>\n",
       "      <th>1_mean_sea_level_pressure</th>\n",
       "      <th>1_u_component_of_wind_10m</th>\n",
       "      <th>1_v_component_of_wind_10m</th>\n",
       "      <th>2_mean_2m_air_temperature</th>\n",
       "      <th>...</th>\n",
       "      <th>12_maximum_2m_air_temperature</th>\n",
       "      <th>12_dewpoint_2m_temperature</th>\n",
       "      <th>12_total_precipitation</th>\n",
       "      <th>12_surface_pressure</th>\n",
       "      <th>12_mean_sea_level_pressure</th>\n",
       "      <th>12_u_component_of_wind_10m</th>\n",
       "      <th>12_v_component_of_wind_10m</th>\n",
       "      <th>year</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>283.617432</td>\n",
       "      <td>274.514099</td>\n",
       "      <td>293.051849</td>\n",
       "      <td>279.182190</td>\n",
       "      <td>0.215081</td>\n",
       "      <td>92250.945312</td>\n",
       "      <td>101025.101562</td>\n",
       "      <td>2.339942</td>\n",
       "      <td>-1.741069</td>\n",
       "      <td>283.682892</td>\n",
       "      <td>...</td>\n",
       "      <td>293.280151</td>\n",
       "      <td>278.507690</td>\n",
       "      <td>0.214973</td>\n",
       "      <td>91823.835938</td>\n",
       "      <td>100589.523438</td>\n",
       "      <td>1.331599</td>\n",
       "      <td>-1.586958</td>\n",
       "      <td>1979</td>\n",
       "      <td>-46</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>284.689545</td>\n",
       "      <td>273.895508</td>\n",
       "      <td>295.293182</td>\n",
       "      <td>280.788971</td>\n",
       "      <td>0.264142</td>\n",
       "      <td>92111.539062</td>\n",
       "      <td>100855.046875</td>\n",
       "      <td>1.082877</td>\n",
       "      <td>-0.996928</td>\n",
       "      <td>282.993622</td>\n",
       "      <td>...</td>\n",
       "      <td>293.592224</td>\n",
       "      <td>280.121765</td>\n",
       "      <td>0.088443</td>\n",
       "      <td>92457.976562</td>\n",
       "      <td>101241.312500</td>\n",
       "      <td>0.833229</td>\n",
       "      <td>-0.764634</td>\n",
       "      <td>1980</td>\n",
       "      <td>-46</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>284.936646</td>\n",
       "      <td>274.029205</td>\n",
       "      <td>293.806641</td>\n",
       "      <td>280.351562</td>\n",
       "      <td>0.065239</td>\n",
       "      <td>92711.820312</td>\n",
       "      <td>101490.492188</td>\n",
       "      <td>1.865336</td>\n",
       "      <td>-1.452276</td>\n",
       "      <td>284.757507</td>\n",
       "      <td>...</td>\n",
       "      <td>293.230774</td>\n",
       "      <td>281.170258</td>\n",
       "      <td>0.208652</td>\n",
       "      <td>92287.460938</td>\n",
       "      <td>101046.523438</td>\n",
       "      <td>1.027116</td>\n",
       "      <td>-0.874772</td>\n",
       "      <td>1981</td>\n",
       "      <td>-46</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>283.649567</td>\n",
       "      <td>274.507050</td>\n",
       "      <td>293.252380</td>\n",
       "      <td>279.620819</td>\n",
       "      <td>0.219091</td>\n",
       "      <td>92001.867188</td>\n",
       "      <td>100763.882812</td>\n",
       "      <td>2.079320</td>\n",
       "      <td>-1.756939</td>\n",
       "      <td>284.861938</td>\n",
       "      <td>...</td>\n",
       "      <td>292.498871</td>\n",
       "      <td>277.305939</td>\n",
       "      <td>0.160083</td>\n",
       "      <td>91935.570312</td>\n",
       "      <td>100772.304688</td>\n",
       "      <td>1.964107</td>\n",
       "      <td>-1.288524</td>\n",
       "      <td>1982</td>\n",
       "      <td>-46</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>282.124695</td>\n",
       "      <td>272.930054</td>\n",
       "      <td>293.302368</td>\n",
       "      <td>278.383118</td>\n",
       "      <td>0.222093</td>\n",
       "      <td>91664.773438</td>\n",
       "      <td>100442.992188</td>\n",
       "      <td>1.911922</td>\n",
       "      <td>-2.058668</td>\n",
       "      <td>283.099060</td>\n",
       "      <td>...</td>\n",
       "      <td>294.530212</td>\n",
       "      <td>277.901886</td>\n",
       "      <td>0.195903</td>\n",
       "      <td>92046.609375</td>\n",
       "      <td>100889.664062</td>\n",
       "      <td>1.336580</td>\n",
       "      <td>-0.468514</td>\n",
       "      <td>1983</td>\n",
       "      <td>-46</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1_mean_2m_air_temperature  1_minimum_2m_air_temperature  \\\n",
       "0                 283.617432                    274.514099   \n",
       "1                 284.689545                    273.895508   \n",
       "2                 284.936646                    274.029205   \n",
       "3                 283.649567                    274.507050   \n",
       "4                 282.124695                    272.930054   \n",
       "\n",
       "   1_maximum_2m_air_temperature  1_dewpoint_2m_temperature  \\\n",
       "0                    293.051849                 279.182190   \n",
       "1                    295.293182                 280.788971   \n",
       "2                    293.806641                 280.351562   \n",
       "3                    293.252380                 279.620819   \n",
       "4                    293.302368                 278.383118   \n",
       "\n",
       "   1_total_precipitation  1_surface_pressure  1_mean_sea_level_pressure  \\\n",
       "0               0.215081        92250.945312              101025.101562   \n",
       "1               0.264142        92111.539062              100855.046875   \n",
       "2               0.065239        92711.820312              101490.492188   \n",
       "3               0.219091        92001.867188              100763.882812   \n",
       "4               0.222093        91664.773438              100442.992188   \n",
       "\n",
       "   1_u_component_of_wind_10m  1_v_component_of_wind_10m  \\\n",
       "0                   2.339942                  -1.741069   \n",
       "1                   1.082877                  -0.996928   \n",
       "2                   1.865336                  -1.452276   \n",
       "3                   2.079320                  -1.756939   \n",
       "4                   1.911922                  -2.058668   \n",
       "\n",
       "   2_mean_2m_air_temperature  ...  12_maximum_2m_air_temperature  \\\n",
       "0                 283.682892  ...                     293.280151   \n",
       "1                 282.993622  ...                     293.592224   \n",
       "2                 284.757507  ...                     293.230774   \n",
       "3                 284.861938  ...                     292.498871   \n",
       "4                 283.099060  ...                     294.530212   \n",
       "\n",
       "   12_dewpoint_2m_temperature  12_total_precipitation  12_surface_pressure  \\\n",
       "0                  278.507690                0.214973         91823.835938   \n",
       "1                  280.121765                0.088443         92457.976562   \n",
       "2                  281.170258                0.208652         92287.460938   \n",
       "3                  277.305939                0.160083         91935.570312   \n",
       "4                  277.901886                0.195903         92046.609375   \n",
       "\n",
       "   12_mean_sea_level_pressure  12_u_component_of_wind_10m  \\\n",
       "0               100589.523438                    1.331599   \n",
       "1               101241.312500                    0.833229   \n",
       "2               101046.523438                    1.027116   \n",
       "3               100772.304688                    1.964107   \n",
       "4               100889.664062                    1.336580   \n",
       "\n",
       "   12_v_component_of_wind_10m  year  lat  long  \n",
       "0                   -1.586958  1979  -46   168  \n",
       "1                   -0.764634  1980  -46   168  \n",
       "2                   -0.874772  1981  -46   168  \n",
       "3                   -1.288524  1982  -46   168  \n",
       "4                   -0.468514  1983  -46   168  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read era_features (ran from above cell)\n",
    "era_features = pd.read_csv('era_features.csv', index_col=0)\n",
    "era_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing: \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#statistical features only \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Y Master\n",
    "look up table for all the previous flood events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_col =  [col for col in df_yrly.columns if '_bin' in col]\n",
    "df_yrly_bin = df_yrly[['grid_id','year'] + bin_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #get a list of disasters and flood_id \n",
    "# all_dis = gdis[['grid_id','Year','disastertype']]\n",
    "\n",
    "# #\n",
    "# flood = all_dis.loc[all_dis['disastertype']=='flood']\n",
    "# flood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1960.0 2018.0\n",
      "166793\n"
     ]
    }
   ],
   "source": [
    "# get a list of grid_ids \n",
    "grid_id = gdis['grid_id'].unique()\n",
    "# get a list of year information \n",
    "print(gdis.Year.min(), gdis.Year.max())\n",
    "year_id = np.arange(1960, 2019, 1) \n",
    "#create multi-index: each grid id, spanning over the years \n",
    "idd = pd.MultiIndex.from_product([grid_id, year_id],\n",
    "                           names=['grid_id', 'year'])\n",
    "\n",
    "#length should be |years| * |grid_ids| \n",
    "print(len(idd))\n",
    "#get dataframe \n",
    "idd = idd.to_frame().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#master disaster targets for all years and all ids: \n",
    "#merge with df_yrly \n",
    "y_master = pd.merge(idd, df_yrly_bin, on=['grid_id','year'], how='left').fillna(0)\n",
    "\n",
    "#keep just the binary\n",
    "# y_master.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3783.0\n",
      "4274\n"
     ]
    }
   ],
   "source": [
    "#check: \n",
    "print(y_master['flood_bin'].sum()) #total number of binary flood targets \n",
    "\n",
    "#total number of flood incidents: \n",
    "print(gdis.loc[gdis['disastertype']=='flood'].shape[0])\n",
    "\n",
    "#the two numbers are slightly different, but that's because some country have more than 1 flood per year \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_id</th>\n",
       "      <th>year</th>\n",
       "      <th>flood_bin</th>\n",
       "      <th>storm_bin</th>\n",
       "      <th>earthquake_bin</th>\n",
       "      <th>extreme temperature _bin</th>\n",
       "      <th>landslide_bin</th>\n",
       "      <th>volcanic activity_bin</th>\n",
       "      <th>drought_bin</th>\n",
       "      <th>mass movement (dry)_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(42, 19)</td>\n",
       "      <td>1960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(42, 19)</td>\n",
       "      <td>1961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(42, 19)</td>\n",
       "      <td>1962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(42, 19)</td>\n",
       "      <td>1963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(42, 19)</td>\n",
       "      <td>1964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166788</th>\n",
       "      <td>(9, 30)</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166789</th>\n",
       "      <td>(9, 30)</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166790</th>\n",
       "      <td>(9, 30)</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166791</th>\n",
       "      <td>(9, 30)</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166792</th>\n",
       "      <td>(9, 30)</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166793 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         grid_id  year  flood_bin  storm_bin  earthquake_bin  \\\n",
       "0       (42, 19)  1960        0.0        0.0             0.0   \n",
       "1       (42, 19)  1961        0.0        0.0             0.0   \n",
       "2       (42, 19)  1962        0.0        0.0             0.0   \n",
       "3       (42, 19)  1963        0.0        0.0             0.0   \n",
       "4       (42, 19)  1964        0.0        0.0             0.0   \n",
       "...          ...   ...        ...        ...             ...   \n",
       "166788   (9, 30)  2014        0.0        0.0             0.0   \n",
       "166789   (9, 30)  2015        0.0        0.0             0.0   \n",
       "166790   (9, 30)  2016        0.0        0.0             0.0   \n",
       "166791   (9, 30)  2017        0.0        0.0             0.0   \n",
       "166792   (9, 30)  2018        0.0        0.0             0.0   \n",
       "\n",
       "        extreme temperature _bin  landslide_bin  volcanic activity_bin  \\\n",
       "0                            0.0            0.0                    0.0   \n",
       "1                            0.0            0.0                    0.0   \n",
       "2                            0.0            0.0                    0.0   \n",
       "3                            0.0            0.0                    0.0   \n",
       "4                            0.0            0.0                    0.0   \n",
       "...                          ...            ...                    ...   \n",
       "166788                       0.0            0.0                    0.0   \n",
       "166789                       0.0            0.0                    0.0   \n",
       "166790                       0.0            0.0                    0.0   \n",
       "166791                       0.0            0.0                    0.0   \n",
       "166792                       0.0            0.0                    0.0   \n",
       "\n",
       "        drought_bin  mass movement (dry)_bin  \n",
       "0               0.0                      0.0  \n",
       "1               0.0                      0.0  \n",
       "2               0.0                      0.0  \n",
       "3               0.0                      0.0  \n",
       "4               0.0                      0.0  \n",
       "...             ...                      ...  \n",
       "166788          0.0                      0.0  \n",
       "166789          0.0                      0.0  \n",
       "166790          0.0                      0.0  \n",
       "166791          0.0                      0.0  \n",
       "166792          0.0                      0.0  \n",
       "\n",
       "[166793 rows x 10 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct next n year target -> look up this table \n",
    "y_master\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter data to previously flooded regions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of grid_ids selected 791\n",
      "len of idd 46669\n"
     ]
    }
   ],
   "source": [
    "#step 1: filter xy_df to those grid_ids with previous frequent flooding history \n",
    "agg = df_yrly.groupby('grid_id').agg({'flood_bin':'sum'})\n",
    "grid_id_ls = agg.loc[agg['flood_bin']>=2].index.tolist()\n",
    "print('no of grid_ids selected', len(grid_id_ls))\n",
    "\n",
    "\n",
    "#step 2: interpolate years to record all years, fill with 0 without any flood using idd \n",
    "#create multi-index: each grid id, spanning over the years \n",
    "year_id = np.arange(1960, 2019, 1) \n",
    "idd = pd.MultiIndex.from_product([grid_id_ls, year_id],\n",
    "                           names=['grid_id', 'year'])\n",
    "\n",
    "#length should be |years| * |grid_ids| \n",
    "print('len of idd', len(idd))\n",
    "#get dataframe \n",
    "idd = idd.to_frame().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7977, 26)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yrly.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### attach NLP feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2852, 37)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle \n",
    "print(pickle.format_version)\n",
    "\n",
    "#load processed nlp features: \n",
    "#note: you can load other nlp features too, they all start with 'nlp_*' \n",
    "file = open('../../data/nlp_cls_transfer.pkl', 'rb') \n",
    "# load file\n",
    "df_nlp = pickle.load(file)\n",
    "# close the file\n",
    "file.close()\n",
    "df_nlp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2852, 37) (2852, 2)\n",
      "(2852, 37)\n",
      "(2382, 37)\n"
     ]
    }
   ],
   "source": [
    "#convert old grid id to new grid id \n",
    "grid_id_map = pd.read_csv('grid_id_conversion.csv', index_col=0)\n",
    "grid_id_map = grid_id_map.drop_duplicates(subset=['grid_id_old'], keep='first')\n",
    "df_nlp = df_nlp.rename(columns={'grid_id':'grid_id_old'})\n",
    "print(df_nlp.shape, grid_id_map.shape)\n",
    "df_nlp = df_nlp.merge(grid_id_map, on='grid_id_old', how='left').drop('grid_id_old', axis=1)\n",
    "print(df_nlp.shape)\n",
    "#drop duplicates \n",
    "df_nlp = df_nlp.drop_duplicates(subset='grid_id', keep='first')\n",
    "print(df_nlp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixing formatting error: change string of tuple of grid_id to tuple \n",
    "def string_to_tuple(df, col): \n",
    "    try: \n",
    "        df[col] = df.apply(lambda row: eval(row[col]), axis=1) \n",
    "    except: \n",
    "        'error converting to tuple'\n",
    "    return df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of xy_df with nlp features (7759, 59)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_id</th>\n",
       "      <th>year</th>\n",
       "      <th>flood_amt</th>\n",
       "      <th>storm_amt</th>\n",
       "      <th>earthquake_amt</th>\n",
       "      <th>extreme temperature _amt</th>\n",
       "      <th>landslide_amt</th>\n",
       "      <th>volcanic activity_amt</th>\n",
       "      <th>drought_amt</th>\n",
       "      <th>mass movement (dry)_amt</th>\n",
       "      <th>...</th>\n",
       "      <th>nlp_22</th>\n",
       "      <th>nlp_23</th>\n",
       "      <th>nlp_24</th>\n",
       "      <th>nlp_25</th>\n",
       "      <th>nlp_26</th>\n",
       "      <th>nlp_27</th>\n",
       "      <th>nlp_28</th>\n",
       "      <th>nlp_29</th>\n",
       "      <th>nlp_30</th>\n",
       "      <th>nlp_31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(-54, -72)</td>\n",
       "      <td>1990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285712</td>\n",
       "      <td>0.175260</td>\n",
       "      <td>0.066858</td>\n",
       "      <td>0.402230</td>\n",
       "      <td>0.307911</td>\n",
       "      <td>0.413373</td>\n",
       "      <td>-0.304808</td>\n",
       "      <td>0.332228</td>\n",
       "      <td>0.176272</td>\n",
       "      <td>-0.206565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(-49, -73)</td>\n",
       "      <td>2017</td>\n",
       "      <td>2211.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.295375</td>\n",
       "      <td>0.147407</td>\n",
       "      <td>-0.000792</td>\n",
       "      <td>0.327370</td>\n",
       "      <td>0.290429</td>\n",
       "      <td>0.431107</td>\n",
       "      <td>-0.327519</td>\n",
       "      <td>0.183837</td>\n",
       "      <td>0.048896</td>\n",
       "      <td>-0.185709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(-49, -70)</td>\n",
       "      <td>1991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375935</td>\n",
       "      <td>0.161357</td>\n",
       "      <td>0.086125</td>\n",
       "      <td>0.396205</td>\n",
       "      <td>0.309829</td>\n",
       "      <td>0.434621</td>\n",
       "      <td>-0.271017</td>\n",
       "      <td>0.377438</td>\n",
       "      <td>0.124515</td>\n",
       "      <td>-0.173165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(-46, -73)</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303552</td>\n",
       "      <td>0.173102</td>\n",
       "      <td>0.097518</td>\n",
       "      <td>0.477680</td>\n",
       "      <td>0.316651</td>\n",
       "      <td>0.445075</td>\n",
       "      <td>-0.281092</td>\n",
       "      <td>0.293919</td>\n",
       "      <td>0.158472</td>\n",
       "      <td>-0.205128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(-46, -73)</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303552</td>\n",
       "      <td>0.173102</td>\n",
       "      <td>0.097518</td>\n",
       "      <td>0.477680</td>\n",
       "      <td>0.316651</td>\n",
       "      <td>0.445075</td>\n",
       "      <td>-0.281092</td>\n",
       "      <td>0.293919</td>\n",
       "      <td>0.158472</td>\n",
       "      <td>-0.205128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7754</th>\n",
       "      <td>(66, 130)</td>\n",
       "      <td>1998</td>\n",
       "      <td>5818.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241954</td>\n",
       "      <td>0.260355</td>\n",
       "      <td>0.086829</td>\n",
       "      <td>0.508838</td>\n",
       "      <td>0.289577</td>\n",
       "      <td>0.384660</td>\n",
       "      <td>-0.194955</td>\n",
       "      <td>0.296642</td>\n",
       "      <td>0.106905</td>\n",
       "      <td>-0.120921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7755</th>\n",
       "      <td>(66, 130)</td>\n",
       "      <td>2007</td>\n",
       "      <td>33655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241954</td>\n",
       "      <td>0.260355</td>\n",
       "      <td>0.086829</td>\n",
       "      <td>0.508838</td>\n",
       "      <td>0.289577</td>\n",
       "      <td>0.384660</td>\n",
       "      <td>-0.194955</td>\n",
       "      <td>0.296642</td>\n",
       "      <td>0.106905</td>\n",
       "      <td>-0.120921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7756</th>\n",
       "      <td>(66, 130)</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241954</td>\n",
       "      <td>0.260355</td>\n",
       "      <td>0.086829</td>\n",
       "      <td>0.508838</td>\n",
       "      <td>0.289577</td>\n",
       "      <td>0.384660</td>\n",
       "      <td>-0.194955</td>\n",
       "      <td>0.296642</td>\n",
       "      <td>0.106905</td>\n",
       "      <td>-0.120921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7757</th>\n",
       "      <td>(68, -135)</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296960</td>\n",
       "      <td>0.232861</td>\n",
       "      <td>0.145010</td>\n",
       "      <td>0.493256</td>\n",
       "      <td>0.297104</td>\n",
       "      <td>0.419325</td>\n",
       "      <td>-0.291666</td>\n",
       "      <td>0.335292</td>\n",
       "      <td>0.182556</td>\n",
       "      <td>-0.052409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7758</th>\n",
       "      <td>(68, 26)</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310192</td>\n",
       "      <td>0.260462</td>\n",
       "      <td>0.023379</td>\n",
       "      <td>0.391883</td>\n",
       "      <td>0.277369</td>\n",
       "      <td>0.287159</td>\n",
       "      <td>-0.261535</td>\n",
       "      <td>0.210903</td>\n",
       "      <td>0.199086</td>\n",
       "      <td>-0.114386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7759 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         grid_id  year  flood_amt  storm_amt  earthquake_amt  \\\n",
       "0     (-54, -72)  1990        0.0        0.0             0.0   \n",
       "1     (-49, -73)  2017     2211.0        0.0             0.0   \n",
       "2     (-49, -70)  1991        0.0        0.0             0.0   \n",
       "3     (-46, -73)  2007        0.0        0.0             0.0   \n",
       "4     (-46, -73)  2010        0.0        0.0             0.0   \n",
       "...          ...   ...        ...        ...             ...   \n",
       "7754   (66, 130)  1998     5818.0        0.0             0.0   \n",
       "7755   (66, 130)  2007    33655.0        0.0             0.0   \n",
       "7756   (66, 130)  2012        0.0        0.0             0.0   \n",
       "7757  (68, -135)  2006        0.0        0.0             0.0   \n",
       "7758    (68, 26)  2005        0.0        0.0             0.0   \n",
       "\n",
       "      extreme temperature _amt  landslide_amt  volcanic activity_amt  \\\n",
       "0                          0.0            0.0                    0.0   \n",
       "1                          0.0            0.0                    0.0   \n",
       "2                          0.0            0.0                    0.0   \n",
       "3                          0.0            0.0                    0.0   \n",
       "4                          0.0            0.0                    0.0   \n",
       "...                        ...            ...                    ...   \n",
       "7754                       0.0            0.0                    0.0   \n",
       "7755                       0.0            0.0                    0.0   \n",
       "7756                       0.0            0.0                    0.0   \n",
       "7757                       0.0            0.0                    0.0   \n",
       "7758                       0.0            0.0                    0.0   \n",
       "\n",
       "      drought_amt  mass movement (dry)_amt  ...    nlp_22    nlp_23    nlp_24  \\\n",
       "0             0.0                      0.0  ...  0.285712  0.175260  0.066858   \n",
       "1             0.0                      0.0  ...  0.295375  0.147407 -0.000792   \n",
       "2             0.0                      0.0  ...  0.375935  0.161357  0.086125   \n",
       "3             0.0                      0.0  ...  0.303552  0.173102  0.097518   \n",
       "4             0.0                      0.0  ...  0.303552  0.173102  0.097518   \n",
       "...           ...                      ...  ...       ...       ...       ...   \n",
       "7754          0.0                      0.0  ...  0.241954  0.260355  0.086829   \n",
       "7755          0.0                      0.0  ...  0.241954  0.260355  0.086829   \n",
       "7756          0.0                      0.0  ...  0.241954  0.260355  0.086829   \n",
       "7757          0.0                      0.0  ...  0.296960  0.232861  0.145010   \n",
       "7758          0.0                      0.0  ...  0.310192  0.260462  0.023379   \n",
       "\n",
       "        nlp_25    nlp_26    nlp_27    nlp_28    nlp_29    nlp_30    nlp_31  \n",
       "0     0.402230  0.307911  0.413373 -0.304808  0.332228  0.176272 -0.206565  \n",
       "1     0.327370  0.290429  0.431107 -0.327519  0.183837  0.048896 -0.185709  \n",
       "2     0.396205  0.309829  0.434621 -0.271017  0.377438  0.124515 -0.173165  \n",
       "3     0.477680  0.316651  0.445075 -0.281092  0.293919  0.158472 -0.205128  \n",
       "4     0.477680  0.316651  0.445075 -0.281092  0.293919  0.158472 -0.205128  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "7754  0.508838  0.289577  0.384660 -0.194955  0.296642  0.106905 -0.120921  \n",
       "7755  0.508838  0.289577  0.384660 -0.194955  0.296642  0.106905 -0.120921  \n",
       "7756  0.508838  0.289577  0.384660 -0.194955  0.296642  0.106905 -0.120921  \n",
       "7757  0.493256  0.297104  0.419325 -0.291666  0.335292  0.182556 -0.052409  \n",
       "7758  0.391883  0.277369  0.287159 -0.261535  0.210903  0.199086 -0.114386  \n",
       "\n",
       "[7759 rows x 59 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#attach nlp to xy_df \n",
    "def attach_nlp(xy_df, df_nlp):\n",
    "    #correct formatting for df_nlp \n",
    "    df_nlp = string_to_tuple(df_nlp, 'grid_id')\n",
    "    #drop text, location and label columns \n",
    "    df_nlp = df_nlp.drop(['location','txt','label','flood_ct_x'], axis=1)\n",
    "    #add prefix \n",
    "    df_nlp = df_nlp.rename(columns={c: 'nlp_' + str(c) for c in df_nlp.columns if c not in ['grid_id']})\n",
    "    #merge \n",
    "    xy_df_out = pd.merge(xy_df, df_nlp , on='grid_id', how='left')\n",
    "    print('shape of xy_df with nlp features', xy_df_out.shape)\n",
    "    return xy_df_out \n",
    "\n",
    "attach_nlp(xy_df, df_nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attach ERA features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read era_features (ran from above cell)\n",
    "df_era = pd.read_csv('era_features.csv', index_col=0)\n",
    "df_era['grid_id'] = list(zip(df_era['lat'],df_era['long']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of xy_df with era features (45878, 279)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_id</th>\n",
       "      <th>year</th>\n",
       "      <th>flood_amt</th>\n",
       "      <th>storm_amt</th>\n",
       "      <th>earthquake_amt</th>\n",
       "      <th>extreme temperature _amt</th>\n",
       "      <th>landslide_amt</th>\n",
       "      <th>volcanic activity_amt</th>\n",
       "      <th>drought_amt</th>\n",
       "      <th>mass movement (dry)_amt</th>\n",
       "      <th>...</th>\n",
       "      <th>era_12_minimum_2m_air_temperature_y</th>\n",
       "      <th>era_12_maximum_2m_air_temperature_y</th>\n",
       "      <th>era_12_dewpoint_2m_temperature_y</th>\n",
       "      <th>era_12_total_precipitation_y</th>\n",
       "      <th>era_12_surface_pressure_y</th>\n",
       "      <th>era_12_mean_sea_level_pressure_y</th>\n",
       "      <th>era_12_u_component_of_wind_10m_y</th>\n",
       "      <th>era_12_v_component_of_wind_10m_y</th>\n",
       "      <th>era_lat_y</th>\n",
       "      <th>era_long_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(-46, 168)</td>\n",
       "      <td>1960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(-46, 168)</td>\n",
       "      <td>1961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(-46, 168)</td>\n",
       "      <td>1962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(-46, 168)</td>\n",
       "      <td>1963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(-46, 168)</td>\n",
       "      <td>1964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45873</th>\n",
       "      <td>(66, 130)</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45874</th>\n",
       "      <td>(66, 130)</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45875</th>\n",
       "      <td>(66, 130)</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45876</th>\n",
       "      <td>(66, 130)</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45877</th>\n",
       "      <td>(66, 130)</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45878 rows × 279 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          grid_id  year  flood_amt  storm_amt  earthquake_amt  \\\n",
       "0      (-46, 168)  1960        0.0        0.0             0.0   \n",
       "1      (-46, 168)  1961        0.0        0.0             0.0   \n",
       "2      (-46, 168)  1962        0.0        0.0             0.0   \n",
       "3      (-46, 168)  1963        0.0        0.0             0.0   \n",
       "4      (-46, 168)  1964        0.0        0.0             0.0   \n",
       "...           ...   ...        ...        ...             ...   \n",
       "45873   (66, 130)  2013        0.0        0.0             0.0   \n",
       "45874   (66, 130)  2014        0.0        0.0             0.0   \n",
       "45875   (66, 130)  2015        0.0        0.0             0.0   \n",
       "45876   (66, 130)  2016        0.0        0.0             0.0   \n",
       "45877   (66, 130)  2017        0.0        0.0             0.0   \n",
       "\n",
       "       extreme temperature _amt  landslide_amt  volcanic activity_amt  \\\n",
       "0                           0.0            0.0                    0.0   \n",
       "1                           0.0            0.0                    0.0   \n",
       "2                           0.0            0.0                    0.0   \n",
       "3                           0.0            0.0                    0.0   \n",
       "4                           0.0            0.0                    0.0   \n",
       "...                         ...            ...                    ...   \n",
       "45873                       0.0            0.0                    0.0   \n",
       "45874                       0.0            0.0                    0.0   \n",
       "45875                       0.0            0.0                    0.0   \n",
       "45876                       0.0            0.0                    0.0   \n",
       "45877                       0.0            0.0                    0.0   \n",
       "\n",
       "       drought_amt  mass movement (dry)_amt  ...  \\\n",
       "0              0.0                      0.0  ...   \n",
       "1              0.0                      0.0  ...   \n",
       "2              0.0                      0.0  ...   \n",
       "3              0.0                      0.0  ...   \n",
       "4              0.0                      0.0  ...   \n",
       "...            ...                      ...  ...   \n",
       "45873          0.0                      0.0  ...   \n",
       "45874          0.0                      0.0  ...   \n",
       "45875          0.0                      0.0  ...   \n",
       "45876          0.0                      0.0  ...   \n",
       "45877          0.0                      0.0  ...   \n",
       "\n",
       "       era_12_minimum_2m_air_temperature_y  \\\n",
       "0                                      NaN   \n",
       "1                                      NaN   \n",
       "2                                      NaN   \n",
       "3                                      NaN   \n",
       "4                                      NaN   \n",
       "...                                    ...   \n",
       "45873                                  NaN   \n",
       "45874                                  NaN   \n",
       "45875                                  NaN   \n",
       "45876                                  NaN   \n",
       "45877                                  NaN   \n",
       "\n",
       "       era_12_maximum_2m_air_temperature_y  era_12_dewpoint_2m_temperature_y  \\\n",
       "0                                      NaN                               NaN   \n",
       "1                                      NaN                               NaN   \n",
       "2                                      NaN                               NaN   \n",
       "3                                      NaN                               NaN   \n",
       "4                                      NaN                               NaN   \n",
       "...                                    ...                               ...   \n",
       "45873                                  NaN                               NaN   \n",
       "45874                                  NaN                               NaN   \n",
       "45875                                  NaN                               NaN   \n",
       "45876                                  NaN                               NaN   \n",
       "45877                                  NaN                               NaN   \n",
       "\n",
       "       era_12_total_precipitation_y  era_12_surface_pressure_y  \\\n",
       "0                               NaN                        NaN   \n",
       "1                               NaN                        NaN   \n",
       "2                               NaN                        NaN   \n",
       "3                               NaN                        NaN   \n",
       "4                               NaN                        NaN   \n",
       "...                             ...                        ...   \n",
       "45873                           NaN                        NaN   \n",
       "45874                           NaN                        NaN   \n",
       "45875                           NaN                        NaN   \n",
       "45876                           NaN                        NaN   \n",
       "45877                           NaN                        NaN   \n",
       "\n",
       "       era_12_mean_sea_level_pressure_y  era_12_u_component_of_wind_10m_y  \\\n",
       "0                                   NaN                               NaN   \n",
       "1                                   NaN                               NaN   \n",
       "2                                   NaN                               NaN   \n",
       "3                                   NaN                               NaN   \n",
       "4                                   NaN                               NaN   \n",
       "...                                 ...                               ...   \n",
       "45873                               NaN                               NaN   \n",
       "45874                               NaN                               NaN   \n",
       "45875                               NaN                               NaN   \n",
       "45876                               NaN                               NaN   \n",
       "45877                               NaN                               NaN   \n",
       "\n",
       "       era_12_v_component_of_wind_10m_y  era_lat_y  era_long_y  \n",
       "0                                   NaN        NaN         NaN  \n",
       "1                                   NaN        NaN         NaN  \n",
       "2                                   NaN        NaN         NaN  \n",
       "3                                   NaN        NaN         NaN  \n",
       "4                                   NaN        NaN         NaN  \n",
       "...                                 ...        ...         ...  \n",
       "45873                               NaN        NaN         NaN  \n",
       "45874                               NaN        NaN         NaN  \n",
       "45875                               NaN        NaN         NaN  \n",
       "45876                               NaN        NaN         NaN  \n",
       "45877                               NaN        NaN         NaN  \n",
       "\n",
       "[45878 rows x 279 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#attach era features\n",
    "def attach_era(xy_df, df_era):\n",
    "    #add prefix \n",
    "    df_era = df_era.rename(columns={c: 'era_' + c for c in df_era.columns if c not in ['grid_id','year']})\n",
    "    xy_df_out = pd.merge(xy_df, df_era, on=['grid_id','year'], how='left')\n",
    "    print('shape of xy_df with era features', xy_df_out.shape)\n",
    "    return xy_df_out\n",
    "\n",
    "attach_era(xy_df, df_era)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pwd\n",
    "import sys\n",
    "# setting path\n",
    "sys.path.append('../src')\n",
    "\n",
    "#import model training module \n",
    "import models as m \n",
    "\n",
    "#split training and testing \n",
    "from sklearn.model_selection import train_test_split\n",
    "# import shap\n",
    "from sklearn import metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attach target for a particular disease for next n years, using y_master  \n",
    "#next_n is how we choose the next n-periods for the prediction target\n",
    "def attach_target(x_df, y_master, disaster, next_n): \n",
    "    y = y_master.copy()\n",
    "    #shift years\n",
    "    y['year'] = y['year'] - next_n\n",
    "    #keep for particular disaster \n",
    "    y = y[['grid_id','year',disaster+'_bin']]\n",
    "    # Rename into target\n",
    "    y = y.rename(columns={disaster +'_bin': 'target_' + disaster + '_'+ str(next_n)})\n",
    "    xy_df = pd.merge(x_df, y, on = ['grid_id','year'], how='inner')\n",
    "    return xy_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of x_df 46669\n",
      "shape of xy_df with nlp features (46669, 58)\n"
     ]
    }
   ],
   "source": [
    "#construct x_df with various modalities: stat, nlp, era features \n",
    "\n",
    "#select to those id pass the filtering criteria \n",
    "x_df = df_yrly.loc[df_yrly['grid_id'].isin(grid_id_ls)]\n",
    "#interpolate missing years to have no flood \n",
    "x_df = pd.merge(idd, x_df, on=['grid_id','year'], how='left').fillna(0)\n",
    "\n",
    "print('length of x_df', len(x_df))\n",
    "\n",
    "#attach nlp features \n",
    "x_df = attach_nlp(x_df, df_nlp)\n",
    "# #attach era features \n",
    "# x_df = attach_era(x_df, df_era)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of xy_df with era features (46669, 278)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_id</th>\n",
       "      <th>year</th>\n",
       "      <th>flood_amt</th>\n",
       "      <th>storm_amt</th>\n",
       "      <th>earthquake_amt</th>\n",
       "      <th>extreme temperature _amt</th>\n",
       "      <th>landslide_amt</th>\n",
       "      <th>volcanic activity_amt</th>\n",
       "      <th>drought_amt</th>\n",
       "      <th>mass movement (dry)_amt</th>\n",
       "      <th>...</th>\n",
       "      <th>era_12_minimum_2m_air_temperature_y</th>\n",
       "      <th>era_12_maximum_2m_air_temperature_y</th>\n",
       "      <th>era_12_dewpoint_2m_temperature_y</th>\n",
       "      <th>era_12_total_precipitation_y</th>\n",
       "      <th>era_12_surface_pressure_y</th>\n",
       "      <th>era_12_mean_sea_level_pressure_y</th>\n",
       "      <th>era_12_u_component_of_wind_10m_y</th>\n",
       "      <th>era_12_v_component_of_wind_10m_y</th>\n",
       "      <th>era_lat_y</th>\n",
       "      <th>era_long_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(-46, 168)</td>\n",
       "      <td>1960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(-46, 168)</td>\n",
       "      <td>1961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(-46, 168)</td>\n",
       "      <td>1962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(-46, 168)</td>\n",
       "      <td>1963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(-46, 168)</td>\n",
       "      <td>1964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46664</th>\n",
       "      <td>(66, 130)</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46665</th>\n",
       "      <td>(66, 130)</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46666</th>\n",
       "      <td>(66, 130)</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46667</th>\n",
       "      <td>(66, 130)</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46668</th>\n",
       "      <td>(66, 130)</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46669 rows × 278 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          grid_id  year  flood_amt  storm_amt  earthquake_amt  \\\n",
       "0      (-46, 168)  1960        0.0        0.0             0.0   \n",
       "1      (-46, 168)  1961        0.0        0.0             0.0   \n",
       "2      (-46, 168)  1962        0.0        0.0             0.0   \n",
       "3      (-46, 168)  1963        0.0        0.0             0.0   \n",
       "4      (-46, 168)  1964        0.0        0.0             0.0   \n",
       "...           ...   ...        ...        ...             ...   \n",
       "46664   (66, 130)  2014        0.0        0.0             0.0   \n",
       "46665   (66, 130)  2015        0.0        0.0             0.0   \n",
       "46666   (66, 130)  2016        0.0        0.0             0.0   \n",
       "46667   (66, 130)  2017        0.0        0.0             0.0   \n",
       "46668   (66, 130)  2018        0.0        0.0             0.0   \n",
       "\n",
       "       extreme temperature _amt  landslide_amt  volcanic activity_amt  \\\n",
       "0                           0.0            0.0                    0.0   \n",
       "1                           0.0            0.0                    0.0   \n",
       "2                           0.0            0.0                    0.0   \n",
       "3                           0.0            0.0                    0.0   \n",
       "4                           0.0            0.0                    0.0   \n",
       "...                         ...            ...                    ...   \n",
       "46664                       0.0            0.0                    0.0   \n",
       "46665                       0.0            0.0                    0.0   \n",
       "46666                       0.0            0.0                    0.0   \n",
       "46667                       0.0            0.0                    0.0   \n",
       "46668                       0.0            0.0                    0.0   \n",
       "\n",
       "       drought_amt  mass movement (dry)_amt  ...  \\\n",
       "0              0.0                      0.0  ...   \n",
       "1              0.0                      0.0  ...   \n",
       "2              0.0                      0.0  ...   \n",
       "3              0.0                      0.0  ...   \n",
       "4              0.0                      0.0  ...   \n",
       "...            ...                      ...  ...   \n",
       "46664          0.0                      0.0  ...   \n",
       "46665          0.0                      0.0  ...   \n",
       "46666          0.0                      0.0  ...   \n",
       "46667          0.0                      0.0  ...   \n",
       "46668          0.0                      0.0  ...   \n",
       "\n",
       "       era_12_minimum_2m_air_temperature_y  \\\n",
       "0                                      NaN   \n",
       "1                                      NaN   \n",
       "2                                      NaN   \n",
       "3                                      NaN   \n",
       "4                                      NaN   \n",
       "...                                    ...   \n",
       "46664                                  NaN   \n",
       "46665                                  NaN   \n",
       "46666                                  NaN   \n",
       "46667                                  NaN   \n",
       "46668                                  NaN   \n",
       "\n",
       "       era_12_maximum_2m_air_temperature_y  era_12_dewpoint_2m_temperature_y  \\\n",
       "0                                      NaN                               NaN   \n",
       "1                                      NaN                               NaN   \n",
       "2                                      NaN                               NaN   \n",
       "3                                      NaN                               NaN   \n",
       "4                                      NaN                               NaN   \n",
       "...                                    ...                               ...   \n",
       "46664                                  NaN                               NaN   \n",
       "46665                                  NaN                               NaN   \n",
       "46666                                  NaN                               NaN   \n",
       "46667                                  NaN                               NaN   \n",
       "46668                                  NaN                               NaN   \n",
       "\n",
       "       era_12_total_precipitation_y  era_12_surface_pressure_y  \\\n",
       "0                               NaN                        NaN   \n",
       "1                               NaN                        NaN   \n",
       "2                               NaN                        NaN   \n",
       "3                               NaN                        NaN   \n",
       "4                               NaN                        NaN   \n",
       "...                             ...                        ...   \n",
       "46664                           NaN                        NaN   \n",
       "46665                           NaN                        NaN   \n",
       "46666                           NaN                        NaN   \n",
       "46667                           NaN                        NaN   \n",
       "46668                           NaN                        NaN   \n",
       "\n",
       "       era_12_mean_sea_level_pressure_y  era_12_u_component_of_wind_10m_y  \\\n",
       "0                                   NaN                               NaN   \n",
       "1                                   NaN                               NaN   \n",
       "2                                   NaN                               NaN   \n",
       "3                                   NaN                               NaN   \n",
       "4                                   NaN                               NaN   \n",
       "...                                 ...                               ...   \n",
       "46664                               NaN                               NaN   \n",
       "46665                               NaN                               NaN   \n",
       "46666                               NaN                               NaN   \n",
       "46667                               NaN                               NaN   \n",
       "46668                               NaN                               NaN   \n",
       "\n",
       "       era_12_v_component_of_wind_10m_y  era_lat_y  era_long_y  \n",
       "0                                   NaN        NaN         NaN  \n",
       "1                                   NaN        NaN         NaN  \n",
       "2                                   NaN        NaN         NaN  \n",
       "3                                   NaN        NaN         NaN  \n",
       "4                                   NaN        NaN         NaN  \n",
       "...                                 ...        ...         ...  \n",
       "46664                               NaN        NaN         NaN  \n",
       "46665                               NaN        NaN         NaN  \n",
       "46666                               NaN        NaN         NaN  \n",
       "46667                               NaN        NaN         NaN  \n",
       "46668                               NaN        NaN         NaN  \n",
       "\n",
       "[46669 rows x 278 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_df\n",
    "#attach era features \n",
    "x_df = attach_era(x_df, df_era)\n",
    "x_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1_mean_2m_air_temperature</th>\n",
       "      <th>1_minimum_2m_air_temperature</th>\n",
       "      <th>1_maximum_2m_air_temperature</th>\n",
       "      <th>1_dewpoint_2m_temperature</th>\n",
       "      <th>1_total_precipitation</th>\n",
       "      <th>1_surface_pressure</th>\n",
       "      <th>1_mean_sea_level_pressure</th>\n",
       "      <th>1_u_component_of_wind_10m</th>\n",
       "      <th>1_v_component_of_wind_10m</th>\n",
       "      <th>2_mean_2m_air_temperature</th>\n",
       "      <th>...</th>\n",
       "      <th>12_dewpoint_2m_temperature</th>\n",
       "      <th>12_total_precipitation</th>\n",
       "      <th>12_surface_pressure</th>\n",
       "      <th>12_mean_sea_level_pressure</th>\n",
       "      <th>12_u_component_of_wind_10m</th>\n",
       "      <th>12_v_component_of_wind_10m</th>\n",
       "      <th>year</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>grid_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>280.732391</td>\n",
       "      <td>276.481750</td>\n",
       "      <td>286.436157</td>\n",
       "      <td>277.461914</td>\n",
       "      <td>0.182955</td>\n",
       "      <td>97196.718750</td>\n",
       "      <td>100086.515625</td>\n",
       "      <td>4.649180</td>\n",
       "      <td>-0.568458</td>\n",
       "      <td>282.632080</td>\n",
       "      <td>...</td>\n",
       "      <td>276.148590</td>\n",
       "      <td>0.133512</td>\n",
       "      <td>97371.992188</td>\n",
       "      <td>100277.859375</td>\n",
       "      <td>4.096223</td>\n",
       "      <td>-0.112465</td>\n",
       "      <td>1990</td>\n",
       "      <td>-54</td>\n",
       "      <td>-72</td>\n",
       "      <td>(-54, -72)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>279.195557</td>\n",
       "      <td>271.100372</td>\n",
       "      <td>290.727417</td>\n",
       "      <td>276.204803</td>\n",
       "      <td>0.287271</td>\n",
       "      <td>90187.007812</td>\n",
       "      <td>100793.093750</td>\n",
       "      <td>2.730071</td>\n",
       "      <td>-1.450440</td>\n",
       "      <td>281.566498</td>\n",
       "      <td>...</td>\n",
       "      <td>275.571167</td>\n",
       "      <td>0.253060</td>\n",
       "      <td>90203.921875</td>\n",
       "      <td>100820.429688</td>\n",
       "      <td>2.443160</td>\n",
       "      <td>-1.339134</td>\n",
       "      <td>2017</td>\n",
       "      <td>-49</td>\n",
       "      <td>-73</td>\n",
       "      <td>(-49, -73)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>286.905273</td>\n",
       "      <td>275.971741</td>\n",
       "      <td>299.562683</td>\n",
       "      <td>274.170776</td>\n",
       "      <td>0.021335</td>\n",
       "      <td>92155.750000</td>\n",
       "      <td>100647.632812</td>\n",
       "      <td>5.395926</td>\n",
       "      <td>-1.747644</td>\n",
       "      <td>286.351410</td>\n",
       "      <td>...</td>\n",
       "      <td>269.993988</td>\n",
       "      <td>0.032401</td>\n",
       "      <td>91627.937500</td>\n",
       "      <td>100194.570312</td>\n",
       "      <td>5.218695</td>\n",
       "      <td>-1.139208</td>\n",
       "      <td>1991</td>\n",
       "      <td>-49</td>\n",
       "      <td>-70</td>\n",
       "      <td>(-49, -70)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>283.893646</td>\n",
       "      <td>274.633179</td>\n",
       "      <td>295.927734</td>\n",
       "      <td>279.956207</td>\n",
       "      <td>0.112344</td>\n",
       "      <td>93330.679688</td>\n",
       "      <td>101365.687500</td>\n",
       "      <td>1.874738</td>\n",
       "      <td>-0.753395</td>\n",
       "      <td>282.869995</td>\n",
       "      <td>...</td>\n",
       "      <td>278.860962</td>\n",
       "      <td>0.193761</td>\n",
       "      <td>93280.343750</td>\n",
       "      <td>101359.429688</td>\n",
       "      <td>2.096800</td>\n",
       "      <td>-0.883072</td>\n",
       "      <td>2007</td>\n",
       "      <td>-46</td>\n",
       "      <td>-73</td>\n",
       "      <td>(-46, -73)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>282.626709</td>\n",
       "      <td>274.491669</td>\n",
       "      <td>291.303619</td>\n",
       "      <td>279.329773</td>\n",
       "      <td>0.305667</td>\n",
       "      <td>93043.046875</td>\n",
       "      <td>101109.804688</td>\n",
       "      <td>2.263980</td>\n",
       "      <td>-1.185996</td>\n",
       "      <td>282.552338</td>\n",
       "      <td>...</td>\n",
       "      <td>277.970123</td>\n",
       "      <td>0.245718</td>\n",
       "      <td>92992.773438</td>\n",
       "      <td>101092.289062</td>\n",
       "      <td>2.298511</td>\n",
       "      <td>-0.999548</td>\n",
       "      <td>2010</td>\n",
       "      <td>-46</td>\n",
       "      <td>-73</td>\n",
       "      <td>(-46, -73)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7972</th>\n",
       "      <td>235.834885</td>\n",
       "      <td>222.739182</td>\n",
       "      <td>251.434311</td>\n",
       "      <td>232.512177</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>93440.148438</td>\n",
       "      <td>102651.304688</td>\n",
       "      <td>0.514051</td>\n",
       "      <td>0.670460</td>\n",
       "      <td>240.236725</td>\n",
       "      <td>...</td>\n",
       "      <td>229.950821</td>\n",
       "      <td>0.004996</td>\n",
       "      <td>92814.562500</td>\n",
       "      <td>101953.828125</td>\n",
       "      <td>0.499564</td>\n",
       "      <td>1.215622</td>\n",
       "      <td>1998</td>\n",
       "      <td>66</td>\n",
       "      <td>130</td>\n",
       "      <td>(66, 130)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7973</th>\n",
       "      <td>238.504425</td>\n",
       "      <td>223.017487</td>\n",
       "      <td>259.830963</td>\n",
       "      <td>235.215561</td>\n",
       "      <td>0.003875</td>\n",
       "      <td>92749.226562</td>\n",
       "      <td>101773.632812</td>\n",
       "      <td>1.406846</td>\n",
       "      <td>1.488987</td>\n",
       "      <td>235.905975</td>\n",
       "      <td>...</td>\n",
       "      <td>234.151413</td>\n",
       "      <td>0.004338</td>\n",
       "      <td>92871.890625</td>\n",
       "      <td>101969.570312</td>\n",
       "      <td>0.655941</td>\n",
       "      <td>1.295936</td>\n",
       "      <td>2007</td>\n",
       "      <td>66</td>\n",
       "      <td>130</td>\n",
       "      <td>(66, 130)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7974</th>\n",
       "      <td>236.635864</td>\n",
       "      <td>224.434296</td>\n",
       "      <td>254.942383</td>\n",
       "      <td>233.412125</td>\n",
       "      <td>0.005831</td>\n",
       "      <td>93840.953125</td>\n",
       "      <td>103060.304688</td>\n",
       "      <td>0.698611</td>\n",
       "      <td>1.081600</td>\n",
       "      <td>238.844528</td>\n",
       "      <td>...</td>\n",
       "      <td>234.401718</td>\n",
       "      <td>0.005005</td>\n",
       "      <td>93443.507812</td>\n",
       "      <td>102624.578125</td>\n",
       "      <td>1.094045</td>\n",
       "      <td>0.911866</td>\n",
       "      <td>2012</td>\n",
       "      <td>66</td>\n",
       "      <td>130</td>\n",
       "      <td>(66, 130)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7975</th>\n",
       "      <td>245.251770</td>\n",
       "      <td>231.130249</td>\n",
       "      <td>258.097565</td>\n",
       "      <td>241.889053</td>\n",
       "      <td>0.007374</td>\n",
       "      <td>101070.218750</td>\n",
       "      <td>101287.226562</td>\n",
       "      <td>-0.455457</td>\n",
       "      <td>0.971647</td>\n",
       "      <td>254.961594</td>\n",
       "      <td>...</td>\n",
       "      <td>251.950745</td>\n",
       "      <td>0.013709</td>\n",
       "      <td>100066.625000</td>\n",
       "      <td>100276.078125</td>\n",
       "      <td>-0.825087</td>\n",
       "      <td>0.420770</td>\n",
       "      <td>2006</td>\n",
       "      <td>68</td>\n",
       "      <td>-135</td>\n",
       "      <td>(68, -135)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7976</th>\n",
       "      <td>265.334961</td>\n",
       "      <td>248.547745</td>\n",
       "      <td>274.293243</td>\n",
       "      <td>263.763702</td>\n",
       "      <td>0.055944</td>\n",
       "      <td>95971.828125</td>\n",
       "      <td>99795.968750</td>\n",
       "      <td>-0.068817</td>\n",
       "      <td>2.343028</td>\n",
       "      <td>263.356995</td>\n",
       "      <td>...</td>\n",
       "      <td>261.303558</td>\n",
       "      <td>0.034403</td>\n",
       "      <td>97536.578125</td>\n",
       "      <td>101447.695312</td>\n",
       "      <td>0.067387</td>\n",
       "      <td>0.321785</td>\n",
       "      <td>2005</td>\n",
       "      <td>68</td>\n",
       "      <td>26</td>\n",
       "      <td>(68, 26)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7977 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1_mean_2m_air_temperature  1_minimum_2m_air_temperature  \\\n",
       "0                    280.732391                    276.481750   \n",
       "1                    279.195557                    271.100372   \n",
       "2                    286.905273                    275.971741   \n",
       "3                    283.893646                    274.633179   \n",
       "4                    282.626709                    274.491669   \n",
       "...                         ...                           ...   \n",
       "7972                 235.834885                    222.739182   \n",
       "7973                 238.504425                    223.017487   \n",
       "7974                 236.635864                    224.434296   \n",
       "7975                 245.251770                    231.130249   \n",
       "7976                 265.334961                    248.547745   \n",
       "\n",
       "      1_maximum_2m_air_temperature  1_dewpoint_2m_temperature  \\\n",
       "0                       286.436157                 277.461914   \n",
       "1                       290.727417                 276.204803   \n",
       "2                       299.562683                 274.170776   \n",
       "3                       295.927734                 279.956207   \n",
       "4                       291.303619                 279.329773   \n",
       "...                            ...                        ...   \n",
       "7972                    251.434311                 232.512177   \n",
       "7973                    259.830963                 235.215561   \n",
       "7974                    254.942383                 233.412125   \n",
       "7975                    258.097565                 241.889053   \n",
       "7976                    274.293243                 263.763702   \n",
       "\n",
       "      1_total_precipitation  1_surface_pressure  1_mean_sea_level_pressure  \\\n",
       "0                  0.182955        97196.718750              100086.515625   \n",
       "1                  0.287271        90187.007812              100793.093750   \n",
       "2                  0.021335        92155.750000              100647.632812   \n",
       "3                  0.112344        93330.679688              101365.687500   \n",
       "4                  0.305667        93043.046875              101109.804688   \n",
       "...                     ...                 ...                        ...   \n",
       "7972               0.006969        93440.148438              102651.304688   \n",
       "7973               0.003875        92749.226562              101773.632812   \n",
       "7974               0.005831        93840.953125              103060.304688   \n",
       "7975               0.007374       101070.218750              101287.226562   \n",
       "7976               0.055944        95971.828125               99795.968750   \n",
       "\n",
       "      1_u_component_of_wind_10m  1_v_component_of_wind_10m  \\\n",
       "0                      4.649180                  -0.568458   \n",
       "1                      2.730071                  -1.450440   \n",
       "2                      5.395926                  -1.747644   \n",
       "3                      1.874738                  -0.753395   \n",
       "4                      2.263980                  -1.185996   \n",
       "...                         ...                        ...   \n",
       "7972                   0.514051                   0.670460   \n",
       "7973                   1.406846                   1.488987   \n",
       "7974                   0.698611                   1.081600   \n",
       "7975                  -0.455457                   0.971647   \n",
       "7976                  -0.068817                   2.343028   \n",
       "\n",
       "      2_mean_2m_air_temperature  ...  12_dewpoint_2m_temperature  \\\n",
       "0                    282.632080  ...                  276.148590   \n",
       "1                    281.566498  ...                  275.571167   \n",
       "2                    286.351410  ...                  269.993988   \n",
       "3                    282.869995  ...                  278.860962   \n",
       "4                    282.552338  ...                  277.970123   \n",
       "...                         ...  ...                         ...   \n",
       "7972                 240.236725  ...                  229.950821   \n",
       "7973                 235.905975  ...                  234.151413   \n",
       "7974                 238.844528  ...                  234.401718   \n",
       "7975                 254.961594  ...                  251.950745   \n",
       "7976                 263.356995  ...                  261.303558   \n",
       "\n",
       "      12_total_precipitation  12_surface_pressure  12_mean_sea_level_pressure  \\\n",
       "0                   0.133512         97371.992188               100277.859375   \n",
       "1                   0.253060         90203.921875               100820.429688   \n",
       "2                   0.032401         91627.937500               100194.570312   \n",
       "3                   0.193761         93280.343750               101359.429688   \n",
       "4                   0.245718         92992.773438               101092.289062   \n",
       "...                      ...                  ...                         ...   \n",
       "7972                0.004996         92814.562500               101953.828125   \n",
       "7973                0.004338         92871.890625               101969.570312   \n",
       "7974                0.005005         93443.507812               102624.578125   \n",
       "7975                0.013709        100066.625000               100276.078125   \n",
       "7976                0.034403         97536.578125               101447.695312   \n",
       "\n",
       "      12_u_component_of_wind_10m  12_v_component_of_wind_10m  year  lat  long  \\\n",
       "0                       4.096223                   -0.112465  1990  -54   -72   \n",
       "1                       2.443160                   -1.339134  2017  -49   -73   \n",
       "2                       5.218695                   -1.139208  1991  -49   -70   \n",
       "3                       2.096800                   -0.883072  2007  -46   -73   \n",
       "4                       2.298511                   -0.999548  2010  -46   -73   \n",
       "...                          ...                         ...   ...  ...   ...   \n",
       "7972                    0.499564                    1.215622  1998   66   130   \n",
       "7973                    0.655941                    1.295936  2007   66   130   \n",
       "7974                    1.094045                    0.911866  2012   66   130   \n",
       "7975                   -0.825087                    0.420770  2006   68  -135   \n",
       "7976                    0.067387                    0.321785  2005   68    26   \n",
       "\n",
       "         grid_id  \n",
       "0     (-54, -72)  \n",
       "1     (-49, -73)  \n",
       "2     (-49, -70)  \n",
       "3     (-46, -73)  \n",
       "4     (-46, -73)  \n",
       "...          ...  \n",
       "7972   (66, 130)  \n",
       "7973   (66, 130)  \n",
       "7974   (66, 130)  \n",
       "7975  (68, -135)  \n",
       "7976    (68, 26)  \n",
       "\n",
       "[7977 rows x 112 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_era"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of xy_df 45878\n",
      "imbalance target_flood_1    0.060639\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#construct xy_df, depending on the n_pred target period \n",
    "n_pred = 1\n",
    "\n",
    "xy_df = attach_target(x_df, y_master, 'flood', n_pred)\n",
    "print('length of xy_df', len(xy_df))\n",
    "print('imbalance', xy_df.filter(regex='target').sum()/len(xy_df))\n",
    "\n",
    "#construct x,y train and test set \n",
    "x = xy_df.drop(xy_df.filter(regex='target').columns, axis=1)#drop target col \n",
    "x = x.select_dtypes(['number'])#drop index col\n",
    "y = xy_df.filter(regex='target') #filter to cols containing target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stat features only \n",
    "x_stat = x.drop(x.filter(regex='nlp').columns, axis=1)#drop nlp features  \n",
    "x_stat = x_stat.drop(x.filter(regex='era').columns, axis=1)#drop era features \n",
    "\n",
    "#stat + era \n",
    "x_stat_era = x.drop(x.filter(regex='nlp').columns, axis=1)#drop nlp features  \n",
    "\n",
    "#stat + nlp \n",
    "x_stat_nlp = x.drop(x.filter(regex='era').columns, axis=1)#drop nlp features  \n",
    "\n",
    "#stat + nlp + era \n",
    "x_stat_nlp_era = x.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_models(x, y):\n",
    "    results={}\n",
    "\n",
    "    #train_test_split \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "    print(x_train.shape) #x_train contains stat features only \n",
    "    \n",
    "    #try a dumb model predicting just zeros , we are just guessing no flood!\n",
    "    y_base = np.zeros(len(y_test)) \n",
    "    print('Dumb baseline AUC', metrics.roc_auc_score(y_test,y_base))\n",
    "    results['base1']=m.get_scores_clf(y_test,y_base)\n",
    "\n",
    "    #try a less dumb model predicting outcome = current flood outcome \n",
    "    y_base2 = x_test['flood_bin'] \n",
    "    print('Dumb baseline 2 AUC', metrics.roc_auc_score(y_test,y_base2))\n",
    "    results['base2']= m.get_scores_clf(y_test,y_base2)\n",
    "    \n",
    "    #logreg model \n",
    "    y_pred, y_pred_prob = m.run_logreg(x_train, y_train, x_test)\n",
    "    results['logreg'] = m.get_scores_clf(y_test, y_pred_prob)\n",
    "    # print('Test AUC', metrics.roc_auc_score(y_test, y_pred_prob))\n",
    "    \n",
    "    y_pred, y_pred_prob = m.run_xgb(x_train, y_train, x_test)\n",
    "    results['xgb'] = m.get_scores_clf(y_test, y_pred_prob)\n",
    "\n",
    "    return results \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45878, 167)\n",
      "(32114, 167)\n",
      "Dumb baseline AUC 0.5\n",
      "maximum f1 score, thres 0.48441714114474077 0.4\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.5 0.48441714114474077 0.9395524556814879 0.5 0.06044754431851206 0.0\n",
      "[[12932     0]\n",
      " [  832     0]]\n",
      "Dumb baseline 2 AUC 0.5551864114658926\n",
      "maximum f1 score, thres 0.5559981154419161 0.4\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.5551864114658926 0.5559981154419161 0.9006102877070619 0.5551864114658925 0.07781682803007245 0.1622596153846154\n",
      "[[12261   671]\n",
      " [  697   135]]\n",
      "running log reg...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [136]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_i \u001b[38;5;129;01min\u001b[39;00m [x_stat_nlp_era, x_stat, x_stat_era, x_stat_nlp]: \n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x_i\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mrun_all_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [133]\u001b[0m, in \u001b[0;36mrun_all_models\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     16\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mget_scores_clf(y_test,y_base2)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#logreg model \u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m y_pred, y_pred_prob \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_logreg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogreg\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mget_scores_clf(y_test, y_pred_prob)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# print('Test AUC', metrics.roc_auc_score(y_test, y_pred_prob))\u001b[39;00m\n",
      "File \u001b[0;32m~/flood/nbs/oscar/models.py:56\u001b[0m, in \u001b[0;36mrun_logreg\u001b[0;34m(x_train, y_train, x_test)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m#grid search\u001b[39;00m\n\u001b[1;32m     55\u001b[0m gs \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator \u001b[38;5;241m=\u001b[39m est, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, scoring\u001b[38;5;241m=\u001b[39mgs_metric, cv\u001b[38;5;241m=\u001b[39m cv_folds, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m \u001b[43mgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m#training auc\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain AUC: \u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m.\u001b[39mroc_auc_score(y_train, gs\u001b[38;5;241m.\u001b[39mpredict_proba(x_train)[:,\u001b[38;5;241m1\u001b[39m]))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:73\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m as keyword args. From version 0.25 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassing these as positional arguments will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult in an error\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(args_msg)),\n\u001b[1;32m     71\u001b[0m                   \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[1;32m     72\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate({k: arg \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args)})\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:765\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    763\u001b[0m refit_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_estimator_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    767\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1342\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1340\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m-> 1342\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m                           \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m                           \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1345\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:432\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 432\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    433\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:73\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m as keyword args. From version 0.25 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassing these as positional arguments will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult in an error\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(args_msg)),\n\u001b[1;32m     71\u001b[0m                   \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[1;32m     72\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate({k: arg \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args)})\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:796\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    794\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 796\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m                \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m                \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m                \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m                \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m                \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m                \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_output:\n\u001b[1;32m    805\u001b[0m     y \u001b[38;5;241m=\u001b[39m check_array(y, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m'\u001b[39m, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    806\u001b[0m                     ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:73\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m as keyword args. From version 0.25 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassing these as positional arguments will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult in an error\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(args_msg)),\n\u001b[1;32m     71\u001b[0m                   \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[1;32m     72\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate({k: arg \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args)})\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:645\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    642\u001b[0m                          \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name))\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 645\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    649\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:97\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (allow_nan \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misinf(X)\u001b[38;5;241m.\u001b[39many() \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m     95\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(X)\u001b[38;5;241m.\u001b[39mall()):\n\u001b[1;32m     96\u001b[0m         type_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minfinity\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_nan \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNaN, infinity\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 97\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     98\u001b[0m                 msg_err\u001b[38;5;241m.\u001b[39mformat\n\u001b[1;32m     99\u001b[0m                 (type_err,\n\u001b[1;32m    100\u001b[0m                  msg_dtype \u001b[38;5;28;01mif\u001b[39;00m msg_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    101\u001b[0m         )\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "for x_i in [x_stat_nlp_era, x_stat, x_stat_era, x_stat_nlp]: \n",
    "    print('x_i shape', x_i.shape)\n",
    "    run_all_models(x_i,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>flood_amt</th>\n",
       "      <th>storm_amt</th>\n",
       "      <th>earthquake_amt</th>\n",
       "      <th>extreme temperature _amt</th>\n",
       "      <th>landslide_amt</th>\n",
       "      <th>volcanic activity_amt</th>\n",
       "      <th>drought_amt</th>\n",
       "      <th>mass movement (dry)_amt</th>\n",
       "      <th>flood_ct</th>\n",
       "      <th>...</th>\n",
       "      <th>era_12_minimum_2m_air_temperature</th>\n",
       "      <th>era_12_maximum_2m_air_temperature</th>\n",
       "      <th>era_12_dewpoint_2m_temperature</th>\n",
       "      <th>era_12_total_precipitation</th>\n",
       "      <th>era_12_surface_pressure</th>\n",
       "      <th>era_12_mean_sea_level_pressure</th>\n",
       "      <th>era_12_u_component_of_wind_10m</th>\n",
       "      <th>era_12_v_component_of_wind_10m</th>\n",
       "      <th>era_lat</th>\n",
       "      <th>era_long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45873</th>\n",
       "      <td>2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45874</th>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45875</th>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45876</th>\n",
       "      <td>2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45877</th>\n",
       "      <td>2017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45878 rows × 167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  flood_amt  storm_amt  earthquake_amt  extreme temperature _amt  \\\n",
       "0      1960        0.0        0.0             0.0                       0.0   \n",
       "1      1961        0.0        0.0             0.0                       0.0   \n",
       "2      1962        0.0        0.0             0.0                       0.0   \n",
       "3      1963        0.0        0.0             0.0                       0.0   \n",
       "4      1964        0.0        0.0             0.0                       0.0   \n",
       "...     ...        ...        ...             ...                       ...   \n",
       "45873  2013        0.0        0.0             0.0                       0.0   \n",
       "45874  2014        0.0        0.0             0.0                       0.0   \n",
       "45875  2015        0.0        0.0             0.0                       0.0   \n",
       "45876  2016        0.0        0.0             0.0                       0.0   \n",
       "45877  2017        0.0        0.0             0.0                       0.0   \n",
       "\n",
       "       landslide_amt  volcanic activity_amt  drought_amt  \\\n",
       "0                0.0                    0.0          0.0   \n",
       "1                0.0                    0.0          0.0   \n",
       "2                0.0                    0.0          0.0   \n",
       "3                0.0                    0.0          0.0   \n",
       "4                0.0                    0.0          0.0   \n",
       "...              ...                    ...          ...   \n",
       "45873            0.0                    0.0          0.0   \n",
       "45874            0.0                    0.0          0.0   \n",
       "45875            0.0                    0.0          0.0   \n",
       "45876            0.0                    0.0          0.0   \n",
       "45877            0.0                    0.0          0.0   \n",
       "\n",
       "       mass movement (dry)_amt  flood_ct  ...  \\\n",
       "0                          0.0       0.0  ...   \n",
       "1                          0.0       0.0  ...   \n",
       "2                          0.0       0.0  ...   \n",
       "3                          0.0       0.0  ...   \n",
       "4                          0.0       0.0  ...   \n",
       "...                        ...       ...  ...   \n",
       "45873                      0.0       0.0  ...   \n",
       "45874                      0.0       0.0  ...   \n",
       "45875                      0.0       0.0  ...   \n",
       "45876                      0.0       0.0  ...   \n",
       "45877                      0.0       0.0  ...   \n",
       "\n",
       "       era_12_minimum_2m_air_temperature  era_12_maximum_2m_air_temperature  \\\n",
       "0                                    NaN                                NaN   \n",
       "1                                    NaN                                NaN   \n",
       "2                                    NaN                                NaN   \n",
       "3                                    NaN                                NaN   \n",
       "4                                    NaN                                NaN   \n",
       "...                                  ...                                ...   \n",
       "45873                                NaN                                NaN   \n",
       "45874                                NaN                                NaN   \n",
       "45875                                NaN                                NaN   \n",
       "45876                                NaN                                NaN   \n",
       "45877                                NaN                                NaN   \n",
       "\n",
       "       era_12_dewpoint_2m_temperature  era_12_total_precipitation  \\\n",
       "0                                 NaN                         NaN   \n",
       "1                                 NaN                         NaN   \n",
       "2                                 NaN                         NaN   \n",
       "3                                 NaN                         NaN   \n",
       "4                                 NaN                         NaN   \n",
       "...                               ...                         ...   \n",
       "45873                             NaN                         NaN   \n",
       "45874                             NaN                         NaN   \n",
       "45875                             NaN                         NaN   \n",
       "45876                             NaN                         NaN   \n",
       "45877                             NaN                         NaN   \n",
       "\n",
       "       era_12_surface_pressure  era_12_mean_sea_level_pressure  \\\n",
       "0                          NaN                             NaN   \n",
       "1                          NaN                             NaN   \n",
       "2                          NaN                             NaN   \n",
       "3                          NaN                             NaN   \n",
       "4                          NaN                             NaN   \n",
       "...                        ...                             ...   \n",
       "45873                      NaN                             NaN   \n",
       "45874                      NaN                             NaN   \n",
       "45875                      NaN                             NaN   \n",
       "45876                      NaN                             NaN   \n",
       "45877                      NaN                             NaN   \n",
       "\n",
       "       era_12_u_component_of_wind_10m  era_12_v_component_of_wind_10m  \\\n",
       "0                                 NaN                             NaN   \n",
       "1                                 NaN                             NaN   \n",
       "2                                 NaN                             NaN   \n",
       "3                                 NaN                             NaN   \n",
       "4                                 NaN                             NaN   \n",
       "...                               ...                             ...   \n",
       "45873                             NaN                             NaN   \n",
       "45874                             NaN                             NaN   \n",
       "45875                             NaN                             NaN   \n",
       "45876                             NaN                             NaN   \n",
       "45877                             NaN                             NaN   \n",
       "\n",
       "       era_lat  era_long  \n",
       "0          NaN       NaN  \n",
       "1          NaN       NaN  \n",
       "2          NaN       NaN  \n",
       "3          NaN       NaN  \n",
       "4          NaN       NaN  \n",
       "...        ...       ...  \n",
       "45873      NaN       NaN  \n",
       "45874      NaN       NaN  \n",
       "45875      NaN       NaN  \n",
       "45876      NaN       NaN  \n",
       "45877      NaN       NaN  \n",
       "\n",
       "[45878 rows x 167 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumb baseline AUC 0.5\n",
      "maximum f1 score, thres 0.48441714114474077 0.4\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.5 0.48441714114474077 0.9395524556814879 0.5 0.06044754431851206 0.0\n",
      "[[12932     0]\n",
      " [  832     0]]\n",
      "Dumb baseline 2 AUC 0.5551864114658926\n",
      "maximum f1 score, thres 0.5559981154419161 0.4\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.5551864114658926 0.5559981154419161 0.9006102877070619 0.5551864114658925 0.07781682803007245 0.1622596153846154\n",
      "[[12261   671]\n",
      " [  697   135]]\n"
     ]
    }
   ],
   "source": [
    "#try a simple baseline\n",
    "\n",
    "#try a dumb model predicting just zeros , we are just guessing no flood!\n",
    "y_base = np.zeros(len(y_test)) \n",
    "print('Dumb baseline AUC', metrics.roc_auc_score(y_test,y_base))\n",
    "results['base1']=m.get_scores_clf(y_test,y_base)\n",
    "\n",
    "#try a less dumb model predicting outcome = current flood outcome \n",
    "y_base2 = x_test['flood_bin'] \n",
    "print('Dumb baseline 2 AUC', metrics.roc_auc_score(y_test,y_base2))\n",
    "results['base2']= m.get_scores_clf(y_test,y_base2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running log reg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:432: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  l2_reg_strength = 1.0 / C\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py:198: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  loss += 0.5 * l2_reg_strength * (weights @ weights)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in multiply\n",
      "  grad[:n_features] = X.T @ grad_per_sample + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:432: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  l2_reg_strength = 1.0 / C\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py:198: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  loss += 0.5 * l2_reg_strength * (weights @ weights)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in multiply\n",
      "  grad[:n_features] = X.T @ grad_per_sample + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:432: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  l2_reg_strength = 1.0 / C\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py:198: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  loss += 0.5 * l2_reg_strength * (weights @ weights)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in multiply\n",
      "  grad[:n_features] = X.T @ grad_per_sample + l2_reg_strength * weights\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.5               nan 0.95936341        nan 0.95936456        nan\n",
      " 0.9593636         nan 0.95928403        nan]\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:432: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  l2_reg_strength = 1.0 / C\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py:198: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  loss += 0.5 * l2_reg_strength * (weights @ weights)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in multiply\n",
      "  grad[:n_features] = X.T @ grad_per_sample + l2_reg_strength * weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC:  0.5\n",
      "maximum f1 score, thres 0.49608075131257856 0.6\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.5 0.49608075131257856 0.984444933597476 0.5 0.015555066402524029 0.0\n",
      "[[13417     0]\n",
      " [  212     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/test_env/lib/python3.8/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#logreg model -> How is this doing the same thing as our baseline model\n",
    "y_pred, y_pred_prob = m.run_logreg(x_train, y_train, x_test)\n",
    "results['logreg'] = m.get_scores_clf(y_test, y_pred_prob)\n",
    "# print('Test AUC', metrics.roc_auc_score(y_test, y_pred_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running xgb...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gridsan/czeng12/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/gridsan/czeng12/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/gridsan/czeng12/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/gridsan/czeng12/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/gridsan/czeng12/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/gridsan/czeng12/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/gridsan/czeng12/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/gridsan/czeng12/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/gridsan/czeng12/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/gridsan/czeng12/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/gridsan/czeng12/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/gridsan/czeng12/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/home/gridsan/czeng12/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC:  0.7947773028810027\n",
      "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'scale_pos_weight': 10}\n",
      "maximum f1 score, thres 0.5641563808212884 0.6\n",
      "auc, f1, accu, accu_bl, precision, recall=  0.7817612262515168 0.5277838608784438 0.8338419064225516 0.6264909720074234 0.09714549547823817 0.390625\n",
      "[[11152  1780]\n",
      " [  507   325]]\n"
     ]
    }
   ],
   "source": [
    "y_pred, y_pred_prob = m.run_xgb(x_train, y_train, x_test)\n",
    "results['xgb'] = m.get_scores_clf(y_test, y_pred_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC 0.9651197579528084\n"
     ]
    }
   ],
   "source": [
    "print('Test AUC', metrics.roc_auc_score(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base1</th>\n",
       "      <th>base2</th>\n",
       "      <th>logreg</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.786129</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.965120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.496081</td>\n",
       "      <td>0.615005</td>\n",
       "      <td>0.496081</td>\n",
       "      <td>0.639297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.984445</td>\n",
       "      <td>0.944530</td>\n",
       "      <td>0.984445</td>\n",
       "      <td>0.975347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.786129</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.655543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015555</td>\n",
       "      <td>0.107588</td>\n",
       "      <td>0.015555</td>\n",
       "      <td>0.096208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      base1     base2    logreg       xgb\n",
       "0  0.500000  0.786129  0.500000  0.965120\n",
       "1  0.496081  0.615005  0.496081  0.639297\n",
       "2  0.984445  0.944530  0.984445  0.975347\n",
       "3  0.500000  0.786129  0.500000  0.655543\n",
       "4  0.015555  0.107588  0.015555  0.096208\n",
       "5  0.000000  0.622642  0.000000  0.325472"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results= pd.DataFrame(results)\n",
    "# results.to_clipboard(excel=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare results from different combinations of x_train, x_train1, etc.  \n",
    "- correspond to different modalities of data:\n",
    "   - try which ones give the best result \n",
    "   - @Oscar you can take over from here :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to do: \n",
    "#- duplicate this notebook keep only to ee feature extraction \n",
    "#- in a new notebook to multimodal testing "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
