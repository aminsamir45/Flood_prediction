{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reading raw data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id  country iso3   gwno  year  geo_id  geolocation  level     adm1  \\\n",
      "0  109  Albania  ALB  339.0  2009     346  Ana E Malit      3  Shkoder   \n",
      "1  109  Albania  ALB  339.0  2009     351       Bushat      3  Shkoder   \n",
      "\n",
      "       adm2         adm3     location  historical hist_country disastertype  \\\n",
      "0  Shkodres  Ana E Malit  Ana E Malit           0          NaN        flood   \n",
      "1  Shkodres       Bushat       Bushat           0          NaN        flood   \n",
      "\n",
      "  disasterno   latitude  longitude  \n",
      "0  2009-0631  42.020948  19.418317  \n",
      "1  2009-0631  41.959294  19.514309  \n",
      "          Dis No  Year   Seq Glide Disaster Group Disaster Subgroup  \\\n",
      "0  1900-9002-CPV  1900  9002   NaN        Natural    Climatological   \n",
      "1  1900-9001-IND  1900  9001   NaN        Natural    Climatological   \n",
      "\n",
      "  Disaster Type Disaster Subtype Disaster Subsubtype Event Name  ...  \\\n",
      "0       Drought          Drought                 NaN        NaN  ...   \n",
      "1       Drought          Drought                 NaN        NaN  ...   \n",
      "\n",
      "  Reconstruction Costs, Adjusted ('000 US$) Insured Damages ('000 US$)  \\\n",
      "0                                       NaN                        NaN   \n",
      "1                                       NaN                        NaN   \n",
      "\n",
      "  Insured Damages, Adjusted ('000 US$) Total Damages ('000 US$)  \\\n",
      "0                                  NaN                      NaN   \n",
      "1                                  NaN                      NaN   \n",
      "\n",
      "  Total Damages, Adjusted ('000 US$)       CPI Adm Level Admin1 Code  \\\n",
      "0                                NaN  3.077091       NaN         NaN   \n",
      "1                                NaN  3.077091       NaN         NaN   \n",
      "\n",
      "  Admin2 Code Geo Locations  \n",
      "0         NaN           NaN  \n",
      "1         NaN           NaN  \n",
      "\n",
      "[2 rows x 50 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-f7d9b46ad88a>:4: DtypeWarning: Columns (8,16,17,18,19,24,25,26,27,46,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  emdat = pd.read_csv('../data/emdat_public_2022_09_21_query_uid-47Yzpr.csv', skiprows=[0,1,2,3,4,5])\n"
     ]
    }
   ],
   "source": [
    "#gdis data \n",
    "gdis = pd.read_csv('../data/pend-gdis-1960-2018-disasterlocations.csv')\n",
    "#get emdat dataset\n",
    "emdat = pd.read_csv('../data/emdat_public_2022_09_21_query_uid-47Yzpr.csv', skiprows=[0,1,2,3,4,5])\n",
    "print(gdis.head(2))\n",
    "print(emdat.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select certain columns from emdat and join with gdis \n",
    "emdat['disasterno'] = emdat['Dis No'].str[:-4] #format disasterno to merge  \n",
    "cols = ['disasterno', 'Year', 'Event Name', \n",
    "#         'Disaster Type', 'Disaster Subtype', \n",
    "#         'Region', 'Continent', #'Location',\n",
    "        'Start Year', 'Start Month', 'Start Day', \n",
    "        'End Year', 'End Month','End Day',  \n",
    "        \"Total Damages, Adjusted ('000 US$)\"] \n",
    "\n",
    "emdat = emdat[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join emdat and gdis \n",
    "gdis = pd.merge(emdat, gdis, on = 'disasterno', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (9924, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>country</th>\n",
       "      <th>iso3</th>\n",
       "      <th>gwno</th>\n",
       "      <th>year</th>\n",
       "      <th>geo_id</th>\n",
       "      <th>geolocation</th>\n",
       "      <th>level</th>\n",
       "      <th>adm1</th>\n",
       "      <th>adm2</th>\n",
       "      <th>adm3</th>\n",
       "      <th>location</th>\n",
       "      <th>historical</th>\n",
       "      <th>hist_country</th>\n",
       "      <th>disastertype</th>\n",
       "      <th>disasterno</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109</td>\n",
       "      <td>Albania</td>\n",
       "      <td>ALB</td>\n",
       "      <td>339.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>346</td>\n",
       "      <td>Ana E Malit</td>\n",
       "      <td>3</td>\n",
       "      <td>Shkoder</td>\n",
       "      <td>Shkodres</td>\n",
       "      <td>Ana E Malit</td>\n",
       "      <td>Ana E Malit</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flood</td>\n",
       "      <td>2009-0631</td>\n",
       "      <td>42.020948</td>\n",
       "      <td>19.418317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>175</td>\n",
       "      <td>Angola</td>\n",
       "      <td>AGO</td>\n",
       "      <td>540.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>760</td>\n",
       "      <td>Onjiva</td>\n",
       "      <td>3</td>\n",
       "      <td>Cunene</td>\n",
       "      <td>Cuanhama</td>\n",
       "      <td>Onjiva</td>\n",
       "      <td>Onjiva</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flood</td>\n",
       "      <td>2001-0146</td>\n",
       "      <td>-17.093484</td>\n",
       "      <td>15.665758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  country iso3   gwno  year  geo_id  geolocation  level     adm1  \\\n",
       "0  109  Albania  ALB  339.0  2009     346  Ana E Malit      3  Shkoder   \n",
       "2  175   Angola  AGO  540.0  2001     760       Onjiva      3   Cunene   \n",
       "\n",
       "       adm2         adm3     location  historical hist_country disastertype  \\\n",
       "0  Shkodres  Ana E Malit  Ana E Malit           0          NaN        flood   \n",
       "2  Cuanhama       Onjiva       Onjiva           0          NaN        flood   \n",
       "\n",
       "  disasterno   latitude  longitude  \n",
       "0  2009-0631  42.020948  19.418317  \n",
       "2  2001-0146 -17.093484  15.665758  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print \n",
    "gdis = gdis.drop_duplicates(subset=['id'])\n",
    "print('shape', gdis.shape)\n",
    "gdis.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of grid pairs 2852\n"
     ]
    }
   ],
   "source": [
    "#latitude range from -90 to 90, longitude range from -180 to 180 \n",
    "\n",
    "#convert lat and long into 1 degree grid: correspond to 100*100km \n",
    "gdis['lat_grid'] = np.digitize(np.array(gdis['latitude']),np.arange(-90,90,1))\n",
    "gdis['lon_grid'] = np.digitize(np.array(gdis['longitude']),np.arange(-180,180,1)) \n",
    "#compute the grid pair id \n",
    "gdis['grid_id'] = list(zip(gdis['lat_grid'],gdis['lon_grid']))\n",
    "print('total number of grid pairs', len(gdis.grid_id.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>country</th>\n",
       "      <th>iso3</th>\n",
       "      <th>gwno</th>\n",
       "      <th>year</th>\n",
       "      <th>geo_id</th>\n",
       "      <th>geolocation</th>\n",
       "      <th>level</th>\n",
       "      <th>adm1</th>\n",
       "      <th>adm2</th>\n",
       "      <th>adm3</th>\n",
       "      <th>location</th>\n",
       "      <th>historical</th>\n",
       "      <th>hist_country</th>\n",
       "      <th>disastertype</th>\n",
       "      <th>disasterno</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109</td>\n",
       "      <td>Albania</td>\n",
       "      <td>ALB</td>\n",
       "      <td>339.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>346</td>\n",
       "      <td>Ana E Malit</td>\n",
       "      <td>3</td>\n",
       "      <td>Shkoder</td>\n",
       "      <td>Shkodres</td>\n",
       "      <td>Ana E Malit</td>\n",
       "      <td>Ana E Malit</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flood</td>\n",
       "      <td>2009-0631</td>\n",
       "      <td>42.020948</td>\n",
       "      <td>19.418317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>175</td>\n",
       "      <td>Angola</td>\n",
       "      <td>AGO</td>\n",
       "      <td>540.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>760</td>\n",
       "      <td>Onjiva</td>\n",
       "      <td>3</td>\n",
       "      <td>Cunene</td>\n",
       "      <td>Cuanhama</td>\n",
       "      <td>Onjiva</td>\n",
       "      <td>Onjiva</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flood</td>\n",
       "      <td>2001-0146</td>\n",
       "      <td>-17.093484</td>\n",
       "      <td>15.665758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  country iso3   gwno  year  geo_id  geolocation  level     adm1  \\\n",
       "0  109  Albania  ALB  339.0  2009     346  Ana E Malit      3  Shkoder   \n",
       "2  175   Angola  AGO  540.0  2001     760       Onjiva      3   Cunene   \n",
       "\n",
       "       adm2         adm3     location  historical hist_country disastertype  \\\n",
       "0  Shkodres  Ana E Malit  Ana E Malit           0          NaN        flood   \n",
       "2  Cuanhama       Onjiva       Onjiva           0          NaN        flood   \n",
       "\n",
       "  disasterno   latitude  longitude  \n",
       "0  2009-0631  42.020948  19.418317  \n",
       "2  2001-0146 -17.093484  15.665758  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdis.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #count number of locations in each grid_id: ideally just 1 location per grid_id, if not, I can make grid finer. \n",
    "# gdis.groupby('grid_id').agg({'location':'nunique'}).sort_values(by='location').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the grid with most regions \n",
    "# gdis.loc[gdis['grid_id']==(113, 295)].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Construct X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot function: change rows of info into tables \n",
    "def pivot(df_in, id_col='disastertype', id_list=['Flood']):\n",
    "    df = df_in.reset_index(drop = True)\n",
    "\n",
    "\n",
    "    for id in id_list:\n",
    "        #initialize columns\n",
    "        df[id+'_bin'] = 0\n",
    "        df[id+'_amt'] = 0\n",
    "        df[id+'_ct'] = 0\n",
    "        \n",
    "\n",
    "        df.loc[(df[id_col]==id), id+'_bin'] = 1\n",
    "        df.loc[(df[id_col]==id), id+'_amt'] = df[\"Total Damages, Adjusted ('000 US$)\"].astype(float)\n",
    "        df.loc[(df[id_col]==id), id+'_ct'] = 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flood', 'storm', 'earthquake', 'extreme temperature ', 'landslide', 'volcanic activity', 'drought', 'mass movement (dry)']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disasterno</th>\n",
       "      <th>Year</th>\n",
       "      <th>Event Name</th>\n",
       "      <th>Start Year</th>\n",
       "      <th>Start Month</th>\n",
       "      <th>Start Day</th>\n",
       "      <th>End Year</th>\n",
       "      <th>End Month</th>\n",
       "      <th>End Day</th>\n",
       "      <th>Total Damages, Adjusted ('000 US$)</th>\n",
       "      <th>...</th>\n",
       "      <th>landslide_ct</th>\n",
       "      <th>volcanic activity_bin</th>\n",
       "      <th>volcanic activity_amt</th>\n",
       "      <th>volcanic activity_ct</th>\n",
       "      <th>drought_bin</th>\n",
       "      <th>drought_amt</th>\n",
       "      <th>drought_ct</th>\n",
       "      <th>mass movement (dry)_bin</th>\n",
       "      <th>mass movement (dry)_amt</th>\n",
       "      <th>mass movement (dry)_ct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-0631</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-0146</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-0092</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-0105</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995-0082</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1422569.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9919</th>\n",
       "      <td>1960-0011</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>Manam</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9920</th>\n",
       "      <td>2009-9633</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9921</th>\n",
       "      <td>1990-9289</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9922</th>\n",
       "      <td>1969-9069</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73867.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>73867.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9923</th>\n",
       "      <td>2015-0375</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Hurricane Erika</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>551973.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9924 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     disasterno    Year       Event Name  Start Year  Start Month  Start Day  \\\n",
       "0     2009-0631  2009.0              NaN      2009.0         12.0       27.0   \n",
       "1     2001-0146  2001.0              NaN      2001.0          4.0        2.0   \n",
       "2     2009-0092  2009.0              NaN      2009.0          3.0        1.0   \n",
       "3     2010-0105  2010.0              NaN      2010.0          3.0        1.0   \n",
       "4     1995-0082  1995.0              NaN      1995.0          5.0       15.0   \n",
       "...         ...     ...              ...         ...          ...        ...   \n",
       "9919  1960-0011  1960.0            Manam      1960.0          3.0       17.0   \n",
       "9920  2009-9633  2009.0              NaN      2009.0          NaN        NaN   \n",
       "9921  1990-9289  1990.0              NaN      1990.0          NaN        NaN   \n",
       "9922  1969-9069  1969.0              NaN      1969.0          NaN        NaN   \n",
       "9923  2015-0375  2015.0  Hurricane Erika      2015.0          8.0       27.0   \n",
       "\n",
       "      End Year  End Month  End Day  Total Damages, Adjusted ('000 US$)  ...  \\\n",
       "0       2010.0        1.0      8.0                                 NaN  ...   \n",
       "1       2001.0        4.0      9.0                                 NaN  ...   \n",
       "2       2009.0        4.0     16.0                                 NaN  ...   \n",
       "3       2010.0        3.0     17.0                                 NaN  ...   \n",
       "4       1995.0        5.0     15.0                           1422569.0  ...   \n",
       "...        ...        ...      ...                                 ...  ...   \n",
       "9919    1960.0        3.0     17.0                                 NaN  ...   \n",
       "9920    2010.0        NaN      NaN                                 NaN  ...   \n",
       "9921    1990.0        NaN      NaN                                 NaN  ...   \n",
       "9922    1971.0        NaN      NaN                             73867.0  ...   \n",
       "9923    2015.0        8.0     27.0                            551973.0  ...   \n",
       "\n",
       "     landslide_ct volcanic activity_bin volcanic activity_amt  \\\n",
       "0               0                     0                   0.0   \n",
       "1               0                     0                   0.0   \n",
       "2               0                     0                   0.0   \n",
       "3               0                     0                   0.0   \n",
       "4               0                     0                   0.0   \n",
       "...           ...                   ...                   ...   \n",
       "9919            0                     1                   NaN   \n",
       "9920            0                     0                   0.0   \n",
       "9921            0                     0                   0.0   \n",
       "9922            0                     0                   0.0   \n",
       "9923            0                     0                   0.0   \n",
       "\n",
       "      volcanic activity_ct  drought_bin  drought_amt drought_ct  \\\n",
       "0                        0            0          0.0          0   \n",
       "1                        0            0          0.0          0   \n",
       "2                        0            0          0.0          0   \n",
       "3                        0            0          0.0          0   \n",
       "4                        0            0          0.0          0   \n",
       "...                    ...          ...          ...        ...   \n",
       "9919                     1            0          0.0          0   \n",
       "9920                     0            1          NaN          1   \n",
       "9921                     0            1          NaN          1   \n",
       "9922                     0            1      73867.0          1   \n",
       "9923                     0            0          0.0          0   \n",
       "\n",
       "      mass movement (dry)_bin mass movement (dry)_amt mass movement (dry)_ct  \n",
       "0                           0                     0.0                      0  \n",
       "1                           0                     0.0                      0  \n",
       "2                           0                     0.0                      0  \n",
       "3                           0                     0.0                      0  \n",
       "4                           0                     0.0                      0  \n",
       "...                       ...                     ...                    ...  \n",
       "9919                        0                     0.0                      0  \n",
       "9920                        0                     0.0                      0  \n",
       "9921                        0                     0.0                      0  \n",
       "9922                        0                     0.0                      0  \n",
       "9923                        0                     0.0                      0  \n",
       "\n",
       "[9924 rows x 54 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# id_list= df_sub['Disaster Type'].unique()\n",
    "id_list= gdis['disastertype'].unique().tolist()\n",
    "print(id_list)\n",
    "df_pivot= pivot(gdis, id_col = 'disastertype', id_list = id_list)\n",
    "df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate columns by year\n",
    "def aggregate_yrly(df):\n",
    "    #aggregate count\n",
    "    col_ct = [col for col in df.columns if '_ct' in col]\n",
    "    df_ct = df.groupby(['grid_id','year'])[col_ct].agg('sum')\n",
    "    \n",
    "    #aggregate amount \n",
    "    col_amt = [col for col in df.columns if '_amt' in col]\n",
    "    df_amt = df.groupby(['grid_id','year'])[col_amt].agg('sum')\n",
    "    \n",
    "    #aggregate binary\n",
    "    col_bin = [col for col in df.columns if '_bin' in col]\n",
    "    df_bin= df.groupby(['grid_id','year'])[col_bin].agg('max')\n",
    "\n",
    "    #join\n",
    "    df1= pd.concat([df_amt, df_ct], axis=1)\n",
    "    df_out = pd.concat([df1, df_bin], axis=1)\n",
    "    return df_out.reset_index()\n",
    "df_yrly = aggregate_yrly(df_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_id</th>\n",
       "      <th>year</th>\n",
       "      <th>flood_amt</th>\n",
       "      <th>storm_amt</th>\n",
       "      <th>earthquake_amt</th>\n",
       "      <th>extreme temperature _amt</th>\n",
       "      <th>landslide_amt</th>\n",
       "      <th>volcanic activity_amt</th>\n",
       "      <th>drought_amt</th>\n",
       "      <th>mass movement (dry)_amt</th>\n",
       "      <th>...</th>\n",
       "      <th>drought_ct</th>\n",
       "      <th>mass movement (dry)_ct</th>\n",
       "      <th>flood_bin</th>\n",
       "      <th>storm_bin</th>\n",
       "      <th>earthquake_bin</th>\n",
       "      <th>extreme temperature _bin</th>\n",
       "      <th>landslide_bin</th>\n",
       "      <th>volcanic activity_bin</th>\n",
       "      <th>drought_bin</th>\n",
       "      <th>mass movement (dry)_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(37, 108)</td>\n",
       "      <td>1990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(42, 108)</td>\n",
       "      <td>2017</td>\n",
       "      <td>2211.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(42, 111)</td>\n",
       "      <td>1991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(44, 107)</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(44, 107)</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8675</th>\n",
       "      <td>(157, 311)</td>\n",
       "      <td>1998</td>\n",
       "      <td>5818.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8676</th>\n",
       "      <td>(157, 311)</td>\n",
       "      <td>2007</td>\n",
       "      <td>33655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8677</th>\n",
       "      <td>(157, 311)</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8678</th>\n",
       "      <td>(158, 207)</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8679</th>\n",
       "      <td>(159, 45)</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8680 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         grid_id  year  flood_amt  storm_amt  earthquake_amt  \\\n",
       "0      (37, 108)  1990        0.0        0.0             0.0   \n",
       "1      (42, 108)  2017     2211.0        0.0             0.0   \n",
       "2      (42, 111)  1991        0.0        0.0             0.0   \n",
       "3      (44, 107)  2007        0.0        0.0             0.0   \n",
       "4      (44, 107)  2010        0.0        0.0             0.0   \n",
       "...          ...   ...        ...        ...             ...   \n",
       "8675  (157, 311)  1998     5818.0        0.0             0.0   \n",
       "8676  (157, 311)  2007    33655.0        0.0             0.0   \n",
       "8677  (157, 311)  2012        0.0        0.0             0.0   \n",
       "8678  (158, 207)  2005        0.0        0.0             0.0   \n",
       "8679   (159, 45)  2006        0.0        0.0             0.0   \n",
       "\n",
       "      extreme temperature _amt  landslide_amt  volcanic activity_amt  \\\n",
       "0                          0.0            0.0                    0.0   \n",
       "1                          0.0            0.0                    0.0   \n",
       "2                          0.0            0.0                    0.0   \n",
       "3                          0.0            0.0                    0.0   \n",
       "4                          0.0            0.0                    0.0   \n",
       "...                        ...            ...                    ...   \n",
       "8675                       0.0            0.0                    0.0   \n",
       "8676                       0.0            0.0                    0.0   \n",
       "8677                       0.0            0.0                    0.0   \n",
       "8678                       0.0            0.0                    0.0   \n",
       "8679                       0.0            0.0                    0.0   \n",
       "\n",
       "      drought_amt  mass movement (dry)_amt  ...  drought_ct  \\\n",
       "0             0.0                      0.0  ...           0   \n",
       "1             0.0                      0.0  ...           0   \n",
       "2             0.0                      0.0  ...           0   \n",
       "3             0.0                      0.0  ...           0   \n",
       "4             0.0                      0.0  ...           0   \n",
       "...           ...                      ...  ...         ...   \n",
       "8675          0.0                      0.0  ...           0   \n",
       "8676          0.0                      0.0  ...           0   \n",
       "8677          0.0                      0.0  ...           0   \n",
       "8678          0.0                      0.0  ...           0   \n",
       "8679          0.0                      0.0  ...           0   \n",
       "\n",
       "      mass movement (dry)_ct  flood_bin  storm_bin  earthquake_bin  \\\n",
       "0                          0          1          0               0   \n",
       "1                          0          1          0               0   \n",
       "2                          0          0          0               0   \n",
       "3                          0          0          0               1   \n",
       "4                          0          0          0               0   \n",
       "...                      ...        ...        ...             ...   \n",
       "8675                       0          1          0               0   \n",
       "8676                       0          1          0               0   \n",
       "8677                       0          0          0               0   \n",
       "8678                       0          1          0               0   \n",
       "8679                       0          1          0               0   \n",
       "\n",
       "      extreme temperature _bin  landslide_bin  volcanic activity_bin  \\\n",
       "0                            0              0                      0   \n",
       "1                            0              0                      0   \n",
       "2                            0              0                      1   \n",
       "3                            0              0                      0   \n",
       "4                            1              0                      0   \n",
       "...                        ...            ...                    ...   \n",
       "8675                         0              0                      0   \n",
       "8676                         0              0                      0   \n",
       "8677                         1              0                      0   \n",
       "8678                         0              0                      0   \n",
       "8679                         0              0                      0   \n",
       "\n",
       "      drought_bin  mass movement (dry)_bin  \n",
       "0               0                        0  \n",
       "1               0                        0  \n",
       "2               0                        0  \n",
       "3               0                        0  \n",
       "4               0                        0  \n",
       "...           ...                      ...  \n",
       "8675            0                        0  \n",
       "8676            0                        0  \n",
       "8677            0                        0  \n",
       "8678            0                        0  \n",
       "8679            0                        0  \n",
       "\n",
       "[8680 rows x 26 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yrly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flood_ct\n",
      "0           1032\n",
      "1            983\n",
      "2            361\n",
      "3            190\n",
      "4             81\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'flood_ct'}>]], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#count how many flood for each grid over all data \n",
    "#sum grid id with total flood incidents\n",
    "flood_ct = df_yrly.groupby('grid_id').agg({'flood_ct':'sum'}) \n",
    "print(flood_ct.value_counts().head(5))\n",
    "flood_ct.hist() #[['grid_id','flood_ct']]\n",
    "\n",
    "#1032 grids have no flood before, 983 have 1 flood only, 361 have 2 floods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flood_ct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grid_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(37, 108)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(42, 108)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(42, 111)</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(44, 107)</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(44, 349)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(156, 217)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(157, 157)</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(157, 311)</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(158, 207)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(159, 45)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2852 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            flood_ct\n",
       "grid_id             \n",
       "(37, 108)          1\n",
       "(42, 108)          1\n",
       "(42, 111)          0\n",
       "(44, 107)          0\n",
       "(44, 349)          1\n",
       "...              ...\n",
       "(156, 217)         1\n",
       "(157, 157)         0\n",
       "(157, 311)         2\n",
       "(158, 207)         1\n",
       "(159, 45)          1\n",
       "\n",
       "[2852 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create labels for training NLP \n",
    "flood_ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Y Master\n",
    "look up table for all the previous flood events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_col =  [col for col in df_yrly.columns if '_bin' in col]\n",
    "df_yrly_bin = df_yrly[['grid_id','year'] + bin_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #get a list of disasters and flood_id \n",
    "# all_dis = gdis[['grid_id','Year','disastertype']]\n",
    "\n",
    "# #\n",
    "# flood = all_dis.loc[all_dis['disastertype']=='flood']\n",
    "# flood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1960.0 2018.0\n",
      "168268\n"
     ]
    }
   ],
   "source": [
    "# get a list of grid_ids \n",
    "grid_id = gdis['grid_id'].unique()\n",
    "# get a list of year information \n",
    "print(gdis.Year.min(), gdis.Year.max())\n",
    "year_id = np.arange(1960, 2019, 1) \n",
    "#create multi-index: each grid id, spanning over the years \n",
    "idd = pd.MultiIndex.from_product([grid_id, year_id],\n",
    "                           names=['grid_id', 'year'])\n",
    "\n",
    "#length should be |years| * |grid_ids| \n",
    "print(len(idd))\n",
    "#get dataframe \n",
    "idd = idd.to_frame().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#master disaster targets for all years and all ids: \n",
    "#merge with df_yrly \n",
    "y_master = pd.merge(idd, df_yrly_bin, on=['grid_id','year'], how='left').fillna(0)\n",
    "\n",
    "#keep just the binary\n",
    "# y_master.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4007.0\n",
      "4274\n"
     ]
    }
   ],
   "source": [
    "#check: \n",
    "print(y_master['flood_bin'].sum()) #total number of binary flood targets \n",
    "\n",
    "#total number of flood incidents: \n",
    "print(gdis.loc[gdis['disastertype']=='flood'].shape[0])\n",
    "\n",
    "#the two numbers are slightly different, but that's because some country have more than 1 flood per year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_id</th>\n",
       "      <th>year</th>\n",
       "      <th>flood_bin</th>\n",
       "      <th>storm_bin</th>\n",
       "      <th>earthquake_bin</th>\n",
       "      <th>extreme temperature _bin</th>\n",
       "      <th>landslide_bin</th>\n",
       "      <th>volcanic activity_bin</th>\n",
       "      <th>drought_bin</th>\n",
       "      <th>mass movement (dry)_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(133, 200)</td>\n",
       "      <td>1960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(133, 200)</td>\n",
       "      <td>1961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(133, 200)</td>\n",
       "      <td>1962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(133, 200)</td>\n",
       "      <td>1963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(133, 200)</td>\n",
       "      <td>1964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168263</th>\n",
       "      <td>(99, 210)</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168264</th>\n",
       "      <td>(99, 210)</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168265</th>\n",
       "      <td>(99, 210)</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168266</th>\n",
       "      <td>(99, 210)</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168267</th>\n",
       "      <td>(99, 210)</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168268 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           grid_id  year  flood_bin  storm_bin  earthquake_bin  \\\n",
       "0       (133, 200)  1960        0.0        0.0             0.0   \n",
       "1       (133, 200)  1961        0.0        0.0             0.0   \n",
       "2       (133, 200)  1962        0.0        0.0             0.0   \n",
       "3       (133, 200)  1963        0.0        0.0             0.0   \n",
       "4       (133, 200)  1964        0.0        0.0             0.0   \n",
       "...            ...   ...        ...        ...             ...   \n",
       "168263   (99, 210)  2014        0.0        0.0             0.0   \n",
       "168264   (99, 210)  2015        0.0        0.0             0.0   \n",
       "168265   (99, 210)  2016        0.0        0.0             0.0   \n",
       "168266   (99, 210)  2017        0.0        0.0             0.0   \n",
       "168267   (99, 210)  2018        0.0        0.0             0.0   \n",
       "\n",
       "        extreme temperature _bin  landslide_bin  volcanic activity_bin  \\\n",
       "0                            0.0            0.0                    0.0   \n",
       "1                            0.0            0.0                    0.0   \n",
       "2                            0.0            0.0                    0.0   \n",
       "3                            0.0            0.0                    0.0   \n",
       "4                            0.0            0.0                    0.0   \n",
       "...                          ...            ...                    ...   \n",
       "168263                       0.0            0.0                    0.0   \n",
       "168264                       0.0            0.0                    0.0   \n",
       "168265                       0.0            0.0                    0.0   \n",
       "168266                       0.0            0.0                    0.0   \n",
       "168267                       0.0            0.0                    0.0   \n",
       "\n",
       "        drought_bin  mass movement (dry)_bin  \n",
       "0               0.0                      0.0  \n",
       "1               0.0                      0.0  \n",
       "2               0.0                      0.0  \n",
       "3               0.0                      0.0  \n",
       "4               0.0                      0.0  \n",
       "...             ...                      ...  \n",
       "168263          0.0                      0.0  \n",
       "168264          0.0                      0.0  \n",
       "168265          0.0                      0.0  \n",
       "168266          0.0                      0.0  \n",
       "168267          0.0                      0.0  \n",
       "\n",
       "[168268 rows x 10 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct next n year target -> look up this table \n",
    "y_master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter data to previously flooded regions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of grid_ids selected 818\n",
      "len of idd 48262\n"
     ]
    }
   ],
   "source": [
    "#step 1: filter xy_df to those grid_ids with previous frequent flooding history \n",
    "agg = df_yrly.groupby('grid_id').agg({'flood_bin':'sum'})\n",
    "grid_id_ls = agg.loc[agg['flood_bin']>=2].index.tolist()\n",
    "print('no of grid_ids selected', len(grid_id_ls))\n",
    "\n",
    "\n",
    "#step 2: interpolate years to record all years, fill with 0 without any flood using idd \n",
    "#create multi-index: each grid id, spanning over the years \n",
    "year_id = np.arange(1960, 2019, 1) \n",
    "idd = pd.MultiIndex.from_product([grid_id_ls, year_id],\n",
    "                           names=['grid_id', 'year'])\n",
    "\n",
    "#length should be |years| * |grid_ids| \n",
    "print('len of idd', len(idd))\n",
    "#get dataframe \n",
    "idd = idd.to_frame().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8680, 26)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yrly.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## attach NLP feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "print(pickle.format_version)\n",
    "\n",
    "#load processed nlp features: \n",
    "#note: you can load other nlp features too, they all start with 'nlp_*' \n",
    "file = open('../data/nlp_cls.pkl', 'rb') \n",
    "# dump information to that file\n",
    "df_nlp = pickle.load(file)\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_id</th>\n",
       "      <th>location</th>\n",
       "      <th>txt</th>\n",
       "      <th>flood_ct_x</th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(37, 108)</td>\n",
       "      <td>['Punta Arenas']</td>\n",
       "      <td>Located on the Brunswick Peninsula, Punta Aren...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.001822</td>\n",
       "      <td>-0.928713</td>\n",
       "      <td>-0.967177</td>\n",
       "      <td>0.415425</td>\n",
       "      <td>-0.911949</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.052783</td>\n",
       "      <td>-0.598555</td>\n",
       "      <td>0.424895</td>\n",
       "      <td>-0.130588</td>\n",
       "      <td>-0.364726</td>\n",
       "      <td>-0.503877</td>\n",
       "      <td>-0.486237</td>\n",
       "      <td>-2.300251</td>\n",
       "      <td>0.536454</td>\n",
       "      <td>0.099619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(42, 108)</td>\n",
       "      <td>[\" O'Higgins\"]</td>\n",
       "      <td>In pre-Quaternary times extensive Nothofagus f...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.063225</td>\n",
       "      <td>-0.575212</td>\n",
       "      <td>-1.081799</td>\n",
       "      <td>0.409087</td>\n",
       "      <td>-0.876170</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.484141</td>\n",
       "      <td>-1.167732</td>\n",
       "      <td>0.033461</td>\n",
       "      <td>-0.135048</td>\n",
       "      <td>-0.589876</td>\n",
       "      <td>0.544747</td>\n",
       "      <td>-1.152112</td>\n",
       "      <td>-2.023077</td>\n",
       "      <td>0.504555</td>\n",
       "      <td>0.199211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(42, 111)</td>\n",
       "      <td>['Santa Cruz']</td>\n",
       "      <td>Santa Cruz is on the northern edge of Monterey...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.881308</td>\n",
       "      <td>-0.373587</td>\n",
       "      <td>-0.859964</td>\n",
       "      <td>-0.379370</td>\n",
       "      <td>-0.307493</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.433483</td>\n",
       "      <td>-0.247950</td>\n",
       "      <td>0.364869</td>\n",
       "      <td>-0.171929</td>\n",
       "      <td>0.020665</td>\n",
       "      <td>0.264282</td>\n",
       "      <td>-0.428337</td>\n",
       "      <td>-1.907884</td>\n",
       "      <td>0.925079</td>\n",
       "      <td>-0.015810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(44, 107)</td>\n",
       "      <td>['Aysen region', 'Aisen del Gral. Carlos Ibañe...</td>\n",
       "      <td>The Aysén del General Carlos Ibáñez del Campo ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.691399</td>\n",
       "      <td>-0.696447</td>\n",
       "      <td>-1.076606</td>\n",
       "      <td>0.233475</td>\n",
       "      <td>-1.041147</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.862644</td>\n",
       "      <td>-0.717574</td>\n",
       "      <td>-0.367924</td>\n",
       "      <td>-0.156901</td>\n",
       "      <td>-0.136446</td>\n",
       "      <td>0.119059</td>\n",
       "      <td>-0.291558</td>\n",
       "      <td>-1.823087</td>\n",
       "      <td>0.408933</td>\n",
       "      <td>0.050547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(44, 349)</td>\n",
       "      <td>['Gore', 'Invercargill']</td>\n",
       "      <td>Politically, Southland proper extends from Fio...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.602599</td>\n",
       "      <td>-0.628806</td>\n",
       "      <td>-0.725431</td>\n",
       "      <td>0.293510</td>\n",
       "      <td>-0.414344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071532</td>\n",
       "      <td>-0.608719</td>\n",
       "      <td>0.444171</td>\n",
       "      <td>-0.487947</td>\n",
       "      <td>0.124660</td>\n",
       "      <td>-0.200412</td>\n",
       "      <td>-0.801921</td>\n",
       "      <td>-0.927848</td>\n",
       "      <td>1.225127</td>\n",
       "      <td>-0.321115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 773 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     grid_id                                           location  \\\n",
       "0  (37, 108)                                   ['Punta Arenas']   \n",
       "1  (42, 108)                                     [\" O'Higgins\"]   \n",
       "2  (42, 111)                                     ['Santa Cruz']   \n",
       "3  (44, 107)  ['Aysen region', 'Aisen del Gral. Carlos Ibañe...   \n",
       "4  (44, 349)                           ['Gore', 'Invercargill']   \n",
       "\n",
       "                                                 txt  flood_ct_x  label  \\\n",
       "0  Located on the Brunswick Peninsula, Punta Aren...         1.0      0   \n",
       "1  In pre-Quaternary times extensive Nothofagus f...         1.0      0   \n",
       "2  Santa Cruz is on the northern edge of Monterey...         0.0      0   \n",
       "3  The Aysén del General Carlos Ibáñez del Campo ...         0.0      0   \n",
       "4  Politically, Southland proper extends from Fio...         1.0      0   \n",
       "\n",
       "          0         1         2         3         4  ...       758       759  \\\n",
       "0  1.001822 -0.928713 -0.967177  0.415425 -0.911949  ... -1.052783 -0.598555   \n",
       "1  1.063225 -0.575212 -1.081799  0.409087 -0.876170  ... -1.484141 -1.167732   \n",
       "2  0.881308 -0.373587 -0.859964 -0.379370 -0.307493  ... -0.433483 -0.247950   \n",
       "3  0.691399 -0.696447 -1.076606  0.233475 -1.041147  ... -0.862644 -0.717574   \n",
       "4  0.602599 -0.628806 -0.725431  0.293510 -0.414344  ...  0.071532 -0.608719   \n",
       "\n",
       "        760       761       762       763       764       765       766  \\\n",
       "0  0.424895 -0.130588 -0.364726 -0.503877 -0.486237 -2.300251  0.536454   \n",
       "1  0.033461 -0.135048 -0.589876  0.544747 -1.152112 -2.023077  0.504555   \n",
       "2  0.364869 -0.171929  0.020665  0.264282 -0.428337 -1.907884  0.925079   \n",
       "3 -0.367924 -0.156901 -0.136446  0.119059 -0.291558 -1.823087  0.408933   \n",
       "4  0.444171 -0.487947  0.124660 -0.200412 -0.801921 -0.927848  1.225127   \n",
       "\n",
       "        767  \n",
       "0  0.099619  \n",
       "1  0.199211  \n",
       "2 -0.015810  \n",
       "3  0.050547  \n",
       "4 -0.321115  \n",
       "\n",
       "[5 rows x 773 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nlp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_id</th>\n",
       "      <th>year</th>\n",
       "      <th>flood_amt</th>\n",
       "      <th>storm_amt</th>\n",
       "      <th>earthquake_amt</th>\n",
       "      <th>extreme temperature _amt</th>\n",
       "      <th>landslide_amt</th>\n",
       "      <th>volcanic activity_amt</th>\n",
       "      <th>drought_amt</th>\n",
       "      <th>mass movement (dry)_amt</th>\n",
       "      <th>...</th>\n",
       "      <th>drought_ct</th>\n",
       "      <th>mass movement (dry)_ct</th>\n",
       "      <th>flood_bin</th>\n",
       "      <th>storm_bin</th>\n",
       "      <th>earthquake_bin</th>\n",
       "      <th>extreme temperature _bin</th>\n",
       "      <th>landslide_bin</th>\n",
       "      <th>volcanic activity_bin</th>\n",
       "      <th>drought_bin</th>\n",
       "      <th>mass movement (dry)_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(37, 108)</td>\n",
       "      <td>1990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(42, 108)</td>\n",
       "      <td>2017</td>\n",
       "      <td>2211.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(42, 111)</td>\n",
       "      <td>1991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(44, 107)</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(44, 107)</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8675</th>\n",
       "      <td>(157, 311)</td>\n",
       "      <td>1998</td>\n",
       "      <td>5818.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8676</th>\n",
       "      <td>(157, 311)</td>\n",
       "      <td>2007</td>\n",
       "      <td>33655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8677</th>\n",
       "      <td>(157, 311)</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8678</th>\n",
       "      <td>(158, 207)</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8679</th>\n",
       "      <td>(159, 45)</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8680 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         grid_id  year  flood_amt  storm_amt  earthquake_amt  \\\n",
       "0      (37, 108)  1990        0.0        0.0             0.0   \n",
       "1      (42, 108)  2017     2211.0        0.0             0.0   \n",
       "2      (42, 111)  1991        0.0        0.0             0.0   \n",
       "3      (44, 107)  2007        0.0        0.0             0.0   \n",
       "4      (44, 107)  2010        0.0        0.0             0.0   \n",
       "...          ...   ...        ...        ...             ...   \n",
       "8675  (157, 311)  1998     5818.0        0.0             0.0   \n",
       "8676  (157, 311)  2007    33655.0        0.0             0.0   \n",
       "8677  (157, 311)  2012        0.0        0.0             0.0   \n",
       "8678  (158, 207)  2005        0.0        0.0             0.0   \n",
       "8679   (159, 45)  2006        0.0        0.0             0.0   \n",
       "\n",
       "      extreme temperature _amt  landslide_amt  volcanic activity_amt  \\\n",
       "0                          0.0            0.0                    0.0   \n",
       "1                          0.0            0.0                    0.0   \n",
       "2                          0.0            0.0                    0.0   \n",
       "3                          0.0            0.0                    0.0   \n",
       "4                          0.0            0.0                    0.0   \n",
       "...                        ...            ...                    ...   \n",
       "8675                       0.0            0.0                    0.0   \n",
       "8676                       0.0            0.0                    0.0   \n",
       "8677                       0.0            0.0                    0.0   \n",
       "8678                       0.0            0.0                    0.0   \n",
       "8679                       0.0            0.0                    0.0   \n",
       "\n",
       "      drought_amt  mass movement (dry)_amt  ...  drought_ct  \\\n",
       "0             0.0                      0.0  ...           0   \n",
       "1             0.0                      0.0  ...           0   \n",
       "2             0.0                      0.0  ...           0   \n",
       "3             0.0                      0.0  ...           0   \n",
       "4             0.0                      0.0  ...           0   \n",
       "...           ...                      ...  ...         ...   \n",
       "8675          0.0                      0.0  ...           0   \n",
       "8676          0.0                      0.0  ...           0   \n",
       "8677          0.0                      0.0  ...           0   \n",
       "8678          0.0                      0.0  ...           0   \n",
       "8679          0.0                      0.0  ...           0   \n",
       "\n",
       "      mass movement (dry)_ct  flood_bin  storm_bin  earthquake_bin  \\\n",
       "0                          0          1          0               0   \n",
       "1                          0          1          0               0   \n",
       "2                          0          0          0               0   \n",
       "3                          0          0          0               1   \n",
       "4                          0          0          0               0   \n",
       "...                      ...        ...        ...             ...   \n",
       "8675                       0          1          0               0   \n",
       "8676                       0          1          0               0   \n",
       "8677                       0          0          0               0   \n",
       "8678                       0          1          0               0   \n",
       "8679                       0          1          0               0   \n",
       "\n",
       "      extreme temperature _bin  landslide_bin  volcanic activity_bin  \\\n",
       "0                            0              0                      0   \n",
       "1                            0              0                      0   \n",
       "2                            0              0                      1   \n",
       "3                            0              0                      0   \n",
       "4                            1              0                      0   \n",
       "...                        ...            ...                    ...   \n",
       "8675                         0              0                      0   \n",
       "8676                         0              0                      0   \n",
       "8677                         1              0                      0   \n",
       "8678                         0              0                      0   \n",
       "8679                         0              0                      0   \n",
       "\n",
       "      drought_bin  mass movement (dry)_bin  \n",
       "0               0                        0  \n",
       "1               0                        0  \n",
       "2               0                        0  \n",
       "3               0                        0  \n",
       "4               0                        0  \n",
       "...           ...                      ...  \n",
       "8675            0                        0  \n",
       "8676            0                        0  \n",
       "8677            0                        0  \n",
       "8678            0                        0  \n",
       "8679            0                        0  \n",
       "\n",
       "[8680 rows x 26 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#attach nlp to xy_df \n",
    "\n",
    "df_yrly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "# pwd\n",
    "import sys\n",
    "# setting path\n",
    "sys.path.append('../src')\n",
    "\n",
    "#import model training module \n",
    "import models as m \n",
    "\n",
    "#split training and testing \n",
    "from sklearn.model_selection import train_test_split\n",
    "# import shap\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attach target for a particular disease for next n years, using y_master  \n",
    "def attach_target(x_df, y_master, disaster, next_n): \n",
    "    y = y_master.copy()\n",
    "    #shift years\n",
    "    y['year'] = y['year'] - next_n\n",
    "    #keep for particular disaster \n",
    "    y = y[['grid_id','year',disaster+'_bin']]\n",
    "    y = y.rename(columns={disaster +'_bin': 'target_' + disaster + '_'+ str(next_n)})\n",
    "    xy_df = pd.merge(x_df, y, on = ['grid_id','year'], how='inner')\n",
    "    return xy_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of xy_df 8464\n",
      "length of xy_df_sub 48262\n",
      "imbalance target_flood_1    0.015188\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#construct xy_df \n",
    "n_pred = 1\n",
    "\n",
    "xy_df = attach_target(df_yrly, y_master, 'flood', n_pred)\n",
    "print('length of xy_df', len(xy_df))\n",
    "\n",
    "#select to those id pass the filtering criteria \n",
    "xy_df_sub = xy_df.loc[xy_df['grid_id'].isin(grid_id_ls)]\n",
    "#interpolate missing years to have no flood \n",
    "xy_df_sub = pd.merge(idd, xy_df_sub, on=['grid_id','year'], how='left').fillna(0)\n",
    "\n",
    "print('length of xy_df_sub', len(xy_df_sub))\n",
    "\n",
    "print('imbalance', xy_df_sub.filter(regex='target').sum()/len(xy_df_sub))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total feature n (48262, 795)\n"
     ]
    }
   ],
   "source": [
    "#merge with NLP \n",
    "xy_df_sub1 = pd.merge(xy_df_sub, df_nlp.drop(['location','txt'], axis=1), on=['grid_id'], how='left') \n",
    "print('total feature n', xy_df_sub1.shape)\n",
    "#construct x,y train and test set \n",
    "x = xy_df_sub1.drop(xy_df_sub1.filter(regex='target').columns, axis=1)#drop target col \n",
    "x = x.select_dtypes(['number'])#drop index col\n",
    "y = xy_df_sub1.filter(regex='target') #filter to cols containing target \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "results={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumb baseline AUC 0.5\n",
      "maximum f1 score, thres 0.49613724944320714 0.4\n",
      "auc, f1, accu, accu_bl=  0.5 0.49613724944320714 0.9846674494094896 0.5\n",
      "[[14257     0]\n",
      " [  222     0]]\n",
      "Dumb baseline 2 AUC 0.8074162399756843\n",
      "maximum f1 score, thres 0.6188569873840768 0.4\n",
      "auc, f1, accu, accu_bl=  0.8074162399756843 0.6188569873840768 0.9438497133779957 0.8074162399756845\n",
      "[[13518   739]\n",
      " [   74   148]]\n"
     ]
    }
   ],
   "source": [
    "#try a simple baseline\n",
    "\n",
    "#try a dumb model predicting just zeros \n",
    "y_base = np.zeros(len(y_test)) \n",
    "print('Dumb baseline AUC', metrics.roc_auc_score(y_test,y_base))\n",
    "results['base1']=m.get_scores_clf(y_test,y_base)\n",
    "\n",
    "#try a less dumb model predicting outcome = current flood outcome \n",
    "y_base2 = x_test['flood_bin'] \n",
    "print('Dumb baseline 2 AUC', metrics.roc_auc_score(y_test,y_base2))\n",
    "results['base2']= m.get_scores_clf(y_test,y_base2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running log reg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:760: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  args=(X, target, 1. / C, sample_weight),\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:123: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  out = -np.sum(sample_weight * log_logistic(yz)) + .5 * alpha * np.dot(w, w)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:128: RuntimeWarning: invalid value encountered in multiply\n",
      "  grad[:n_features] = safe_sparse_dot(X.T, z0) + alpha * w\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1406, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 758, in _logistic_regression_path\n",
      "    opt_res = optimize.minimize(\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/_minimize.py\", line 619, in minimize\n",
      "    return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/lbfgsb.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 260, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 226, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 133, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 130, in fun_wrapped\n",
      "    return fun(x, *args)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 74, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 68, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 123, in _logistic_loss_and_grad\n",
      "    out = -np.sum(sample_weight * log_logistic(yz)) + .5 * alpha * np.dot(w, w)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/utils/extmath.py\", line 581, in log_logistic\n",
      "    X = check_array(X, dtype=np.float64)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:760: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  args=(X, target, 1. / C, sample_weight),\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:123: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  out = -np.sum(sample_weight * log_logistic(yz)) + .5 * alpha * np.dot(w, w)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:128: RuntimeWarning: invalid value encountered in multiply\n",
      "  grad[:n_features] = safe_sparse_dot(X.T, z0) + alpha * w\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1406, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 758, in _logistic_regression_path\n",
      "    opt_res = optimize.minimize(\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/_minimize.py\", line 619, in minimize\n",
      "    return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/lbfgsb.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 260, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 226, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 133, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 130, in fun_wrapped\n",
      "    return fun(x, *args)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 74, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 68, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 123, in _logistic_loss_and_grad\n",
      "    out = -np.sum(sample_weight * log_logistic(yz)) + .5 * alpha * np.dot(w, w)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/utils/extmath.py\", line 581, in log_logistic\n",
      "    X = check_array(X, dtype=np.float64)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:760: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  args=(X, target, 1. / C, sample_weight),\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:123: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  out = -np.sum(sample_weight * log_logistic(yz)) + .5 * alpha * np.dot(w, w)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:128: RuntimeWarning: invalid value encountered in multiply\n",
      "  grad[:n_features] = safe_sparse_dot(X.T, z0) + alpha * w\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1406, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 758, in _logistic_regression_path\n",
      "    opt_res = optimize.minimize(\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/_minimize.py\", line 619, in minimize\n",
      "    return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/lbfgsb.py\", line 360, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 260, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 226, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 133, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\", line 130, in fun_wrapped\n",
      "    return fun(x, *args)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 74, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/scipy/optimize/optimize.py\", line 68, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 123, in _logistic_loss_and_grad\n",
      "    out = -np.sum(sample_weight * log_logistic(yz)) + .5 * alpha * np.dot(w, w)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/utils/extmath.py\", line 581, in log_logistic\n",
      "    X = check_array(X, dtype=np.float64)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.543907          nan 0.54390418        nan\n",
      " 0.54390418        nan 0.54390418        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC:  0.5460438106311307\n",
      "maximum f1 score, thres 0.5912654195582056 0.5\n",
      "auc, f1, accu, accu_bl=  0.5520814178841814 0.5525942370221311 0.9692658332757788 0.6141242771845282\n",
      "[[13979   278]\n",
      " [  167    55]]\n"
     ]
    }
   ],
   "source": [
    "#logreg model \n",
    "y_pred, y_pred_prob = m.run_logreg(x_train, y_train, x_test)\n",
    "results['logreg'] = m.get_scores_clf(y_test, y_pred_prob)\n",
    "\n",
    "# print('Test AUC', metrics.roc_auc_score(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running xgb...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC:  0.9925761640165458\n",
      "{'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100, 'scale_pos_weight': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum f1 score, thres 0.6348158775917638 0.4\n",
      "auc, f1, accu, accu_bl=  0.9608531165660996 0.6169862698052062 0.9528972995372609 0.7987073838234672\n",
      "[[13655   602]\n",
      " [   80   142]]\n"
     ]
    }
   ],
   "source": [
    "y_pred, y_pred_prob = m.run_xgb(x_train, y_train, x_test)\n",
    "results['xgb'] = m.get_scores_clf(y_test, y_pred_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC 0.9608531165660996\n"
     ]
    }
   ],
   "source": [
    "print('Test AUC', metrics.roc_auc_score(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base1</th>\n",
       "      <th>base2</th>\n",
       "      <th>logreg</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.807416</td>\n",
       "      <td>0.552081</td>\n",
       "      <td>0.960853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.496137</td>\n",
       "      <td>0.618857</td>\n",
       "      <td>0.591265</td>\n",
       "      <td>0.634816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.984667</td>\n",
       "      <td>0.943850</td>\n",
       "      <td>0.969266</td>\n",
       "      <td>0.952897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.807416</td>\n",
       "      <td>0.614124</td>\n",
       "      <td>0.798707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      base1     base2    logreg       xgb\n",
       "0  0.500000  0.807416  0.552081  0.960853\n",
       "1  0.496137  0.618857  0.591265  0.634816\n",
       "2  0.984667  0.943850  0.969266  0.952897\n",
       "3  0.500000  0.807416  0.614124  0.798707"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results= pd.DataFrame(results)\n",
    "# results.to_clipboard(excel=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding climate data using google earth engine \n",
    "@Oscar you can take over from here :) \n",
    "- Goal: \n",
    "    - given a [grid_id, year] index, attach climate features obtained from GEE \n",
    "    - consider the following steps:\n",
    "        1. grid_id: -> corresponding lat, and longitude box (see above digitalization code) \n",
    "        2. lat, long box: -> compute e.g. the center lat, lon of that box  \n",
    "        3. lat, long, year -> try fetch features such as monthly temperature average\n",
    "        4. attach to the dataset above, re-run models \n",
    "    - Sources: \n",
    "        - https://developers.google.com/earth-engine/datasets/catalog/ECMWF_ERA5_MONTHLY \n",
    "\n",
    "- Alternative sources of climate data: \n",
    "    - https://psl.noaa.gov/data/gridded/ \n",
    "    - https://psl.noaa.gov/data/gridded/data.cmap.html \n",
    "    - https://confluence.ecmwf.int/display/CKB/ERA5-Land%3A+data+documentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
